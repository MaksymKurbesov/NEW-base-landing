<!DOCTYPE html><!-- Last Published: Mon Oct 21 2024 09:23:35 GMT+0000 (Coordinated Universal Time) --><html data-wf-domain="www.eclipse.xyz" data-wf-page="6679233ab6cb01cc096a4049" data-wf-site="667150f66409572775122b43" lang="en" data-wf-collection="6679233ab6cb01cc096a402a" data-wf-item-slug="block-stm-vs-sealevel-a-comparison-of-parallel-execution-engines"><head><meta charset="utf-8"/><title>BASE</title><meta content="width=device-width, initial-scale=1" name="viewport"/><link href="https://cdn.prod.website-files.com/667150f66409572775122b43/css/ext-eclipse-staging.webflow.2cdcdd925.css" rel="stylesheet" type="text/css"/><script type="text/javascript">!function(o,c){var n=c.documentElement,t=" w-mod-";n.className+=t+"js",("ontouchstart"in o||o.DocumentTouch&&c instanceof DocumentTouch)&&(n.className+=t+"touch")}(window,document);</script><link href="https://cdn.prod.website-files.com/667150f66409572775122b43/667bc1750dd575e2dfc2f25a_favicon.svg" rel="shortcut icon" type="image/x-icon"/><link href="https://cdn.prod.website-files.com/667150f66409572775122b43/667bc178f7d7c5e9849c975b_webclip.svg" rel="apple-touch-icon"/><!-- TRACKING CODE -->

<!-- HOTJAR  CODE -->
<script type="fs-cc" fs-cc-categories="personalization, analytics">
    (function(h,o,t,j,a,r){
        h.hj=h.hj||function(){(h.hj.q=h.hj.q||[]).push(arguments)};
        h._hjSettings={hjid:5070189,hjsv:6};
        a=o.getElementsByTagName('head')[0];
        r=o.createElement('script');r.async=1;
        r.src=t+h._hjSettings.hjid+j+h._hjSettings.hjsv;
        a.appendChild(r);
    })(window,document,'https://static.hotjar.com/c/hotjar-','.js?sv=');
</script>
<!-- END OF HOTJAR CODE -->

<!-- GOOGLE GTAG-->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-LNM2NLZLDS" type="fs-cc" fs-cc-categories="analytics"></script>
<!-- END OF GOOGLE GTAG-->

<style> 
  body {
    -webkit-font-smoothing: antialiased;
    -moz-font-smoothing: antialiased;
    -o-font-smoothing: antialiased;
  }

  /*Text Selection Color*/
  ::selection {
    background: #000;
    color: #fff;
  }
  ::-moz-selection {
    background: #000;
    color: #fff;
  }

  /*Reset apple form styles*/
  input, textarea, select { 
    -webkit-appearance: none; 
    -moz-appearance: none; 
    appearance: none; border-radius: 0; 
    background-image: none; 
  }
</style>

<link
  rel="stylesheet"
  href="https://cdn.jsdelivr.net/npm/swiper@11/swiper-bundle.min.css"
/>

<script defer src="https://cdn.jsdelivr.net/npm/swiper@11/swiper-bundle.min.js"></script>

<!-- [Attributes by Finsweet] Social Share -->
<script defer src="https://cdn.jsdelivr.net/npm/@finsweet/attributes-socialshare@1/socialshare.js"></script>

<!-- GSAP INSTALLATION DOCS -->
<script src="https://cdn.jsdelivr.net/npm/gsap@3.12.5/dist/gsap.min.js"></script>

<!-- [Attributes by Finsweet] Disable scrolling -->
<script defer src="https://cdn.jsdelivr.net/npm/@finsweet/attributes-scrolldisable@1/scrolldisable.js"></script>

<!-- Finsweet Cookie Consent -->
<script async src="https://cdn.jsdelivr.net/npm/@finsweet/cookie-consent@1/fs-cc.js" fs-cc-mode="opt-in"></script>

<!-- [Attributes by Finsweet] Powerful Rich Text -->
<script defer src="https://cdn.jsdelivr.net/npm/@finsweet/attributes-richtext@1/richtext.js"></script>

<!-- MATHJAX CONFIGURATION -->
<script>
  window.MathJax = {
    tex: {
      inlineMath: [['$', '$'], ['\\(', '\\)']],
      displayMath: [['$$', '$$'], ['\\[', '\\]']],
    },
    options: {
      skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
    },
  };
</script>
<!-- MATHJAX SCRIPT LOADING -->
<script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head><body><div class="page-wrapper"><div class="global-css"><div class="styles__global-embed-code w-embed"><style>
:root {
	/* Reset Font Weight variable values */
	--type-weight--100: 100;
	--type-weight--200: 200;
	--type-weight--300: 300;
	--type-weight--400: 400;
	--type-weight--500: 500;
	--type-weight--600: 600;
	--type-weight--700: 700;
	--type-weight--800: 800;
	--type-weight--900: 900;
}

.weight-500{
	font-weight: 500;
}

/* Remove top margin on rich text first child */
.w-richtext>:first-child {
	margin-top: 0;
}

/* Remove bottom margin of rich text last child */
.w-richtext>:last-child, .w-richtext ol li:last-child, .w-richtext ul li:last-child {
	margin-bottom: 0;
}

</style></div><div class="styles__scaling w-embed"><style>

@media (min-width: 992px) {
   html {font-size: calc(10.67px + 5.33 * ((100vw - 992px) / 448));}
}

@media (min-width: 1600px) {
   html {font-size: 16px;}
}

</style></div><div class="styles__rich-text w-embed"><style>
	.rich-text blockquote{
  	position: relative;
  }
  
  .rich-text blockquote:after{
  	content: "";
  	position: absolute;
    width: 2.625rem;
    height: 1.75rem;
    top: 1.5rem;
   	background-image: url("https://cdn.prod.website-files.com/667150f66409572775122b43/6674976b90255877c7f197c9_Vector.svg");
    background-size: contain;
    background-repeat: no-repeat;
    background-position: 50% 50%;
  }
  
  .rich-text blockquote:before{
  	content: "";
  	position: absolute;
    width: 2.625rem;
    height: 1.75rem;
    bottom: 1.5rem;
   	background-image: url("https://cdn.prod.website-files.com/667150f66409572775122b43/6674976b90255877c7f197c9_Vector.svg");
    background-size: contain;
    background-repeat: no-repeat;
    background-position: 50% 50%;
  }
</style></div><div class="styles__hover-bgs w-embed"><style>

  .nav-link_wrapper:hover .nav-link_bg{
    transform: scale(1);
    opacity: 1;
  }

</style></div><div class="styles__marquees w-embed"><style>

@keyframes scroll {
  from {
    transform: translateX(0);
  }
  to {
    transform: translateX(-50%);
  }
}

.marquee-track {
  animation: scroll 20s linear infinite;
}

</style></div><div class="styles__scrollbars w-embed"><style>

  *{
    overscroll-behavior: none;
  }

  /* width */
  ::-webkit-scrollbar {
    width: 5px;
    height: 0.5px;
  }
  /* Track */
  ::-webkit-scrollbar-track {
    background: white;
  }

  /* Handle */
  ::-webkit-scrollbar-thumb {
    background: black;
  }

  /* Handle on hover */
  ::-webkit-scrollbar-thumb:hover {
    background: black;
  }


</style></div><div class="styles__line-clamp w-embed"><style>

  .card-text{
    display: -webkit-box;
    -webkit-line-clamp: 4;
    -webkit-box-orient: vertical;
    overflow: hidden;
  }

</style></div><div class="styles__nav-brand w-embed"><style>

	
  .d_nav-brand.is-short{
  	.nav-brand-short{
    	opacity: 1;
    }
    
    .nav-brand-long{
    	opacity: 0;
    }
  	
  }

</style></div></div><div class="cookies-banners"><div fs-cc="banner" class="fs-cc-banner_component"><div class="fs-cc-banner_container"><div class="fs-cc-banner_block"><div class="cookie-banner-text">COOKIE CONSENT: </div><p class="cookie-banner-text">By clicking <strong>“Accept”</strong>, you agree to the storing of cookies on your device to enhance site navigation, analyze site usage, and assist in our marketing efforts. View our <a href="../privacy-policy.html" class="inline-text-link">Privacy Policy</a> for more information.</p></div><div class="fs-cc-banner_buttons-wrapper"><a fs-cc="deny" href="block-stm-vs-sealevel-a-comparison-of-parallel-execution-engines.html#" class="btn cc-inverse-outline cc-smaller-mobile w-inline-block"><div class="btn-icon"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:svgjs="http://svgjs.com/svgjs" version="1.1" width="100%" x="0" y="0" viewBox="0 0 329.328 329.328" STYLE="enable-background:new 0 0 512 512" xml:space="preserve" class=""><g><path xmlns="http://www.w3.org/2000/svg" d="M164.666,0C73.871,0,0.004,73.871,0.004,164.672c0.009,90.792,73.876,164.656,164.662,164.656  c90.793,0,164.658-73.865,164.658-164.658C329.324,73.871,255.459,0,164.666,0z M164.666,30c31.734,0,60.933,11.042,83.975,29.477  L59.478,248.638c-18.431-23.04-29.471-52.237-29.474-83.967C30.004,90.413,90.413,30,164.666,30z M164.666,299.328  c-31.733,0-60.934-11.042-83.977-29.477L269.854,80.691c18.431,23.043,29.471,52.244,29.471,83.979  C299.324,238.921,238.917,299.328,164.666,299.328z" fill="currentColor" data-original="#000000" STYLE="" class=""></path><g xmlns="http://www.w3.org/2000/svg"></g><g xmlns="http://www.w3.org/2000/svg"></g><g xmlns="http://www.w3.org/2000/svg"></g><g xmlns="http://www.w3.org/2000/svg"></g><g xmlns="http://www.w3.org/2000/svg"></g><g xmlns="http://www.w3.org/2000/svg"></g><g xmlns="http://www.w3.org/2000/svg"></g><g xmlns="http://www.w3.org/2000/svg"></g><g xmlns="http://www.w3.org/2000/svg"></g><g xmlns="http://www.w3.org/2000/svg"></g><g xmlns="http://www.w3.org/2000/svg"></g><g xmlns="http://www.w3.org/2000/svg"></g><g xmlns="http://www.w3.org/2000/svg"></g><g xmlns="http://www.w3.org/2000/svg"></g><g xmlns="http://www.w3.org/2000/svg"></g></g></svg></div><div>Deny</div></a><a fs-cc="allow" href="block-stm-vs-sealevel-a-comparison-of-parallel-execution-engines.html#" class="btn cc-smaller-mobile cc-accent w-inline-block"><div class="btn-icon"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:svgjs="http://svgjs.com/svgjs" version="1.1" width="100%" x="0" y="0" viewBox="0 0 515.556 515.556" STYLE="enable-background:new 0 0 512 512" xml:space="preserve" class="icon-embed"><g><path xmlns="http://www.w3.org/2000/svg" d="m0 274.226 176.549 176.886 339.007-338.672-48.67-47.997-290.337 290-128.553-128.552z" fill="currentColor" data-original="#000000" STYLE=""></path></g></svg></div><div>Accept</div></a></div></div></div><div fs-cc="manager" class="fs-cc-manager_component"><a fs-cc="open-preferences" href="block-stm-vs-sealevel-a-comparison-of-parallel-execution-engines.html#" class="btn cc-smaller-mobile w-inline-block"><div class="btn-icon"><svg xmlns="http://www.w3.org/2000/svg" enable-background="new 0 0 512.026 512.026" viewBox="0 0 512.026 512.026" fill="currentColor" width="100%" class="icon-embed"><g><path d="m511.525 241.705c-1.21-22.482-6.909-49.971-17.666-77.748-3.766-9.725-16.048-12.699-23.855-5.881-5.564 4.859-15.309 3.478-18.563-2.599-3.886-7.256-12.89-10.023-20.179-6.209-17.818 9.326-40.237.637-46.641-19.032-2.388-7.335-9.952-11.665-17.487-10.006-20.777 4.568-40.134-11.324-40.134-32.217 0-8.143 2.995-15.965 8.433-22.025 8.406-9.367 2.187-24.346-10.388-24.997-7.513-.391-12.884-6.94-9.429-12.76 5.277-8.89.174-20.366-9.994-22.373-15.381-3.036-32.039-5.845-49.622-5.845-140.303 0-256 106.637-256 248 0 140.366 114.711 264 256 264 148.992 0 264.611-127.454 255.525-270.308zm-43.83 93.429c-16.703-5.236-28.695-20.835-28.695-39.121 0-23.222 19.421-42.061 42.99-40.947.148 27.26-4.678 54.421-14.295 80.068zm-386.695-127.121c0 26.156-28.999 41.656-50.664 27.883 1.147-21.147 5.289-41.403 12.025-60.399 20.312-3.49 38.639 12.198 38.639 32.516zm175 274c-115.793 0-214.585-95.744-225.064-213.349 40.47 11.345 80.064-19.283 80.064-60.651 0-32.132-24.186-58.704-55.305-62.513 37.448-69.237 112.24-115.487 200.305-115.487 9.639 0 19.241 1.046 28.557 2.521.179 12.837 6.935 24.244 17.288 31.24-17.505 41.973 14.071 88.048 59.285 87.229 14.429 25.643 44.523 37.606 72.45 29.503 10.287 9.14 24.546 12.389 37.663 9.473 3.752 11.781 6.52 23.482 8.312 35.046-38.944.241-70.555 31.988-70.555 70.988 0 30.389 19.136 56.487 46.252 66.559-38.139 71.029-113.144 119.441-199.252 119.441z"></path><path d="m304 305.013c-39.149 0-71 31.851-71 71s31.851 71 71 71 71-31.851 71-71-31.851-71-71-71zm0 112c-22.607 0-41-18.393-41-41s18.393-41 41-41 41 18.393 41 41-18.393 41-41 41z"></path><path d="m279 188.013c0-28.121-22.878-51-51-51s-51 22.879-51 51 22.878 51 51 51 51-22.879 51-51zm-51 21c-11.58 0-21-9.421-21-21s9.42-21 21-21 21 9.421 21 21-9.42 21-21 21z"></path><path d="m148 273.013c-28.122 0-51 22.879-51 51s22.878 51 51 51 51-22.879 51-51-22.878-51-51-51zm0 72c-11.58 0-21-9.421-21-21s9.42-21 21-21 21 9.421 21 21-9.42 21-21 21z"></path></g></svg></div><div>Cookie preferences</div></a></div><div fs-cc-scroll="disable" fs-cc="preferences" class="fs-cc-prefs3_component"><div fs-cc="close" class="fs-cc-prefs_close"><div class="fs-cc-preferences3_close-icon"><svg fill="currentColor" aria-hidden="true" focusable="false" viewBox="0 0 16 16" width="100%" class="icon-embed"><path d="M9.414 8l4.293-4.293-1.414-1.414L8 6.586 3.707 2.293 2.293 3.707 6.586 8l-4.293 4.293 1.414 1.414L8 9.414l4.293 4.293 1.414-1.414L9.414 8z"></path></svg></div></div><div class="fs-cc-prefs_form-wrapper w-form"><form id="cookie-preferences" name="wf-form-Cookie-Preferences" data-name="Cookie Preferences" method="get" class="fs-cc-prefs_form" data-wf-page-id="6679233ab6cb01cc096a4049" data-wf-element-id="a31b8315-b109-8c91-38d4-b41fc23d9b36"><div class="fs-cc-prefs_header"><div class="fs-cc-prefs_icon"><div fs-cc="open-preferences" role="button" tabindex="0" title="Cookie Preferences" aria-label="Cookie Preferences" class="icon-embed w-embed"><svg enable-background="new 0 0 512.026 512.026" viewBox="0 0 512.026 512.026" fill="currentColor" xmlns="http://www.w3.org/2000/svg"><g><path d="m511.525 241.705c-1.21-22.482-6.909-49.971-17.666-77.748-3.766-9.725-16.048-12.699-23.855-5.881-5.564 4.859-15.309 3.478-18.563-2.599-3.886-7.256-12.89-10.023-20.179-6.209-17.818 9.326-40.237.637-46.641-19.032-2.388-7.335-9.952-11.665-17.487-10.006-20.777 4.568-40.134-11.324-40.134-32.217 0-8.143 2.995-15.965 8.433-22.025 8.406-9.367 2.187-24.346-10.388-24.997-7.513-.391-12.884-6.94-9.429-12.76 5.277-8.89.174-20.366-9.994-22.373-15.381-3.036-32.039-5.845-49.622-5.845-140.303 0-256 106.637-256 248 0 140.366 114.711 264 256 264 148.992 0 264.611-127.454 255.525-270.308zm-43.83 93.429c-16.703-5.236-28.695-20.835-28.695-39.121 0-23.222 19.421-42.061 42.99-40.947.148 27.26-4.678 54.421-14.295 80.068zm-386.695-127.121c0 26.156-28.999 41.656-50.664 27.883 1.147-21.147 5.289-41.403 12.025-60.399 20.312-3.49 38.639 12.198 38.639 32.516zm175 274c-115.793 0-214.585-95.744-225.064-213.349 40.47 11.345 80.064-19.283 80.064-60.651 0-32.132-24.186-58.704-55.305-62.513 37.448-69.237 112.24-115.487 200.305-115.487 9.639 0 19.241 1.046 28.557 2.521.179 12.837 6.935 24.244 17.288 31.24-17.505 41.973 14.071 88.048 59.285 87.229 14.429 25.643 44.523 37.606 72.45 29.503 10.287 9.14 24.546 12.389 37.663 9.473 3.752 11.781 6.52 23.482 8.312 35.046-38.944.241-70.555 31.988-70.555 70.988 0 30.389 19.136 56.487 46.252 66.559-38.139 71.029-113.144 119.441-199.252 119.441z"/><path d="m304 305.013c-39.149 0-71 31.851-71 71s31.851 71 71 71 71-31.851 71-71-31.851-71-71-71zm0 112c-22.607 0-41-18.393-41-41s18.393-41 41-41 41 18.393 41 41-18.393 41-41 41z"/><path d="m279 188.013c0-28.121-22.878-51-51-51s-51 22.879-51 51 22.878 51 51 51 51-22.879 51-51zm-51 21c-11.58 0-21-9.421-21-21s9.42-21 21-21 21 9.421 21 21-9.42 21-21 21z"/><path d="m148 273.013c-28.122 0-51 22.879-51 51s22.878 51 51 51 51-22.879 51-51-22.878-51-51-51zm0 72c-11.58 0-21-9.421-21-21s9.42-21 21-21 21 9.421 21 21-9.42 21-21 21z"/></g></svg></div></div><div class="text-32 u-text-caps u-mb-0">Privacy Preferences</div></div><div class="fs-cc-prefs_content"><div class="fs-cc-prefs_option"><div class="fs-cc-prefs_toggle-wrapper"><div class="text-20 cc-barlow u-mb-0">Essential cookies</div><div class="fs-cc-prefs_line"></div><div>Required</div></div></div><div class="fs-cc-prefs_option"><div class="fs-cc-prefs_toggle-wrapper"><div class="text-20 cc-barlow u-mb-0">Marketing cookies</div><div class="fs-cc-prefs_line"></div><label class="w-checkbox fs-cc-prefs_checkbox-field"><div class="w-checkbox-input w-checkbox-input--inputType-custom fs-cc-prefs_checkbox"></div><input type="checkbox" name="marketing-2" id="marketing-2" data-name="Marketing 2" fs-cc-checkbox="marketing" style="opacity:0;position:absolute;z-index:-1"/><span for="marketing-2" class="fs-cc-prefs_checkbox-label w-form-label">Essential</span></label></div></div><div class="fs-cc-prefs_option"><div class="fs-cc-prefs_toggle-wrapper"><div class="text-20 cc-barlow u-mb-0">Personalization cookies</div><div class="fs-cc-prefs_line"></div><label class="w-checkbox fs-cc-prefs_checkbox-field"><div class="w-checkbox-input w-checkbox-input--inputType-custom fs-cc-prefs_checkbox"></div><input type="checkbox" name="personalization-2" id="personalization-2" data-name="Personalization 2" fs-cc-checkbox="personalization" style="opacity:0;position:absolute;z-index:-1"/><span for="personalization-2" class="fs-cc-prefs_checkbox-label w-form-label">Essential</span></label></div></div><div class="fs-cc-prefs_option"><div class="fs-cc-prefs_toggle-wrapper"><div class="text-20 cc-barlow u-mb-0">Analytics cookies</div><div class="fs-cc-prefs_line"></div><label class="w-checkbox fs-cc-prefs_checkbox-field"><div class="w-checkbox-input w-checkbox-input--inputType-custom fs-cc-prefs_checkbox"></div><input type="checkbox" name="analytics-2" id="analytics-2" data-name="Analytics 2" fs-cc-checkbox="analytics" style="opacity:0;position:absolute;z-index:-1"/><span for="analytics-2" class="fs-cc-prefs_checkbox-label w-form-label">Essential</span></label></div></div></div><div class="fs-cc-prefs_buttons-wrapper"><div class="fs-cc-prefs_buttons-block"><a fs-cc="deny" href="block-stm-vs-sealevel-a-comparison-of-parallel-execution-engines.html#" class="btn w-button">Reject all cookies</a><a fs-cc="allow" href="block-stm-vs-sealevel-a-comparison-of-parallel-execution-engines.html#" class="btn cc-accent-inverse w-button">Allow all cookies</a></div><input type="submit" data-wait="Please wait..." class="btn cc-outline w-button" value="Save preferences"/></div></form><div class="w-form-done"></div><div class="w-form-fail"></div><div fs-cc="close" class="fs-cc-prefs3_overlay"></div></div></div></div><main class="page-main"><nav id="" class="nav"><div class="nav-container"><div class="nav-blur_bg"></div><div class="d_nav-links"><div class="nav-link_wrapper"><div class="nav-link_bg"></div><div data-hover="false" data-delay="0" class="nav-dropdown w-dropdown"><div class="nav-link w-dropdown-toggle"><div>About</div><div class="u-position-relative u-m-0 w-icon-dropdown-toggle"></div></div><nav class="nav-dropdown_list w-dropdown-list"><div class="nav-dropdown_list-wrapper"><a href="../why-eclipse.html" class="nav-link w-inline-block"><div>Why BASE?</div></a><a href="../blog.html" class="nav-link w-inline-block"><div>Blog</div></a><a href="https://boards.greenhouse.io/eclipse" target="_blank" class="nav-link w-inline-block"><div>Careers</div></a></div></nav></div></div><div class="nav-link_wrapper"><div class="nav-link_bg"></div><div data-hover="false" data-delay="0" class="nav-dropdown w-dropdown"><div class="nav-link w-dropdown-toggle"><div>builders</div><div class="u-position-relative u-m-0 w-icon-dropdown-toggle"></div></div><nav class="nav-dropdown_list w-dropdown-list"><div class="nav-dropdown_list-wrapper"><a href="mailto:team@eclipse.xyz" class="nav-link w-inline-block"><div>Contact</div></a><a href="https://docs.eclipse.xyz/" target="_blank" class="nav-link w-inline-block"><div>Developer Docs</div></a></div></nav></div></div><div class="nav-link_wrapper"><div class="nav-link_bg"></div><a href="https://www.hackathon.eclipse.xyz/" target="_blank" class="nav-link w-inline-block"><div class="arrow-icon"></div></a></div></div><div class="d_nav-brands"><a href="../index.html" class="d_nav-brand w-inline-block"><div class="nav-brand-long"><svg xmlns="http://www.w3.org/2000/svg" width="100%" viewBox="0 0 1344 144" fill="none" class="icon-embed"><path d="M193.189 28.5047L200.076 0H54.9142C40.7075 0 26.3636 11.7106 22.8712 26.1591L0.770964 117.638C-2.71855 132.086 5.96666 143.797 20.1705 143.797H165.333L172.22 115.292H56.7404C52.0048 115.292 49.1098 111.388 50.2729 106.572L55.2057 86.1507H179.256L186.144 57.646H62.0961L67.0289 37.2244C68.1921 32.4082 72.9734 28.5047 77.7089 28.5047H193.186H193.189Z" fill="currentColor"></path><path d="M383.017 28.5047L389.904 0H244.742C230.538 0 216.195 11.7106 212.702 26.1591L190.599 117.638C187.11 132.086 195.795 143.797 209.999 143.797H355.161L362.048 115.292H246.571C241.836 115.292 238.941 111.388 240.104 106.572L256.86 37.2244C258.023 32.4082 262.804 28.5047 267.54 28.5047H383.017Z" fill="currentColor"></path><path d="M431.977 106.572L457.727 0H410.897L382.475 117.638C378.986 132.086 387.671 143.797 401.875 143.797H547.037L553.924 115.292H438.447C433.712 115.292 430.817 111.388 431.98 106.572H431.977Z" fill="currentColor"></path><path d="M764.962 28.5047L771.85 0H600.966L594.079 28.5047H647.53C652.266 28.5047 655.161 32.4082 653.998 37.2244L637.242 106.572C636.079 111.388 631.297 115.292 626.562 115.292H573.11L566.223 143.797H737.106L743.994 115.292H690.542C685.806 115.292 682.911 111.388 684.075 106.572L700.83 37.2244C701.994 32.4082 706.775 28.5047 711.511 28.5047H764.962Z" fill="currentColor"></path><path d="M839.07 0H817.961C803.757 0 789.411 11.7106 785.921 26.1591L757.499 143.797H804.329L818.255 86.1507H916.585C930.792 86.1507 945.136 74.4401 948.628 59.9916L956.802 26.1591C960.294 11.7106 951.606 0 937.402 0H839.073H839.07ZM894.03 57.646H825.14L832.182 28.5047H901.072C905.808 28.5047 908.703 32.4082 907.54 37.2244L904.713 48.9263C903.55 53.7425 898.769 57.646 894.033 57.646H894.03Z" fill="currentColor"></path><path d="M1092.49 143.797H947.327L954.215 115.292H1069.48C1074.22 115.292 1079 111.388 1080.16 106.572L1082.99 94.8704C1084.15 90.0542 1081.25 86.1507 1076.52 86.1507H986.975C972.768 86.1507 964.083 74.4401 967.576 59.9916L975.749 26.1591C979.239 11.7106 993.585 0 1007.79 0H1152.95L1146.06 28.5047H1030.58C1025.85 28.5047 1021.07 32.4082 1019.9 37.2244L1017.08 48.9263C1015.91 53.7425 1018.81 57.646 1023.54 57.646H1113.3C1127.51 57.646 1136.19 69.3565 1132.7 83.8051L1124.53 117.638C1121.04 132.086 1106.69 143.797 1092.48 143.797H1092.49Z" fill="currentColor"></path><path d="M1337.11 28.5047L1344 0H1198.84C1184.63 0 1170.29 11.7106 1166.79 26.1591L1144.69 117.638C1141.2 132.086 1149.89 143.797 1164.09 143.797H1309.25L1316.14 115.292H1200.66C1195.93 115.292 1193.03 111.388 1194.2 106.572L1199.13 86.1507H1323.18L1330.07 57.646H1206.02L1210.95 37.2244C1212.11 32.4082 1216.89 28.5047 1221.63 28.5047H1337.11H1337.11Z" fill="currentColor"></path></svg></div><div class="nav-brand-short"><svg xmlns="http://www.w3.org/2000/svg" width="100%" viewBox="0 0 31 31" fill="none" class="icon-embed"><g clip-path="url(#clip0_200_96)"><path d="M14.557 10.9757L13.8307 13.5734H27.2108L26.1331 17.427H12.753L12.0266 20.0246C11.8324 20.7185 12.2205 21.281 12.8932 21.281H28.2029L28.1984 21.2971C29.3059 19.5064 30.1345 17.5501 30.5967 15.5003C31.0573 13.457 31.1119 11.5061 30.8151 9.71973H16.1264C15.4537 9.71973 14.7512 10.2821 14.5574 10.9761L14.557 10.9757Z" fill="currentColor"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M7.87564 25.134C6.02589 25.1191 4.96228 23.5641 5.49809 21.6483L8.93727 9.35134C9.47565 7.42604 11.4252 5.86557 13.2914 5.86557H15.9859L15.9853 5.86523H29.4981C29.4982 5.86535 29.4983 5.86547 29.4983 5.86558H29.4996C27.5402 2.29181 23.7869 0 18.9954 0C10.6569 0 2.33302 6.93917 0.402751 15.4998C-1.52752 24.0608 3.66639 30.9997 12.0049 30.9997C16.7968 30.9997 21.5837 28.7078 25.1553 25.1341H7.9035C7.89419 25.1341 7.88491 25.134 7.87564 25.134Z" fill="currentColor"></path></g><defs><clipPath id="clip0_200_96"><rect width="31" height="31" fill="currentColor"></rect></clipPath></defs></svg></div></a></div><div class="d_nav-menu"><div class="nav-socials"><a href="https://x.com/EclipseFND" target="_blank" class="nav-social w-inline-block"><svg xmlns="http://www.w3.org/2000/svg" width="100%" viewBox="0 0 18 16" fill="none" class="icon-embed"><path d="M13.9378 0H16.64L10.7378 6.79111L17.7067 16H12.2311L7.96444 10.4178L3.05778 16H0.355556L6.68444 8.74667L0 0H5.61778L9.49333 5.12L13.9378 0ZM12.9778 14.3644H14.4711L4.8 1.52889H3.16444L12.9778 14.3644Z" fill="currentColor"></path></svg></a><a href="https://discord.gg/eclipse-fnd" target="_blank" class="nav-social cc-discord w-inline-block"><svg xmlns="http://www.w3.org/2000/svg" width="100%" viewBox="0 0 23 16" fill="none" class="icon-embed"><path d="M18.8282 1.33997C17.4412 0.70497 15.977 0.254475 14.4729 0C14.2671 0.367934 14.0809 0.746489 13.915 1.13408C12.3129 0.892656 10.6836 0.892656 9.08145 1.13408C8.91551 0.746529 8.72928 0.367978 8.52354 0C7.0185 0.256624 5.55329 0.708188 4.16489 1.3433C1.40856 5.42134 0.661361 9.39809 1.03496 13.3184C2.64914 14.511 4.45586 15.418 6.3766 16C6.80909 15.4183 7.19179 14.8012 7.52064 14.1553C6.89604 13.922 6.29318 13.6342 5.71906 13.2951C5.87016 13.1856 6.01794 13.0726 6.16074 12.9631C7.8313 13.7487 9.65464 14.156 11.5007 14.156C13.3468 14.156 15.1701 13.7487 16.8407 12.9631C16.9851 13.0809 17.1329 13.1939 17.2824 13.2951C16.7071 13.6347 16.1032 13.9231 15.4775 14.1569C15.8059 14.8026 16.1886 15.4192 16.6215 16C18.5439 15.4204 20.352 14.5138 21.9665 13.32C22.4048 8.77376 21.2176 4.83354 18.8282 1.33997ZM7.99386 10.9074C6.95277 10.9074 6.09266 9.96264 6.09266 8.80033C6.09266 7.63802 6.92288 6.68493 7.99054 6.68493C9.05821 6.68493 9.91167 7.63802 9.89341 8.80033C9.87514 9.96264 9.05489 10.9074 7.99386 10.9074ZM15.0076 10.9074C13.9648 10.9074 13.108 9.96264 13.108 8.80033C13.108 7.63802 13.9382 6.68493 15.0076 6.68493C16.0769 6.68493 16.9237 7.63802 16.9054 8.80033C16.8872 9.96264 16.0686 10.9074 15.0076 10.9074Z" fill="currentColor"></path></svg></a></div><a href="https://docs.eclipse.xyz/" target="_blank" class="btn w-inline-block"><div>Start building</div></a></div><button data-w-id="c40c8ec1-279a-1dae-d140-ff06b7a9da77" class="m-nav_menu-button"><div class="m-nav_button-line cc-one"></div><div class="m-nav_button-line cc-two"></div><div class="m-nav_button-line cc-three"></div></button></div><div fs-scrolldisable-element="when-visible" class="m_nav"><div class="m_nav_wrapper"><a href="https://docs.eclipse.xyz/" target="_blank" class="nav-link w-inline-block"><div>Docs</div></a><a href="../why-eclipse.html" class="nav-link w-inline-block"><div>Why Eclipse?</div></a><a href="../blog.html" class="nav-link w-inline-block"><div>Blog</div></a><a href="https://boards.greenhouse.io/eclipse" target="_blank" class="nav-link w-inline-block"><div>Careers</div></a><a href="mailto:team@eclipse.xyz" class="nav-link w-inline-block"><div>Contact</div></a><a href="https://docs.eclipse.xyz/" target="_blank" class="btn is-nav w-inline-block"><div>Start building</div></a></div></div></nav><header class="section cc-article_header w-condition-invisible"><div class="article-header_img"><img src="https://cdn.prod.website-files.com/667922883d09f8c39ad9defe/6711184ec19d83ceb6bb2052_Block-STM%20v%20SVM%20illustrations%20(v%201.0).png" loading="lazy" alt="" sizes="100vw" srcset="https://cdn.prod.website-files.com/667922883d09f8c39ad9defe/6711184ec19d83ceb6bb2052_Block-STM%20v%20SVM%20illustrations%20(v%201.0)-p-500.png 500w, https://cdn.prod.website-files.com/667922883d09f8c39ad9defe/6711184ec19d83ceb6bb2052_Block-STM%20v%20SVM%20illustrations%20(v%201.0)-p-800.png 800w, https://cdn.prod.website-files.com/667922883d09f8c39ad9defe/6711184ec19d83ceb6bb2052_Block-STM%20v%20SVM%20illustrations%20(v%201.0)-p-1080.png 1080w, https://cdn.prod.website-files.com/667922883d09f8c39ad9defe/6711184ec19d83ceb6bb2052_Block-STM%20v%20SVM%20illustrations%20(v%201.0)-p-1600.png 1600w, https://cdn.prod.website-files.com/667922883d09f8c39ad9defe/6711184ec19d83ceb6bb2052_Block-STM%20v%20SVM%20illustrations%20(v%201.0).png 1920w" class="u-img-cover"/><div class="article-overlay"></div></div><div class="container u-position-relative"><div><div class="article-header_tag"><div class="dot"></div><div class="text-12 u-text-caps u-mb-0">FEATURED</div></div><div class="article-header_tag w-condition-invisible"><div class="dot"></div><div class="text-12 u-text-caps u-mb-0">Research</div></div></div><h1 class="heading-140 u-mb-0">Block-STM vs. Sealevel: A Comparison of Parallel Execution Engines</h1><div class="article-header_info"><div class="flex_between"><div class="w-embed"><span class="text-16 u-mb-0 u-text-caps">BY: Eclipse Labs<span></div><div class="text-16 u-text-caps u-mb-0">17.10.2024</div></div></div></div></header><header class="section cc-article_header"><div class="container u-position-relative"><div class="article-header_tag"><div class="dot"></div><div class="text-12 u-text-caps u-mb-0">Research</div></div><h1 class="heading-140 u-mb-0">Block-STM vs. Sealevel: A Comparison of Parallel Execution Engines</h1><div class="article-header_info"><div class="flex_between"><div class="w-embed"><span class="text-16 u-mb-0 u-text-caps">BY: Eclipse Labs<span></div><div class="text-16 u-text-caps u-mb-0">17.10.2024</div></div></div></div></header><header class="section cc-article_header cc-green w-condition-invisible"><div class="container u-position-relative"><div class="article-header_tag"><div class="dot"></div><div class="text-12 u-text-caps u-mb-0">Research</div></div><h1 class="heading-140 u-mb-0">Block-STM vs. Sealevel: A Comparison of Parallel Execution Engines</h1><div class="article-header_info"><div class="flex_between"><div class="w-embed"><span class="text-16 u-mb-0 u-text-caps">BY: Eclipse Labs<span></div><div class="text-16 u-text-caps u-mb-0">17.10.2024</div></div></div></div></header><header class="section cc-article_header cc-white w-condition-invisible"><div class="container u-position-relative"><div class="article-header_tag"><div class="dot"></div><div class="text-12 u-text-caps u-mb-0">Research</div></div><h1 class="heading-140 u-mb-0">Block-STM vs. Sealevel: A Comparison of Parallel Execution Engines</h1><div class="article-header_info"><div class="flex_between"><div class="w-embed"><span class="text-16 u-mb-0 u-text-caps">BY: Eclipse Labs<span></div><div class="text-16 u-text-caps u-mb-0">17.10.2024</div></div></div></div></header><header class="section cc-article_header cc-bg w-condition-invisible"><div class="container u-position-relative"><div class="article-header_tag"><div class="dot"></div><div class="text-12 u-text-caps u-mb-0">Research</div></div><h1 class="heading-140 u-mb-0">Block-STM vs. Sealevel: A Comparison of Parallel Execution Engines</h1><div class="article-header_info"><div class="flex_between"><div class="w-embed"><span class="text-16 u-mb-0 u-text-caps">BY: Eclipse Labs<span></div><div class="text-16 u-text-caps u-mb-0">17.10.2024</div></div></div></div></header><section class="section cc-blog_body"><div class="container cc-smaller"><div class="rich-text w-richtext"><p>Cross posted on https://research.2077.xyz/block-stm-vs-sealevel-1</p><p><strong>An analysis of parallelization in distributed ledger transaction execution.</strong></p><p><em>We’d like to acknowledge: </em><a href="https://x.com/apfitzge"><em>Andrew </em></a><em>&amp; </em><a href="https://x.com/bw_solana"><em>BW</em></a><em> from Anza, </em><a href="https://x.com/0xtaetaehoho"><em>Terry</em></a><em> from Eclipse, and  </em><a href="https://x.com/neilhar_"><em>Neil</em></a><em>, </em><a href="https://x.com/SashaSpiegelman"><em>Sasha</em></a><em>, Daniel, Arun, and Igor from Aptos Labs for their help and fruitful discussions during the research process.</em></p><p>Aptos’ Block-STM and Solana’s Sealevel are antagonistic approaches to parallelizing blockchain execution. Block-STM uses an Optimistic Concurrency Control (OCC) approach, i.e., the Transaction Processing Unit (TPU) (optimistically) assumes that no transactions executed concurrently will conflict and relies on in-built checks and logic to identify and resolve conflicts. Sealevel, on the other hand (pessimistically), assumes that transactions will conflict and relies on lock-based synchronization to prevent conflicts.</p><p>The Pessimistic Concurrency Control (PCC) approach has historically been more performant in distributed database systems and for intuitive reasons too—a TPU that schedules transactions in a manner that prevents conflict should perform better than an TPU that has to resolve conflicts after the fact. However, thanks to clever design and engineering, Block-STM performs surprisingly well, with the added benefits of allowing arbitrary logic and, by extension, a greater range of use cases and a superior devex.</p><p>This paper will examine and break down how both TPUs approach parallelization at a relatively low level and evaluate their performance and scalability. It will also provide an unbiased evaluation of the strengths and weaknesses of both TPUs.</p><p>The paper is written with the assumption that the reader is familiar with blockchain concepts like transactions, blocks, and consensus. Familiarity with distributed databases and computer architecture will help with groking some of the concepts but the glossary explains unfamiliar terms and the main body and appendix contain “primers” on unfamiliar subjects.</p><h1>Table of Contents</h1><ul role="list"><li><a href="https://docs.google.com/document/d/10h-bTC6i_LX2ANinHakutpBgbeta7Dz4jBq8hPv0S_c/edit?pli=1#heading=h.byo8tvnj20ef">Introduction</a></li><li><a href="https://docs.google.com/document/d/10h-bTC6i_LX2ANinHakutpBgbeta7Dz4jBq8hPv0S_c/edit?pli=1#heading=h.wv7bv7kbisyl">Blockchain-Software Transactional Memory (Block-STM)</a></li><li><a href="https://docs.google.com/document/d/10h-bTC6i_LX2ANinHakutpBgbeta7Dz4jBq8hPv0S_c/edit?pli=1#heading=h.7j7q4a3n1hp0">Sealevel</a></li><li><a href="https://docs.google.com/document/d/10h-bTC6i_LX2ANinHakutpBgbeta7Dz4jBq8hPv0S_c/edit?pli=1#heading=h.ts2s5ndxgwrk">Block-STM vs. Sealevel</a></li><li><a href="https://docs.google.com/document/d/10h-bTC6i_LX2ANinHakutpBgbeta7Dz4jBq8hPv0S_c/edit?pli=1#heading=h.q92q613ni6uc">Conclusion</a></li><li><a href="https://docs.google.com/document/d/10h-bTC6i_LX2ANinHakutpBgbeta7Dz4jBq8hPv0S_c/edit?pli=1#heading=h.vd5yvsjmuank">References</a></li><li><a href="https://docs.google.com/document/d/10h-bTC6i_LX2ANinHakutpBgbeta7Dz4jBq8hPv0S_c/edit?pli=1#heading=h.s7hnef6hxrnu">Glossary</a></li><li><a href="https://docs.google.com/document/d/10h-bTC6i_LX2ANinHakutpBgbeta7Dz4jBq8hPv0S_c/edit?pli=1#heading=h.c8ney3g0e3e2">Appendix</a></li></ul><h1>Common terms</h1><p>A few terms will come up often so let’s quickly breakdown what they mean in the context of this paper:</p><ul role="list"><li>concurrency and parallelism: concurrency refers to multiple processes using the same resource(s). Parallelism is multiple processes running completely independent of one another. Programs can have any combination, none, or both of the properties.<br/><br/></li><li>transactions: a transaction is an atomic set of instructions that performs a logical operation. The instructions referenced here are analogous to low-level computer instructions but they do far more than a computer instruction.<br/><br/></li><li>conflict: two or more transactions are said to conflict when they modify/access the same portion of state. Specifically, a conflict occurs when at least one transaction tries to write to the contended portion of state; if all the transactions are reading, then they don’t conflict.<br/><br/></li><li>state: state describes the condition of a thing at an instance in time. In the context of blockchains, state is the set of accounts and their associated data (balances and code). When memory access/modification is mentioned, memory refers to state.<br/><br/></li><li>dependencies: transaction B is said to be a dependency of transaction A if and only if:some text<ul role="list"><li>transaction B conflicts with A,</li><li>and transaction B is of lower priority than A. (If B were of higher priority, A would be a dependency of B.)<br/><br/></li></ul></li><li>lock: a lock or mutex, is a mechanism used to prevent concurrent access to a memory location. When a transaction/process wants to access a memory location in lock-based systems, it attempts to grab the lock for the associated location; if the location is already locked, the lock grab fails and the transaction must wait.</li><li>serializability (of transactions): a set of transactions executed concurrently is said to be serializable if there exists a sequential execution of the same set of transactions that produces the same result.<br/><br/></li></ul><p>With all of that out of the way, we can get started.</p><h1>Introduction</h1><p>A “blockchain network” is a decentralized, byzantine-fault-tolerant distributed database. The Transaction Processing Unit (TPU) is the component responsible for computing state transitions; it takes transaction data as input and outputs an ordered list of transactions and a (succinct) representation of the execution results (usually the blockhash).</p><p>The TPU is usually coupled with, but distinct from the Virtual Machine (VM). Blockchain VMs like the EVM, SVM, and MoveVM are high-level language VMs. That means they convert bytecode (compiled intermediate representations) of the high-level languages (Solidity, Rust, Move) to machine executable code. A blockchain VM is fundamentally the same as the more familiar emulation VMs; it&#x27;s a sandboxed environment that allows a non-native instruction set (blockchain bytecode) to be executed on actual hardware (x86/ARM) . </p><p>The TPU, which is usually the subject of interest, subsumes the VM. It is tasked with the management of the entire transaction execution pipeline, including creating and managing instances of the VM. So, as mentioned earlier, these terms are related but distinct. The TPU, specifically, is the focus of this paper.</p><p>There are two types of TPUs: sequential and parallel. A sequential TPU is the easiest to design and implement. Sequential TPUs process transactions first-in-first-out (FIFO). This approach is very simple and incurs no scheduling overhead, but sequential TPUs don&#x27;t take full advantage of the state and trend of computer hardware design.</p><p>Computer hardware has been approaching the limits of single-processor performance since the mid-2000s, and there has been an industry-wide shift towards scaling by increasing the number of cores. If there are no breakthroughs in computing, computers will continue to improve performance by adding more cores as opposed to <a href="https://en.wikipedia.org/wiki/Frequency_scaling">frequency scaling</a>. And in such a world, sequential TPUs will fail to maximize (even consumer) hardware and execution will quickly become a bottleneck.</p><figure class="w-richtext-align-center w-richtext-figure-type-image"><div><img src="https://cdn.prod.website-files.com/667922883d09f8c39ad9defe/6711187620d50d643a9d49b5_AD_4nXdiYMtPg6E8NYPxwoUcKOGUTWeGhBcSVN5t0Lk782nfWbxHG59TaeMBUUhnP1MIc3t7x0kJE6znZ8xWfxBeBfTC3BaeFsa0i-wa6FMsqO7hBI4n9TYbv42umUux8uhjRSXbXXzqZz7n6-faTVO_SiHFKZnp.png" loading="lazy" alt=""/></div></figure><p><em>Figure 1: Microprocessor Trend Data</em> | <a href="https://www.researchgate.net/figure/50-year-trends-in-microprocessors-Source-Karl-Rupp-https-githubcom-karlrupp_fig2_368754141">Source</a></p><p>Figure 1 shows the trend of single thread performance (blue dots) and frequency (green squares), both of which have slowed down and are even seeming to trend slightly downward. The yellow diamonds show the number of “logical cores,” and this number has been steadily growing since the mid-200s. Parallel TPUs are designed to make the most of this trend.</p><p>Parallel TPUs are designed to execute as many non-conflicting transactions concurrently as is possible. An ideal parallel TPU will execute as many transactions that are not dependent on any higher-priority transactions as is possible. As an example, consider the “priority-ordered” set of transactions {tx<sub>1 </sub>&gt; tx<sub>2 </sub>&gt; tx<sub>3</sub>...tx<sub>7 </sub>&gt; tx<sub>8</sub>} with the dependency graph shown below. The arrows indicate dependencies, e.g., tx<sub>4</sub> is a dependency of  tx<sub>1</sub>.</p><p>tx<sub>1</sub> →<sub> </sub>tx<sub>4 </sub>→ tx<sub>5<br/></sub>tx<sub>2<br/></sub>tx<sub>3 </sub>→<sub> </sub>tx<sub>6</sub></p><p>tx<sub>7</sub></p><p>tx<sub>8</sub></p><p><em>Dependency Graph</em></p><p>Assuming each transaction executes within a unit of time, an ideal four-thread parallel TPU would:</p><ul role="list"><li>execute transactions tx<sub>1</sub>, tx<sub>2</sub>, tx<sub>3, </sub>and tx<sub>7</sub> in parallel. </li><li>then transactions tx<sub>4</sub>, tx<sub>6</sub>, and tx<sub>8 </sub>would be executed right after.</li><li>finally, tx<sub>5 </sub>would be executed.</li></ul><p>The challenge of designing and implementing a parallel TPU is designing a <em>concurrency control</em> system that ensures only non-conflicting transactions are executed simultaneously while maintaining priority with minimal overhead. Let’s look at how this is accomplished in practice.</p><h2>How Parallel TPUs are implemented–Concurrency Control–and why it’s necessary.</h2><p>It’s easy to say, “...<em>just execute the transactions in parallel, bro..</em>” without truly understanding why this is such a difficult problem to solve and so I’ll give a simple example to elaborate why concurrency control is necessary when attempting to parallelize access to shared resources.</p><p>Consider the example of a banking database where:</p><ul role="list"><li>accountA has $50</li><li>transaction1 wants to send $50 from accountA to accountB and</li><li>transaction2 wants to send $50 from accountA to accountC.</li></ul><p>Assuming both transactions are allowed to execute in parallel,</p><ul role="list"><li>both transactions will initially read the balance of accountA as $50.</li><li>both transactions will then write zero ($0) to the memory location where the account balance of accountA is stored.<br/>Note that it doesn’t matter if one writes before the other; they both read the balance as $50 and will update it to be (original balance - transfer amount) so both accounts will write 0 to the account balance.</li><li>both transactions will read accountB and accountC’s account balances and write an additional $50 to the memory location where the balances are stored, printing $50 out of thin air.</li></ul><p>This is a simple example but it suffices to show that when there’s concurrent access/modification of shared resources  by uncoordinated transactions, the execution results are non-deterministic (subject to race conditions) and unserializable. A few other potential problems that arise due to a lack of concurrency control are:</p><ul role="list"><li>The<em> lost update</em> problem: When a batch of transactions is executed in parallel, there’s a possibility that a lower-precedence transaction (say tx<sub>k</sub>) overwrites a memory location that a higher-than-k-precedence transaction (say tx<sub>j</sub>) needs to read. tx<sub>j </sub>should have read the values before tx<sub>k </sub>wrote to the location, without concurrency control, there is no way to enforce this behavior.<br/><br/></li><li>The <em>“dirty read” </em>problem: Sometimes transactions are &quot;aborted,” so all the data they’ve written will be rolled back; however, another transaction might have read these (dirty) values before they’re rolled back, compromising the integrity of the database.</li></ul><p>There are more potential problems that can arise from simply parallelizing transactions but they won’t be discussed for the sake of brevity. The important takeaway is that attempting to parallelize execution without additional safety measures  compromises the integrity of the execution results. The solution to this problem in distributed Database Management Systems (dDBMSs) is referred to as Concurrency Control (CC).</p><h2>Concurrency Control and types of Concurrency Control</h2><p>Concurrency control is the process of ensuring that simultaneously executing operations do not conflict. In DBMSs (and, by extension, blockchains), there are two major paradigms of concurrency control: Optimistic Concurrency Control (OCC) and Pessimistic Concurrency Control (PCC).</p><p><strong>Pessimistic Concurrency Control (PCC): </strong>In PCC, the execution of a transaction is blocked if it needs to access a resource that is already in use by another (usually higher priority) transaction. In PCC systems, locks are usually the method of choice to enforce &quot;blocking.” Most PCC systems also require that transactions declare upfront what portions of memory they will read from and/or write to since acquiring locks on the fly will still lead to unserializable execution results. </p><p><strong>Optimistic Concurrency Control (OCC): </strong>In OCC, transactions are <em>attempted</em> on as many processing resources as are available. But instead of writing directly to or reading directly from persistent memory, the transactions usually write to a <em>log</em>. After <em>attempted</em> execution, the transaction is <em>validated</em> to make sure that its execution did not violate any of the database integrity rules. If validation fails, the effects of the transaction are rolled back, and the transaction is rescheduled for execution. Otherwise, the transaction <em>commits,</em> i.e., writes to persistent memory.</p><p>There are many ways to design and implement OCC and PCC systems, but in the following sections, we’ll look at the leading implementations of both paradigms in the blockchain space, starting with the leading OCC implementation: Block-STM.</p><h1>Blockchain-Software Transactional Memory (Block-STM)</h1><p>Block-STM is the result of years of R&amp;D around Transactional Memory (TM) and distributed databases but before we cover Block-STM, it’s beneficial to briefly go over a few concepts, starting with the lifecycle of an Aptos transaction.</p><h2>Primer 1: Brief description of the life-cycle of an Aptos Transaction</h2><p>The lifecycle of an Aptos transaction is similar to that of other blockchains but contains a few nuances specific to Aptos to improve the performance of Block-STM.</p><ul role="list"><li>A transaction starts out as a request from a client; this request finds its way to a full node or a validator node.<br/><br/></li><li>The full node forwards the transaction to other nodes on the network. The nodes keep these transactions in a mempool.<br/><br/></li><li>The mempools of each node call perform signature verifications, minimum account balance verifications, and replay resistance using the <em>sequence number</em>.<br/><br/>The sequence number of an account is the equivalent of a nonce in Ethereum. It keeps track of the number of transactions that have been submitted from that account. If the sequence number of a transaction does not match the sequence number of the account, the node rejects the transaction. This is Aptos’ approach to preventing replay attacks, a type of attack where a malicious entity stores a signed transaction and repropagates it after it has been executed.<br/><br/></li><li>After checks, the leader for the current block fetches a block of transactions from its mempool (the current implementation prioritizes transactions based on fees) and forwards the unexecuted block to other nodes as a proposed ordering of the next set of transactions.<br/><br/></li><li>The leader begins to execute the block concurrently with the forwarding of the block.<br/><br/></li><li>As soon as the leader completes execution, it signs the execution result and forwards it to other validators.<br/><br/></li><li>The validators, who have all received the block, replay it and come to consensus on the execution results.</li></ul><p>An illustration below from the Aptos documentation shows the lifecycle of a transaction.</p><figure class="w-richtext-align-center w-richtext-figure-type-image"><div><img src="https://cdn.prod.website-files.com/667922883d09f8c39ad9defe/671118750e2cfa3114d2e36f_AD_4nXd7CGPXPaLWvHhCsv8ubX45zSvVEDC0lu2-3K2T25FnhfZVVHnKMjsdSMNftrt01KAqeyREb0EAsEpHoo2gE--zybrUc9Yc9N8VRHoCo9wERdg-jAyi2MvSI72kSObZcKNl-eXFeADFXLeaBSaxrdsTFkr9.png" loading="lazy" alt=""/></div></figure><p><em>Figure 2: Lifecycle of an Aptos Transaction | </em><a href="https://aptos.dev/concepts/blockchain"><em>Source</em></a></p><p>The key difference between Aptos’ transaction lifecycle and that of other blockchains is that Aptos blocks are disseminated <strong>before</strong> they’re executed. This is very different from other blockchains, where execution results are communicated with the transactions. This design choice has two effects:</p><ul role="list"><li>It separates sequencing and execution.</li><li>It adds an extra round of messaging.</li></ul><p>Aptos’s decoupling of sequencing and execution lays the groundwork for asynchronous execution, which has been adopted by <a href="https://docs.monad.xyz/technical-discussion/consensus/deferred-execution">Monad</a> and is on the roadmap for Solana as well.</p><p>Another change that is not immediately evident or, more accurately, considered baked into the cake is that in traditional consensus protocols (including Aptos’), the leader always performs a disproportionate amount of work. To combat this, Aptos now uses <a href="https://medium.com/aptoslabs/quorum-store-how-consensus-horizontally-scales-on-the-aptos-blockchain-988866f6d5b0">Quorum Store</a>, which is an implementation of <a href="https://dl.acm.org/doi/abs/10.1145/3492321.3519594?casa_token=GQtprhA8Ko0AAAAA%3AP_FcreghKROwtXI6OQUL437Ix1ilommzaMDz3_8sDpfZXYg1m2NZIkRtcJSzGXurgVisqRSVvn6XHw">Narwhal</a>, to spread bandwidth utilization across all the validators. I briefly go over Quorum Store in the Appendix.</p><p>With that out of the way, the final stop on the road to covering Block-STM is to provide some background by briefly discussing the major developments that preceded Block-STM.</p><h2>Transactional Memory (TM), Software-only Transactional Memory (STM), Calvin, and BOHM.</h2><p>Like I mentioned earlier, Block-STM is built on the back of decades of research. The earliest development came in 1993 in the form of the Transactional Memory (TM) paper, which detailed a hardware-level solution for “transactional memory access.” Software-only Transactional Memory (STM) was formalized in 2005 and it implements the principles of TM using only software. The other two notable developments are the “Calvin” and “BOHM” protocols that address concurrent <em>transactional modifications</em> of distributed databases. We’ll go over a high-level overview of each of them to provide context for Block-STM.</p><h3>Transactional Memory (TM)</h3><p>I find it easier to think of Transactional Memory as <em>transactional memory access</em>. The underlying principle of TM is to allow concurrent programs to modify (read and write) shared memory in a way that is analogous to how database <em>transactions</em> modify a database <strong>without</strong> using locks. More simply put, TM aims to allow concurrent programs to modify shared memory atomically <strong>and</strong> produce serializable results without locks. The reasoning behind the development of TM was that lock-based synchronization techniques incur overhead from managing locks and must be carefully designed to be resistant to <em>priority inversions, convoying, deadlocks, livelocks, etc</em>. TM would not need to worry about these things and would (in theory) outperform lock-based systems.</p><p>The paper proposed a new multiprocessor architecture (not an instruction-set architecture), and the addition of a few instructions that would allow for transactional memory access. The additional instructions allowed programmers to define new <em>read-modify-write operations</em> that performed atomic updates to one or multiple memory locations without needing to lock those memory locations.<br/><br/>A few (less than ten) implementations of TM were developed but TM never had widespread use.</p><h3>Software (only) Transactional Memory (STM)</h3><p>STM is a suite of software-only implementations of the principles of Transactional Memory. The goal is the same as TM: to allow concurrent processes to access shared memory without the use of locks.</p><p>The way STMs usually implement this functionality is optimistic—threads execute with no regard for what other threads are doing but instead of committing their writes directly to memory, the threads record every read and write in a log (abstract data structure).</p><p>At the end of a thread’s execution, the results are validated, i.e., the values that the process read during its execution are compared against the current values at the same memory locations. If the values are different, then the thread rolls back all its writes because a difference in the read-sets implies that one or more concurrent processes modified the memory areas accessed by the process being validated; hence, the execution results are unserializable. STM implementations will reexecute (and revalidate) transactions that fail validation until they pass. STM maximizes concurrency as threads never have to wait to access resources they need but there’s a great deal of wasted work in high-contention use cases.</p><p>Years of research showed that STM implementations perform worse than “fine-grained” lock-based synchronization methods on a small number of processors due to the overhead from managing the log. For these reasons, STM implementations don’t find much use in practice and when they do, it’s for hyper-specific use cases that the implementations are optimized for.</p><h3>Calvin</h3><p>The next major development that preceded Block-STM came in the 2012 “Calvin” paper, where the authors proved that, contrary to popular belief, enforcing a preset order of transactions improved the execution throughput of distributed databases. The general sentiment before Calvin was that enforcing a preset order of execution would reduce concurrency but Calvin firmly established that as false.</p><p>Calvin, like Sealevel, requires that transactions declare upfront all the memory locations that they will access during execution. The rest of the workflow is fairly straightforward. </p><p>Calvin nodes (computers that manage partitions of the distributed database) first decide on the ordering (priority) of a set of transactions  {tx<sub>1</sub> &gt; tx<sub>2</sub>…&gt; tx<sub>n</sub>}  and after coming to consensus on the ordering, Calvin’s scheduling follows a simple rule:</p><p><em>if two or more transactions request access to the same memory locations, the higher-priority transaction must be allowed to access the memory location first</em>. </p><p>A dedicated thread is responsible for lock management and this thread iterates through the serial transaction order and ensures that requests for locks are made in order. When two transactions conflict, they are scheduled sequentially in order of priority but non-conflicting transactions can be scheduled concurrently.</p><p>There is a lot more nuance to Calvin’s design but the key takeaway is that Calvin established the idea that enforcing priority improved throughput.</p><h3>BOHM</h3><p>The next critical development came in 2014—BOHM. Like Calvin, BOHM is designed for distributed databases but the key insight is also easily extensible to blockchains. BOHM uses a Multi-Version Concurrency Control (MVCC) mechanism, which is an auxiliary form of concurrency control that uses a multi-versioned log to manage reads from and writes to shared memory.</p><p>In a nutshell, in MVCC databases, transactions do not directly modify the database; instead, a log holds multiple versions of the database for every transaction, i.e., each memory location is associated with all the values of the transactions that have written to it rather than the most recent write</p><p>You can imagine the multi-version data structure as a two-dimensional table with entries in the form (transaction_version, value). Each slice of this two-dimensional table is a table that contains the version of state for a particular memory location. An illustration that should help get the idea across is shown in figure 3.</p><figure class="w-richtext-align-center w-richtext-figure-type-image"><div><img src="https://cdn.prod.website-files.com/667922883d09f8c39ad9defe/671118760bfe05acea07e990_AD_4nXfpmCtsFTcFOL3vdiBI1N-A8AcC289a4CwACtrBtdQcw1J58u3UosB_6XPq-ivWps816EKiGc-TXthViISRaerFwFf-2MOm0kc5zowUgWeXVB6loccjcYkwv0ddrgg6bVmFxievdTl7jqBbHj3ELi0Jpf1s.png" loading="lazy" alt=""/></div></figure><p><em>Figure 3: Illustration of the Multi-Version Data Structure</em></p><p>Recording in MVCC is similar to but different from that of TM in that in MVCC, for every write to a memory location, a new version of the location specific to that transaction is created (or updated) rather than overwriting the current value. MVCC databases allow for more concurrency than single-version databases, as transactions can read the values written by any transaction at a memory location regardless of how many transactions have written to that location; the tradeoff is an increase in space (memory) complexity.</p><p>BOHM showed that combining multi-version concurrency control with fixed transaction ordering significantly improved the execution throughput of databases while maintaining full serializability. The way BOHM works is briefly explained below:</p><p>BOHM is a two-layered protocol—there is a concurrency layer and an execution layer. As a stream of transactions is fed to the concurrency layer, a single thread orders the transactions by timestamp. The &quot;concurrency threads” are individually responsible for a logical partition of the database. BOHM requires that transactions declare their read and write sets upfront and using this information, each concurrency thread cycles through the ordered set and checks if the transaction writes to its partition. For all transactions that do, the concurrency thread creates an uninitialized placeholder in the log for that transaction. Because individual threads are responsible for partitions of the database, BOHM increases concurrency with intra-transaction parallelism when creating the placeholders. After the concurrency control threads complete their tasks, another set of threads, ”execution threads,” execute the transactions and fill in the placeholders.</p><p>As mentioned earlier, there’s a priority order, so when a transaction needs to read from a memory location, it checks for values written by the lowest priority transaction that is higher than it. For example, if transactions tx2 and tx6 write to a memory location that tx4 needs to read from, tx4 will read the value written by tx2.</p><p>In the event that the placeholder associated with the correct version to read is still uninitialized, i.e., tx2 has not yet written to that location, the execution of the transaction (tx4) is blocked until the transaction that should write to that location (tx2) completes its write. This “reads never block writes” design allows BOHM to be extremely efficient, especially with large workloads, as the greatest cost—constructing the multi-version data structure—is amortized as the workload grows.</p><p>Again, some nuance has been left out but the key takeaway from BOHM’s design is that multi-version data structures allow for increased concurrency at the cost of memory.</p><p>In addition to the four protocols discussed above, a 2017 paper also did some work on STM for blockchains. In the paper, the authors propose the classic STM design with on-the-fly lock acquisition to attempt to prevent concurrent memory access and post-execution validation to identify conflicts.</p><p>The design is uncomplicated: transactions are optimistically attempted, attempting to grab locks as they require them, and validated after. If a conflict is discovered, it is resolved by rolling back the transaction and re-executing it. The design allowed the leader a great deal of freedom in deciding transaction order but the results were non-deterministic so other nodes would likely not arrive at the same execution results unless the leader shared the exact execution path. But the design never saw any adoption, largely because the performance results presented in the paper showed that the protocol was only slightly better than sequential execution and sometimes worse. Block-STM applies the insights from Calvin and BOHM to succeed where the unnamed 2017 protocol failed. With the appropriate background set, we can move on to Block-STM.</p><h2>Block-STM</h2><p>Traditional distributed databases view the insights of Calvin and BOHM as constraints since:</p><ol role="list"><li>enforcing a priority ordering requires some form of consensus between nodes and</li><li>committing each transaction individually (as opposed to block-level) is the norm in transactional databases.</li></ol><p>But both of these properties are inherent in blockchains—blockchain nodes must agree on the ordering of transactions, even if the leader is free to propose as it wishes and commits usually occur at the block level (or at least in batches a la Solana). In essence, what traditional DBs consider constraints are built into Block-STM’s spec and it leverages them to improve its performance.</p><p>This is a breakdown of how it works:</p><p>Similar to Calvin, transactions are packed and sorted into an ordered set by priority: {tx<sub>1</sub> &gt; tx<sub>2</sub> &gt; tx<sub>3 </sub>&gt;...tx<sub>n</sub>}. After ordering, the transactions are scheduled for execution. Like in STM, transactions are “attempted” with all available resources with no regard for conflicts. And like in BOHM, the execution threads don’t read from/write  to memory directly. Instead, they read from or write to a multi-version data structure (that we’ll refer to as just “data structure” going forward). </p><p>Continuing in BOHM’s footsteps, when a transaction (say tx<sub>j</sub>) <em>reads</em> from the data structure, it reads the values written by the most recent <em>version</em> of the lowest-priority transaction that is higher than itself (in this example, tx<sub>j</sub> will read from some transaction tx<sub>i</sub>). For example, if tx<sub>6 </sub>wants to<em> read</em> from a memory location that has been written to by tx<sub>1 </sub>and tx<sub>3</sub>, tx<sub>6 </sub>reads the value written by  tx<sub>3</sub>. Keep this definition of read in mind as it is central to the working principle of Block-STM.</p><p>During the execution of a transaction, its <em>read set</em> is tracked. The <em>read</em> <em>set </em>contains the memory locations and associated values that a transaction read during execution. After a transaction (tx<sub>j</sub>) completes execution, it is verified by comparing its <em>read set</em> with the current values at the memory locations it read from (keeping in mind the definition of read established earlier). </p><p>If there are any discrepancies between the read set and the current values at the memory locations, it implies that during the transaction’s (tx<sub>j</sub>’s) execution, a higher-than-j precedence transaction (say tx<sub>i</sub>) modified one or multiple memory locations that tx<sub>j</sub> read. Based off the preset serialization order, tx<sub>j</sub> should have read the values written by tx<sub>i</sub> so all the values written by tx<sub>j</sub> are <em>dirty</em>.</p><p>But instead of deleting those values from the data structure, they are marked as estimate and tx<sub>j</sub> is scheduled for reexecution. The values are not deleted because it’s likely that reexecuting tx<sub>j</sub> will write the same locations and any (lower-than-j priority) transactions that read values marked as estimate are delayed until tx<sub>j</sub> is re-executed and revalidated. Because of this heuristic, Block-STM can avoid a cascade of aborts and reexecutions that would occur if the data structure were wiped clean of dirty values.</p><p>If there are no discrepancies, i.e., no higher priority transaction than the one currently being validated (tx<sub>j</sub>), write to a memory location in the read set of  tx<sub>j</sub>, then  tx<sub>j</sub> is marked valid but not safe to commit. The transaction is not safe to commit yet because there’s a chance that a transaction of higher priority, say tx<sub>i</sub> will fail validation. </p><p>In such an eventuality, all validated lower-priority transactions than tx<sub>j</sub> (tx<sub>k</sub>, tx<sub>l</sub>, tx<sub>m</sub>, …) need to be revalidated to ensure that they haven’t read from a location written to by tx<sub>i</sub>.Because of this, transactions are not safe to commit until all transactions that come before them in the preset serialization order have been executed and validated.</p><p>When all the transactions in the BLOCK have been executed and validated, execution is complete. That’s a basic (and likely confusing) overview of how BlockSTM works; we’ll go over the process in detail next.</p><h2>Technical details of Block-STM</h2><p>Before we look at the technical details of Block-STM, a few details need to be concretized.</p><p>First, the input to Block-STM is an ordered set called a BLOCK that contains <em>n</em> transactions in the preset serialization order: {tx<sub>1</sub> &gt; tx<sub>2</sub>…&gt; tx<sub>n</sub>}. The goal of Block-STM is to take this BLOCK of transactions and execute them with the most concurrency possible, without breaking the serialization.</p><p>As I mentioned earlier, each transaction is first executed and then validated. If an executed transaction fails validation, the transaction is scheduled for re-execution. To track the number of times a transaction has been executed, each transaction is associated with an <em>incarnation</em> number in addition to the <em>index</em> number. </p><p>You can think of a transaction as being of the form tx<sub>n,i </sub>where n is the index number and i is the incarnation number. So the BLOCK is initially equivalent to {tx<sub>1, 1</sub> &gt; tx<sub>2, 1</sub>…&gt; tx<sub>n, 1</sub>}. The combination of a transaction&#x27;s index and its incarnation make up the <em>version</em> of the transaction. For example, the version of tx<sub>2, 5</sub> is (2, 5).</p><p>Lastly, to support concurrent reads and writes, Block-STM maintains an in-memory multi-version data structure similar to the one discussed in BOHM that stores the latest writes per transaction, and the transaction version for every memory location. Here’s a snippet of the early implementation:</p><p><strong>pub</strong> <strong>struct</strong> <strong>MVHashMap</strong>&lt;K, V&gt; {<br/>    data: DashMap&lt;K, BTreeMap&lt;TxnIndex, CachePadded&lt;WriteCell&lt;V&gt;&gt;&gt;&gt;</p><p>The MVHashMap maps each memory location to an internal <a href="http://web.mit.edu/rust-lang_v1.25/arch/amd64_ubuntu1404/share/doc/rust/html/std/collections/struct.BTreeMap.html#:~:text=Struct%20std%3A%3Acollections%3A%3ABTreeMap1.0.&amp;text=A%20map%20based%20on%20a,work%20performed%20in%20a%20search.">BTreeMap</a> that maps the indexes of transactions that have written to that memory location to the corresponding values. The <a href="https://docs.rs/dashmap/latest/dashmap/struct.DashMap.html">DashMap</a> is responsible for concurrency. It allows thread-safe modification of the BTreeMap. Full details on the data structure implementation can be found <a href="https://github.com/2077-Research/aptos-core-Block-STM-v-Sealevel-/blob/block-stm_v_sealevel/aptos-move/mvhashmap/src/lib.rs">here</a>.</p><p>Next, we’ll look at the actual thread logic.</p><h3>Thread Logic</h3><p>The activities of the worker threads (execution and validation threads) are coordinated by a <em>collaborative scheduling </em>thread that tracks and modifies two ordered sets that we’ll call <em>E </em>and <em>V</em>. <em>E</em> contains all transactions that are yet to be executed and <em>V </em>tracks transactions that are yet to be validated. The implementation of the collaborative scheduler tracks the tasks with atomic counters; more details can be found in Appendix A3.</p><p>Each of the worker threads cycles through the 3-stage loop outlined below: check done, find next task and perform task.</p><h4>Check done</h4><p>If <em>V </em>and <em>E</em> are empty and no other threads are performing a task, then the execution of the BLOCK is complete. Else:</p><h4>Find next task</h4><p>If there are tasks in <em>E </em>and <em>V, </em>an available worker thread will select the task with the smallest index between <em>V </em>and <em>E</em>. i.e., if <em>V</em> contains {tx<sub>1</sub> and tx<sub>3</sub>} and E contains {tx<sub>2</sub> tx<sub>4</sub>}, the worker thread will create and perform a validation task for tx<sub>1</sub>.<br/>The atomic counter mentioned above ensures that both sets will not contain the same transaction. As to why the transaction with the smallest index is chosen, it’s because validating or executing the higher-priority tasks as soon as possible helps to identify conflicts early. This is one of the ways a preset order improves performance.</p><h4>Perform Task</h4><p> If the next task is:</p><ul role="list"><li>an execution task then: execute the next incarnation of tx<sub>n, i</sub>.some text<ul role="list"><li>If, during the execution of  tx<sub>n, i</sub>, an estimate is read, then:some text<ul role="list"><li>abort execution, </li><li>mark all the data written by tx<sub>n, i</sub> as estimate and </li><li>add tx<sub>n, i</sub> to E (with an increased incarnation number, i.e., tx<sub>n, i + 1</sub><br/><br/></li></ul></li><li>else (if no estimates are read):some text<ul role="list"><li>Check if tx<sub>n, i</sub> writes to any locations that the previous incarnation (tx<sub>n, i-1</sub>) did not write to.<br/><br/>some text<ul role="list"><li>If there is a write to a new location, create and add validation tasks for all transactions lower in priority than tx<sub>n, i</sub> that are, not currently in <em>E </em>(i.e. unexecuted) or currently being executed.<br/><br/>This step is necessary because if the execution of tx<sub>n,i </sub>writes to a new memory location that previous incarnations of tx<sub>n </sub>did not, there’s a chance that transactions of lower precedence (i.e., transactions with indexes &gt; n) already read from these memory locations so they need to be checked for validity. Transactions of higher precedence don’t need to be validated because they should have read that location before tx<sub>n</sub> wrote to it.<br/><br/></li><li>Create a validation task for tx<sub>n, i</sub>,<br/><br/></li></ul></li><li>If tx<sub>n, i</sub> does not write to any new locations, then create a validation task for tx<sub>n, i </sub>alone.</li></ul></li></ul></li><li>Loop back to Check done.</li></ul><ul role="list"><li>a validation task, then: validate tx<sub>n, i</sub>some text<ul role="list"><li>if validation succeeds, the thread returns back to check done.</li><li>else (if validation fails), ABORT and:</li></ul></li></ul><ul role="list"><li>Mark all the values written by tx<sub>n,i </sub>as estimate.</li><li>Create validation tasks for all transactions lower in priority than tx<sub>n, i</sub> that are not currently in <em>E</em> and add the validation tasks to <em>V</em>. Transactions lower in priority than tx<sub>n,i</sub> would never read the value written by tx<sub>n,i</sub> because of the definition of a Block-STM read.</li><li>Create an execution task for tx<sub>n, i</sub> with an incremented incarnation number (tx<sub>n, i+1</sub>) and add the task to <em>E</em>.</li><li>Loop back to Check done.</li></ul><p>This loop continues until there are no more tasks in <em>V</em> and <em>E</em>, at which point check done returns done and the most recent version of the data structure is safe to commit to persistent storage. After commitment, a garbage collector frees up the data structure and the transaction processing unit awaits the next BLOCK<em>.</em> Below is an example of how this process would play out in practice:</p><p>‍</p><figure class="w-richtext-align-center w-richtext-figure-type-image"><div><img src="https://cdn.prod.website-files.com/667922883d09f8c39ad9defe/67111875fcd56570faaa9e00_AD_4nXcz2_b1xjQBgXqf97q92B7AIwPZMChzR9rxzU7rh_QPP-gEoJFdqBL5dhmdwZX0iIF2JN7PzCGqDxPsTrsbY3cZcwr2YD1CY3JGnqR2tTgiY34sw_54AyYw-2mzDEmfUwet9jax67dqbjyGK1pH6CZNC-1x.png" loading="lazy" alt=""/></div></figure><p><em>Figure 4: Block-STM execution example</em></p><p>The illustration above is modeled on a four-worker-thread machine. The sets E and V are the execution and validation sets. Nodes (circles) represent transactions and the color of a node helps to identify other transactions that it conflicts with.</p><p>The upper level of the main table shows execution threads and the lower levels show the validation threads. The sets E and V in every column represent the execution and validation sets after the completion of the iteration.<br/></p><ul role="list"><li>As seen in the illustration, E initially contains all the transactions, and V is empty.</li></ul><ul role="list"><li>During the first iteration, the first four transactions are executed optimistically and E and V are updated accordingly.</li></ul><ul role="list"><li>During the next iteration, all four transactions that were executed are validated.<br/>Transaction 4 fails validation due to a conflict with transaction 1 and must be reexecuted.</li></ul><ul role="list"><li>During the third iteration, transactions 4, 5, 6, and 7 are executed.<br/>Transaction 5 conflicts with 4 so it will read values marked estimate and it’s execution is paused until transaction 4 completes execution.</li></ul><ul role="list"><li>During the fourth iteration, transactions 4, 6, and 7 are validated while the execution of 5 is completed.</li></ul><ul role="list"><li>During the fifth iteration, transactions 5, 6, and 7 are validated. 6 and 7 are revalidated because of the reexecution of 5 for reasons explained above. Transaction 8 is also executed.</li></ul><ul role="list"><li>During the next iteration, transaction 8 is validated while 9 and 10 are executed.</li></ul><ul role="list"><li>And during the final iteration, transactions 9 and 10 are validated and the block is marked safe to commit.</li></ul><p>While I’ve described a simplistic workflow, the same process can be applied to any batch of transactions with any dependency structure. </p><p>At its core, Block-STM is simple, and that simplicity, in conjunction with specific properties of blockchains—fixed ordering of transactions, block-level commits, and the safety of blockchain VMs—allows Block-STM to achieve relatively high throughput without enforcing the declaration of read/write dependencies up front. The Block-STM paper contains formal proofs of liveness and safety. And an even more detailed breakdown of Block-STM—the full algorithm (with explanatory comments)—can be found in Appendix A3. Lastly, an implementation of the scheduler in Rust can be found <a href="https://github.com/danielxiangzl/Block-STM/blob/block_stm/diem-move/parallel-executor/src/scheduler.rs">here</a>.</p><p>Next, we’ll look at how Block-STM performs in practice.</p><h2>Block-STM Performance</h2><p>To evaluate Block-STM’s performance, we forked aptos core and slightly modified the already existing benchmarks to evaluate its performance over a range of existing parameters. The machine we used for testing is Latitude’s m4.metal.large, which has 384 GBs of RAM and an AMD 9254 CPU with 24 physical cores. The tests evaluate the execution process from the BLOCK being fetched to the completion of execution and validation of all transactions, but they do not account for committing the results to storage. For the sake of full disclosure, it’s important to mention that the tests use a “FakeExecutor” which doesn’t necessarily execute transactions “correctly”, however this has no bearing on our tests as we’re only evaluating performance.</p><p>The transactions used during this evaluation are simple “P2P” transfers, a simple send between two accounts. The performance metric evaluated was throughput and the independent variable used for presenting the data is threadcount. The parameters used for evaluating performance are block size and number of accounts (a proxy for contention). </p><p>Highly contentious workloads, like 2 accounts, is the type of traffic you’d expect during an NFT mint or when a particular market is “hot.” 2 is the most extreme possibility, as it means all the transactions in the block are between two accounts. Non-contentious workloads like 10000 accounts are the type of traffic you’d expect if the blockchain was used for P2P transactions. The other loads are good proxies for everything in-between.</p><p>Figures 5-8 show the performance relative to the number of threads of Block-STM  with different “levels of contention” and block sizes.</p><p>‍</p><figure class="w-richtext-align-center w-richtext-figure-type-image"><div><img src="https://cdn.prod.website-files.com/667922883d09f8c39ad9defe/67111876cd397a0fa3c2fcf9_AD_4nXfHv5F0LrXotVckivfP2uLVoc6lFiA7t-AUoZ_wtS9Psrr1T5IYwnFuEAolq__yWiL5SsgYVjyq77UMf0U9d9iZ8Dro7XV2mFb0mumHzXTTBiKe9_hUCN_D9lESj_AFn0OV-yxVoGwHW2ajVJw5T0Q6vJn5.png" loading="lazy" alt=""/></div></figure><p><em>Figure 5: Block-STM performance with different number of accounts and block sizes</em></p><p>From the data, it is evident that (as expected), Block-STM performs better in low contention scenarios. However, throughput is only slightly better than sequential execution in high contention scenarios ( 10 accounts). And in completely sequential situations (2 accounts), Block-STM’s performance is significantly worse than sequential execution, (which is also to be expected.)</p><p>From the data, Block-STM’s performance trends lower as the thread count is increased; this behavior is understandable since more threads in a highly contentious environment increase the chance of the account being concurrently written to and the chance of failure.</p><p>The data also shows that diminishing returns set in at different stages depending on the level of contention. In low contention scenarios, performance is mostly linear until around 16 physical cores. And in high contention scenarios, performance trends slightly downward as the number of cores increases, plateauing around 8 physical cores. In very high contention scenarios, performance peaks at 4 cores (the lower limits of our tests, suggesting that performance would be better with even fewer cores). </p><figure class="w-richtext-align-center w-richtext-figure-type-image"><div><img src="https://cdn.prod.website-files.com/667922883d09f8c39ad9defe/67111875abcf65600070a486_AD_4nXcb2GhaWoe3Eg6JtdIl7UiDGx64xdykiwZllgXP3PnG_dUBeI7c8cNprBe4B4LcyxOsgRwJV7ko6Z4KwpnYjF2vy60ZT1Zq8J_8kiGhzv3krNe9Cp2necsXpsunupjZpxjqDrFtXcY9h5y9YKwyzNp58ui_.png" loading="lazy" alt=""/></div></figure><p><em>Figure 6: Block-STM throughput vs blocks size for different levels of contention and number of threads</em></p><figure class="w-richtext-align-center w-richtext-figure-type-image"><div><img src="https://cdn.prod.website-files.com/667922883d09f8c39ad9defe/67111876e1abd9afe75ea22b_AD_4nXdhFWkG490T5IMAnwaVkfeTj0xTwBtaU-PvYPNvJJAw3I00b0csQsQmQCreDYPjmYXOFZTBESeHA9X9h6OviQedFdlpBoiJDcE-OuQFdp1EGjJzRvv0vDZopEao_5D6EuwZBd7pFmsACR1iXMiSNdzg3h8u.png" loading="lazy" alt=""/></div></figure><p><em>Figure 7: Block-STM throughput vs blocks size for different levels of contention and number of threads</em></p><p>‍</p><figure class="w-richtext-align-center w-richtext-figure-type-image"><div><img src="https://cdn.prod.website-files.com/667922883d09f8c39ad9defe/6711187610376e7f83d7fa2e_AD_4nXeYciuF5efux4w_ug8CMrHkB5I84J7bghEHkJo7fZ9qe2bW61eYxY6saeYYh8tVrs-N7pCrlr0BZczawUugAOUuJvRk1UPZJ4FK-cGO4fk9WP33YU-9RJ091ZyWtyqCcMb1xes25CrTsXg4t0ipnmrWvKY5.png" loading="lazy" alt=""/></div></figure><p><em>Figure 8: Block-STM throughput vs blocks size for different levels of contention and number of threads</em></p><p>Figure 8 provides more insight on how performance scales with contention and block sizes. The data suggests that if contention is low, Block-STM’s performance scales almost linearly with core count—throughput roughly doubles when using twice the number of cores. However, performance does not follow the same trend and even seems to head slightly downwards with increase in core count in high contention scenarios.</p><p>In addition, reduction in contention beyond a certain point does not improve performance, evidenced by the fact that there are infinitesimal performance differences between 1000 accounts and 10,000 accounts. In essence, if thread count &gt;&gt; contention, then performance peaks.</p><p>Lastly, the data shows that, relative to block size, the rate of change in throughput is very high. This is likely due to the initial overhead of executing failing transactions. As the runs get longer, more and more transactions ABORT earlier than the initial set amortizing the initial costs, but performance does not improve beyond a block size of 20k.</p><p>The Block-STM paper contains the results of more tests, including one where Block-STM is compared to and slightly outperforms an implementation of BOHM. This is surprising considering BOHM has complete read and write sets of all transactions beforehand but the outperformance is likely due to the overhead of building the multi-version data structure in BOHM.</p><p>Overall, the data gives a reliable indication of BlockSTM’s limits and it’s not a stretch to say that in low contention situations, Block-STM massively outperforms any sequentially executed runtime and also scales almost linearly, making it suitable for large-scale applications like rollups.</p><p>That concludes the analysis of Block-STM, next we&#x27;ll consider the leading PCC-execution runtime—Sealevel—a “marketing term” for Solana’s parallel execution TPU.</p><h1>Sealevel</h1><p>Sealevel is completely antagonistic in design to Block-STM. Sealevel uses lock-based synchronization for concurrency control, but most notably, it requires that all transactions declare upfront what portion of state they’ll be reading from and/or writing to during execution.</p><p>The Solana execution pipeline is further optimized by the use of Single Instruction Multiple Data (SIMD) instructions. SIMD instructions are a parallel (not concurrent) processing technique that performs a single operation over multiple data points.</p><figure class="w-richtext-align-center w-richtext-figure-type-image"><div><img src="https://cdn.prod.website-files.com/667922883d09f8c39ad9defe/671118763ddeb6defe5ddc92_AD_4nXfGljc372_jPb2S4CvLQH-oH16G2HJHaP-6VqkQn84EjRiDdnUMMJQNdHrtS7LySlkEBex1JoqQ7w7I47UVphhA3egbkotmpb4iQxYO-tfJnoOVGJ9TReppkOb-f6sYMklIb_NzY423DNBirJbjv-TIuVwH.png" loading="lazy" alt=""/></div></figure><p><em>Figure 9: SIMD Instructions | </em><a href="https://en.wikipedia.org/wiki/Single_instruction,_multiple_data"><em>Source</em></a></p><p>Discussions about runtime optimizations are beyond the scope of this paper but the idea is that transaction instructions can be sorted based on what programs they call and all instructions that call the same instruction within a program can be batched and executed in parallel with SIMD instructions (again, not concurrently). A quote from Toly might provide some more insight.</p><p>“So, if the incoming transactions that are loaded by Sealevel all call the same program instructions, such as CryptoKitties::BreedCats, Solana can execute all the transactions concurrently <em>in parallel</em> over all the available CUDA cores.”</p><p>In short, Sealevel is designed for maximum speed. The following section will cover how Sealevel works and its performance. But first, a few primers, starting with a brief description of the lifecycle and structure of a Solana transaction.</p><h2>Primer #2: The Structure and Lifecycle of a Solana Transaction</h2><h3>Transaction Structure</h3><p>As mentioned earlier, Solana transactions must declare upfront what portions of state they will access. They do this by listing the accounts that they will use during execution and specifying if they will read from or write to these accounts. A basic Solana transaction is of the form:</p><p>&quot;transaction&quot;: {<br/>    &quot;message&quot;: {<br/>      &quot;header&quot;: {<br/>        &quot;numReadonlySignedAccounts&quot;: ,<br/>        &quot;numReadonlyUnsignedAccounts&quot;: ,<br/>        &quot;numRequiredSignatures&quot;:<br/>      },<br/><br/>      &quot;accountKeys&quot;: [], //a list of accounts that the transaction will use<br/>      &quot;recentBlockhash&quot;: , //a recent blockhash<br/>      &quot;instructions&quot;: [//list of the instructions within the transaction<br/>        {<br/>          &quot;accounts&quot;: [], //expanded below<br/>          &quot;data&quot;: &quot;3Bxs4NN8M2Yn4TLb&quot;, //eBPF bytecode that contains the //instruction logic<br/><br/>          &quot;programIdIndex&quot;: 2, //index of program being called in the //&quot;accountKeys&quot; array<br/><br/>          &quot;stackHeight&quot;: null<br/>        }<br/>      ],<br/>      &quot;indexToProgramIds&quot;: {}<br/>    },<br/>    &quot;signatures&quot;: [] //an array of signatures </p><p>  }</p><p>The ”accounts” list within the instructions list of the transaction is the main focus here. This list contains all the accounts an instruction will use during its execution. The list is populated based on the AccountMeta struct.</p><p>The AccountMeta struct has a list of accounts with three fields.</p><p>Pubkey: The public key (an ed25519 key that identifies accounts) of the program being invoked.</p><p>is_signer: A bool that determines if the account will sign the message</p><p>is_writable: A bool that marks if the account will be written during execution.</p><p>Here is a sample AccountMeta struct named keys.</p><p>&quot;keys&quot;: [<br/>    {<br/>      &quot;pubkey&quot;: &quot;3z9vL1zjN6qyAFHhHQdWYRTFAcy69pJydkZmSFBKHg1R&quot;,<br/>      &quot;isSigner&quot;: true,<br/>      &quot;isWritable&quot;: true<br/>    },<br/>    {<br/>      &quot;pubkey&quot;: &quot;BpvxsLYKQZTH42jjtWHZpsVSa7s6JVwLKwBptPSHXuZc&quot;,<br/>      &quot;isSigner&quot;: false,<br/>      &quot;isWritable&quot;: true<br/>    }<br/>  ],</p><p>The key takeaway here is that from the  AccountMeta struct, the TPU can identify what accounts will be written by a transaction and use that information to schedule non-conflicting transactions.</p><h3>Lifecycle of a transaction</h3><p>The lifecycle of a Solana transaction is largely the same as that of most other blockchains, with some differences, primary of which is that Solana does not have a mempool. Let’s briefly go over how transactions go from creation to commit.</p><ul role="list"><li>After a transaction is created, the transaction is serialized, signed and forwarded to an RPC node.</li><li>When an RPC node receives the packets, they go through SigVerify, which checks that the signature matches the message.</li><li>After SigVerify, the packets enter the BankingStage, which is where they are either processed or forwarded.</li><li>On Solana, nodes are aware of the<em> leader schedule</em>—a pre-generated roster that dictates what validators will be leaders for what slots. A leader is assigned a set of 4 consecutive slots. Based on this information, nodes that are not leader forward transactions directly to the current leader and the next X (two (2) in the agave implementation) leaders. Note that since this is not a consensus-breaking change, some nodes forward transactions to more or less leaders.</li></ul><figure class="w-richtext-align-center w-richtext-figure-type-image"><div><img src="https://cdn.prod.website-files.com/667922883d09f8c39ad9defe/67111875edb26f52fc3cf586_AD_4nXdqPvF3RDZmJXKkoB6BKrBo8t-nhp2Sj_qzE3jjud-WmrF_Ge6RkpQeV5U10Vlw5rUkO4aRpk0HvMx0Xgqd99gr-5BJcbzZ_oYFZ9VnByt8Lg_yNVTvbmaAb-tc4CSEve60sh4FgdSlcm7rsNiVMCngKNU.png" loading="lazy" alt=""/></div></figure><p><em>Figure 10: Client to Leader flow diagram | </em><a href="https://www.umbraresearch.xyz/writings/lifecycle-of-a-solana-transaction"><em>Source</em></a></p><ul role="list"><li>When the leader receives the packets from other nodes, it runs them through SigVerify and sends the packets to the BankingStage.</li><li>In the BankingStage, transactions are deserialized, scheduled, and executed.</li><li>The banking stage also communicates with the <a href="https://solana.com/docs/terminology#proof-of-history-(poh)">Proof-of-History</a> component to timestamp batches of transactions.<em> </em>More on this later.</li><li>By design, Solana blocks are continuously built and forwarded in small portions called <a href="https://solana.com/docs/terminology#shred"><em>shreds</em></a><em>.</em></li><li>When other nodes receive the shreds, they replay them, and when all the shreds that make up a block have been received, validators compare the execution results to the one proposed by the leader.</li><li>Then validators sign a message that contains the hash of the block they’re voting for and send out their votes. Votes can be disseminated as transactions or through gossip but Solana favors treating votes as transactions in a bid to speed up consensus.</li><li>When the quorum of validators is reached on a fork, the block at the tip of that fork is confirmed.</li><li>When a block has 31+ confirmed blocks built on it, the block is <em>rooted</em> and practically impossible to reorg.</li></ul><p>The major difference between the lifecycle of a Solana transaction and that of an Aptos transaction is that in Aptos, transactions are not executed before nodes receive the ordering of the block. Solana and Monad are moving towards an advanced form of this type of execution called <a href="https://github.com/solana-foundation/solana-improvement-documents/pull/5">asynchronous execution</a>, with the final destination being “stateless validator nodes,” but that discussion is outside the scope of this paper.</p><p>Before we discuss the meat of transaction execution, it’s helpful to do a refresher on Proof-of-History concepts since PoH is heavily intertwined with the banking stage process.</p><h2>Primer #3: Proof of History and the Banking Stage</h2><p>Solana’s Proof of History is a “decentralized clock.” PoH’s working principle is basef on recursive SHA-256 hashes. It uses the cycle to proxy the passage of time.</p><p>The basic idea is that a SHA-256 hash: </p><ol role="list"><li> is pre-image resistant, i.e., the only way to compute a hash (h) of a message (m) is to apply the hash function H to m, and</li><li>takes exactly the same amount of time on any high-performance computer.<br/></li></ol><p>Because of these two properties, nodes recursively performing SHA-256 hashes can agree that an amount of time has passed based on the number of hashes computed. Additionally, verification is highly parallelizable because each hash can be checked against the next one without relying on the results of the previous hashes. Because of these properties, PoH allows Solana nodes to agree on the passage of time without the need for synchronization or communication. The <a href="https://github.com/solana-labs/solana/blob/9488a73f5252ad0d7ea830a0b456d9aa4bfbb7c1/entry/src/poh.rs#L82">PoH hash calculation </a>snippet is shown below:</p><p>  <strong>self</strong>.hash = hashv(&amp;[<strong>self</strong>.hash.as_ref(), mixin.as_ref()]);</p><p>mix_in is an arbitrary piece of information (in this context, transaction hashes) that is appended to the previous hash to assert that the event represented by mix_in occurred before the hash was computed, essentially timestamping the event.</p><p>The other PoH-specific concepts relevant to understanding the BankingStage are:</p><ol role="list"><li>ticks: a tick is a measure of time defined by X (currently 12,500) hashes. The tick hash is the 12500th hash in the chain.<br/><br/></li><li>entry: an entry is a timestamped batch of transactions. Entries are called entries because they’re how Solana transactions are committed to the ledger. An entry is composed of three components:some text<ol role="list"><li>num_hashes: the number of hashes performed since the previous entry.</li><li>hash: is the result of hashing the hash of the previous entry num_hashes times.</li><li>transactions: is a list of transactions that were executed before hash was generated. It can be empty.</li></ol></li></ol><p>There are two types of entries: tick entries and transaction entries. A tick entry contains no transactions and is made at every tick. Transaction entries contain a batch of non-conflicting transactions.<br/></p><ol start="3" role="list"><li>slot: A slot is 64 ticks or 800,000 hashes. A block must contain 64 ticks and the last entry to the block must be a tick entry.</li></ol><h3>Entry Constraints</h3><p>There are quite a number of rules that determine if a block is valid, even if all the transactions it contains are valid. You can find some of those rules <a href="https://apfitzge.github.io/posts/road-to-bankless/">here</a>, but the rule relevant to this report is the <em>entry </em>constraint. This rule dictates that all the transactions within an <em>entry</em> must be non-conflicting. And if an entry contains conflicting transactions, the entire block is invalid and rejected by validators. By enforcing that all the transactions in an entry be non-conflicting, validators can  replay all the transactions within an entry in parallel without the overhead of scheduling.</p><p>However, <a href="https://github.com/solana-foundation/solana-improvement-documents/blob/main/proposals/0083-relax-entry-constraints.md">SIMD-0083</a> proposes the removal of this constraint, as it constrains block production and prevents asynchronous execution on Solana. Andrew Fitzgerald discusses this constraint and a few others in this post on what he thinks are the next steps Solana needs to take on its journey to asynchronous execution.</p><p>To be clear, this constraint does not completely dictate how transactions are scheduled because executed transactions don’t have to be included within the next entry, but it is an important consideration for current scheduler designs.<br/></p><p>With all that out of the way, we can discuss the meat of transaction execution—Solana’s BankingStage.</p><h2>The Banking Stage</h2><p>The BankingStage module houses Solana’s TPU and a lot of other logic for processing transactions. The focus of this report is on the scheduler but a brief overview of the BankingStage will be discussed to provide some necessary context.</p><h3>Overview of the Banking Stage</h3><p>The banking stage sits between the SigVerify module and the BroadcastStage, with the PoH module running in parallel to it. As discussed earlier, SigVerify is where transaction signatures are verified. The BroadcastStage  is where processed transaction data is disseminated (via <em>Turbine</em>) to other nodes on the network and the TPU_Forwarding module is responsible for disseminating sanitized transaction packets to leader nodes.</p><figure class="w-richtext-align-center w-richtext-figure-type-image"><div><img src="https://cdn.prod.website-files.com/667922883d09f8c39ad9defe/6711187b9b9eb293805b5d4b_AD_4nXcLHSGUHhTAyocE-6pURpsgn_SCzuiXXMmjc4lvbz1698uU_xNr4MTkY79guFCtuckQRF1tRmyqJgB3BX4qG_dwiv6CzeRc0fd-F3monv0YzXRNgQAl_JUczmxdu2GAQkglQF5KzU90gUQ0yTSj0Jl9u6Q.png" loading="lazy" alt=""/></div></figure><p><em>Figure 11: Solana Transaction Pipeline | </em><a href="https://apfitzge.github.io/posts/solana-scheduler/"><em>adapted from</em></a></p><p>In the BankingStage, transaction packets from SigVerify are buffered and received by the appropriate channels. Voting transactions are receieved at the end of two channels, the Tpu_vote_receiver, and gossip_vote_receiver while non-votes are received by the non_vote_receiver. After buffering the packets are  forwarded or  “consumed” depending on the leader schedule. If the node is not the leader or due to be leader shortly, the sanitized packets are forwarded to the appropriate nodes. When the node is leader, it “consumes” the transaction packets, i.e., the packets are deserialized, scheduled, and executed.</p><p>Scheduling is the main focus of this paper and it will be expanded on later. The execution stage is relatively straightforward; after a batch of transactions is scheduled, the TPU will:</p><p>‍</p><ul role="list"><li>run checks: the worker thread checks that the transaction:some text<ul role="list"><li>hasn’t expired; by checking that the <em>blockhash</em> it references is not too old.</li><li>hasn’t been included in a previous block.</li></ul></li><li>grab locks: the worker thread attempts to acquire the appropriate read and write locks for all the transactions in the batch. If a lock grab fails, retry the transaction later.</li><li>load accounts and verify that signers can pay fees: the thread checks that the programs being loaded are valid, loads the accounts necessary for execution and checks that the signer can pay the fees specified in the transaction.</li><li>execute: the worker threads create VM instances and executes the transactions.</li><li>record: the execution results and the transaction ids sent to the PoH thread, which generates an <em>entry</em>; <em>entries </em>are also sent<strong> </strong>to the BroadcastStage during this step.</li><li>commit: If recording succeeds, the results are committed, updating the state.</li><li>unlock: Remove locks from accounts.</li></ul><p>‍</p><p>That’s a complete overview of the BankingStage. Next, we’ll dive deep into how scheduling works in the Solana TPU. This portion has had many significant changes, but for the sake of brevity, we’ll discuss only the two most recent implementations: the Thread-Local Multi-Iterator and the Central Scheduler.</p><h2>Thread-Local Multi-Iterator</h2><p>In the Thread-Local Multi-Iterator implementation, consumed transactions packets sit in the non_vote_receiver channel mentioned earlier. Each of the non-vote threads pulls transactions from the shared channel, sorts them based on priority and stores the ordered transactions in a local buffer. </p><figure class="w-richtext-align-center w-richtext-figure-type-image"><div><img src="https://cdn.prod.website-files.com/667922883d09f8c39ad9defe/671118766a6f578ca4b018eb_AD_4nXe1CZBIo9h_lIDX3R7hSEHoF0lJKerhQapVz3rQFaG9Dd2gfO5FlmMvrwoTPG6Hnld5A-qXTy91XfjD3iC11v84TJu97sO7gTar1tdNbZflQoJ_DjnvVuHpPudZUWETFtevNOFi5GDx04yT-SMyk2gE1xe_.png" loading="lazy" alt=""/></div></figure><p><em>Figure 12: TLMI implementation of Banking Stage </em></p><p>The local buffers in the TLMI are double-ended priority queues to allow for adding new high-priority transactions while removing the low-priority ones with minimal time complexity. Each thread then “marches” a <em>multi-iterator</em> through its buffer to create a batch of (128) non-conflicting transactions. </p><p>A multi-iterator is a programming pattern that runs multiple iterator objects through an array; the iterators “select” items from the array based on a decision function. The multi-iterator concept can be abstract so instead of explaining it, here is an example that shows how Solana’s TLMI works:</p><p>Imagine a set of ten transactions  [tx<sub>1</sub> &gt; tx<sub>2</sub> &gt; tx<sub>3 </sub>&gt;...tx<sub>10</sub>]  with the dependency graph below:</p><p>tx<sub>1</sub> →<sub> </sub>tx<sub>4 </sub>→ tx<sub>5<br/></sub>tx<sub>2<br/></sub>tx<sub>3 </sub>→<sub> </sub>tx<sub>6</sub></p><p>tx<sub>7</sub>→<sub> </sub>tx<sub>9</sub></p><p>Tx<sub>8 </sub>→<sub> </sub>tx<sub>10</sub></p><p>Assuming the TLMI created batches of four, with this set of transactions, the TLMI would:</p><ul role="list"><li>select tx<sub>1</sub>, then tx<sub>2</sub>, then tx<sub>3</sub>,<sub> </sub>and finally tx<sub>7 </sub>for the first batch.<br/>tx<sub>4</sub>, tx<sub>5 </sub>and tx<sub>6</sub> would be skipped because they conflict with already selected transactions.</li><li>the next iterator would select tx<sub>4</sub>, tx<sub>6</sub>, tx<sub>8</sub>, and tx<sub>9</sub> and</li><li>the third iterator would select tx<sub>5</sub> and tx<sub>10</sub>.</li></ul><p>‍</p><figure class="w-richtext-align-center w-richtext-figure-type-image"><div><img src="https://cdn.prod.website-files.com/667922883d09f8c39ad9defe/671118768bcb5d6d7ae1a47b_AD_4nXelTE-1ii4BvZFW1MwJuPkdBSD1rQBG4N4NPcDu1N8ijE-cQXZ40XQq5UhbqcAcph6rhIsUAcTJHvl_aeC2D2gNHm6Mj0miuQazz5hZ38cGXqhyZ7Kj3O248P85NbTXzOUrjviL4Ear5CYewyel0t2rU3NI.png" loading="lazy" alt=""/></div></figure><p><em>Figure 13: TLMI Scheduling | </em><a href="https://www.helius.dev/blog/all-you-need-to-know-about-solanas-v1-18-update#the-current-implementation"><em>adapted from</em></a></p><p>Each iterator would follow this process to create a batch of non-conflicting transactions and because of the use of locks during execution, transactions are guaranteed to execute safely regardless of what other threads are doing.</p><p>However, this design led to a lot of problems.</p><h4>The problems with the TLMI implementation</h4><p>The major problem with the TLMI approach is that each thread is isolated from the others.</p><p>Because each of the worker threads <em>independently </em>pulled transactions from the shared channel, the distribution of transactions between threads was roughly the same. So even if the threads create a batch of transactions with no intra-thread conflicts, there could still (and likely would) be inter-thread conflicts, with the problem becoming worse as contention increases.</p><p>In addition, because of the TLMI’s design, there is a high tendency for priority inversion—since two conflicting transactions cannot be in a batch, high-priority transactions that happen to conflict with a higher-priority transaction will not be scheduled until the next batch at the very least and lower-priority transactions would.</p><p>These problems could be approached by reducing the batch size (from 128) but that would create bottlenecks elsewhere, like increased context switching by threads. Instead, the scheduling algorithm was redesigned completely, leading to the Central Scheduler implementation.</p><h2>The Central Scheduler</h2><p>The Agave 1.18 client addresses the “central” problem of Solana’s BankingStage by introducing a “<em>Central Scheduler</em>” very similar in spirit to Block-STM’s <em>Collaborative Scheduler</em>. The <em>Central Scheduler</em> uses a new thread (in addition to the previous six) that performs the task of global scheduling. The way it works is relatively straightforward:</p><p>Just like before, voting transactions are handled by voting threads but now <strong>all</strong> none vote transactions go to a dynamically updated buffer. Since this buffer is fed directly from SigVerify, it has a <em>global</em> view of priority as opposed to the local buffers in the TLMI design.</p><p>‍</p><figure class="w-richtext-align-center w-richtext-figure-type-image"><div><img src="https://cdn.prod.website-files.com/667922883d09f8c39ad9defe/67111876152300a64f84b0da_AD_4nXfYeXwkNSYeZb_g-WRrEwJe_8XvxezHX7ugahET8KslUJXeNSyx-6AfZ1-zQJNuxkiJ9OuLqpgee-yHrrkC8D97b3VywIGcFcaRuATUh0ycufV4a6UiarkVsVM-J5ikWtOJZrpjQlSfeo3qJT6IbUOzqtw.png" loading="lazy" alt=""/></div></figure><p><em>Figure 14: Central Scheduler implementation of Banking stage</em></p><p>The second major change in the Central Scheduler update is the addition of a priority graph.  The “prio-graph” is a lazily populated Directed Acyclic Graph (DAG) that allows efficient identification (and visualization) of transaction dependencies. The Central Scheduler scans through a batch of transactions and populates the prio-graph by representing transactions as nodes and using edges (graph-theory term for a directed line) to represent dependencies.</p><p>Figure 12 below shows a sample prio-graph. The nodes (circles) represent transactions, the alphabets represent priority (A is of higher priority than B), numbers represent the accounts used by the transactions and arrows represent dependencies.</p><figure class="w-richtext-align-center w-richtext-figure-type-image"><div><img src="https://cdn.prod.website-files.com/667922883d09f8c39ad9defe/671118767d6d3aa19896a0a6_AD_4nXdnTxyjg1xC3Gck3ywKxpCpp70gFzESqkppAwoUlkKlJS8ysce1omwDX5GCpjxdG_I3ddIlGjMBe-i2co-n4e6X97XwZBjVKAdkKK2p6vWUITotyp4Dik0gd9e5-wmVpmMrjIHZZV1Aaft8KudTwRu0KOTO.png" loading="lazy" alt=""/></div></figure><p><em>Figure 15: Sample prio-graph</em></p><p>The prio-graph is necessary because Sealevel executes transactions in batches. If transactions were executed ad hoc, there’d be no need for a prio-graph, but since transactions are executed in batches<sup>[1]</sup>, a prio-graph is necessary to prevent unschedulable transactions. An example that shows the problem is explored below.</p><p>Using the prio-graph in Figure 15 as an example, if the <em>Central Scheduler</em> wanted to schedule transactions A through F, it would schedule all of them on one thread. This might seem counterproductive because, at the very least, A and B do not conflict, but naively scheduling the transactions on different threads will lead to unschedulable transactions down the line. The reason is explained below:</p><p>If the transactions are scheduled without a prio-graph (we’ll speed through this by moving in batches of two, but it suffices to show the problem):<br/></p><ul role="list"><li>A and B would be scheduled first and on independent threads since they don’t conflict.</li></ul><figure class="w-richtext-align-center w-richtext-figure-type-image"><div><img src="https://cdn.prod.website-files.com/667922883d09f8c39ad9defe/6711187689ff2821639042a2_AD_4nXfJqI2XGcULe7minaq5jQ4eRXd55cPR-LPIEwr7-8Nhz8JyyhllgoqwcFyQGvPiey-XmpxastgjNy5eZweT3nBq6Ly7D2sOrE4Q5qpvYGg6KEOFOeixEt_HnbiBEMhglnABz6EOglXv0d1ZhAnDcFSSWLRQ.png" loading="lazy" alt=""/></div></figure><p><br/><em>Figure 16: At T1</em></p><ul role="list"><li>Then C and D would be scheduled behind A since they both conflict with A and only A.</li></ul><figure class="w-richtext-align-center w-richtext-figure-type-image"><div><img src="https://cdn.prod.website-files.com/667922883d09f8c39ad9defe/6711187621dfe096b09ee7ab_AD_4nXfH18a60XXnpjN4u39Po_Z5gkhJl6tZ69e2mCfwpO8EG7bP2IL8H_WP9z5XU0VrRrtR90hzfYxp5b-jhiI6WW6VGkifOIfvTb44XwTycgP-bGG_SFgIQkratKp1i6133Vam9m2yH5gJT9RElOrNnq34BqT4.png" loading="lazy" alt=""/></div></figure><p><br/><em>Figure 17: At T2</em></p><ul role="list"><li>E will be perfectly schedulable on thread 1 but F will be unschedulable as it will conflict with both threads. Thread 1 holds the locks for account 3 and thread 2 holds the locks for account 7 so F can only be scheduled after both threads have completed execution.</li></ul><figure class="w-richtext-align-center w-richtext-figure-type-image"><div><img src="https://cdn.prod.website-files.com/667922883d09f8c39ad9defe/67111876ca09c245e4c12b62_AD_4nXcrHCUFHM9niVVlwU61MqhXz9gNagjyWQjbLM0cLTGiAiD-hEz1BVTtVrSFCw3J2oyKskWJ7zPqMs4EpUQ4mJ0hX8SKetB75W3A0yq-THZARhljC0LjWdpg_LyCRcaF1L_oqBvehnzeDRji7ewF_isECPpp.png" loading="lazy" alt=""/></div></figure><p><br/><em>Figure 18: At T3</em></p><p>It is because of these types of conflicts that the scheduler needs a prio-graph when scheduling transactions. The combination of the global priority queue and prio-graph allows the <em>Central Scheduler</em> to schedule transactions in a manner that ensures that there are no inter-thread conflicts and avoids priority inversions.</p><h3>How the Central Scheduler works</h3><ul role="list"><li>Transactions arrive from the SigVerify channel and are split depending on whether or not they are vote transactions.</li><li>The non-vote transactions move to a buffer, where they are sorted based on priority.</li><li>The Central Scheduler scans the highest priority transactions and filters them before “inserting” them into the prio-graph in batches.</li><li>When the target size is reached or the global queue is empty, the central scheduling thread begins to schedule transactions to the worker threads in a manner that avoids inter-thread conflicts.</li><li>The batches of scheduled transactions are executed just as before.</li></ul><p>The above is a basic overview of what the <em>Central Scheduler</em> does. Now for the details.</p><p>Just like in the TLMI implementation, transaction packets coming from SigVerify sit in the same 700,000 capacity buffer. However, in the Central Scheduler, when the node is leader, the packets are fed into another buffer with the same 700,000 capacity called the TransactionStateContainer<em>. </em>The<em> </em>TransactionStateContainer has two components:</p><ul role="list"><li>a double-ended priority queue, specifically a MinMaxHeap<em> </em>with a <em>bubble-up</em> feature that sorts transactions based on priority.</li><li>a HashMap that maps the transaction ids to a “transaction state.”<br/>There are two possible states that a transaction can be in:some text<ul role="list"><li>unprocessed: transaction can be scheduled.</li><li>pending: transaction is available for scheduling and processing.</li></ul></li></ul><p>To create a batch of transactions, the Central Scheduler takes the top 2048 transactions from the TransactionStateContainer, 128 at a time and applies a PreGraphFilter to each transaction in the batch of transactions. </p><p>The PreGraphFilter</p><ol role="list"><li>Sends the transaction to the bank to check if the transaction has been processed and</li><li>checks that the transaction can pay the transaction fees, and deducts them from the fee-paying account.</li></ol><p>Transactions that pass the checks are inserted into the prio-graph. The prio-graph is created by checking for dependencies between a transaction and the next highest priority transaction <strong>per account </strong>i.e, the graph builder checks for conflicts on every single account that the transaction touches<strong>.</strong> This is implemented by tracking in a HashMap what transactions last touched what accounts. This allows the graph builder to quickly identify dependencies.</p><p>Once the prio-graph has been completely built, transactions go through a pre_lock_filter. The pre-lock filter is currently unimplemented so it currently does nothing. But the ideal logic flow is to allow transactions that pass the pre_lock_filter to be scheduled one by one on the appropriate threads.  A small optimization is that if a transaction does not conflict with any thread or any other transactions that could necessitate executing a chain in sequence, the transaction is assigned to the thread with the least amount of work (in terms of CUs). Transactions are scheduled until the prio-graph is empty or every thread either:</p><ul role="list"><li>reaches the max compute units assigned to it (currently 12 million CUs), or </li><li>has a batch of 64 transactions assigned to it.</li></ul><p>If any of these conditions is met, the worker thread(s) begins executing the batch. When it finishes, it communicates with the central scheduler thread and work is scheduled for it.</p><p>This process is repeated until the node is no longer leader, at which point the banking stage is said to be over. I’ve left out the details of committing and forwarding as they’re not relevant to this discourse but the core idea has already been discussed. </p><p>That is a complete overview of how the Central Scheduler approaches parallelization. It is, in some aspects, a significant improvement over previous Sealevel iterations as it prevents intra- and inter-thread conflicts. Ceteris paribus, there should never be a failed lock grab, (which was the main cause of non-linear performance degradation with the other iterations). In addition, since there are no more inter-thread conflicts, the <em>Central Scheduler</em> (theoretically) allows the use of as many non-vote threads as are available for execution.</p><p>The biggest trade-off of the <em>Central Scheduler</em> is the overhead incurred during scheduling. Compared to Block-STM or even the TLMI, it spends a decent amount of time scheduling transactions and has less to spend on execution.</p><p>That wraps up the discussion of the design of the CS and, by extension, Solana’s TPUs. Next,  we’ll examine their performance.</p><h2>Sealevel Performance</h2><p>There are quite a number of Solana benchmarks in the wild. But for the purpose of this report, we modified the agave client codebase and ran the “banking-bench” tests. Links to the repo as used and instructions to reproduce the results can be found in the appendix. The tests were run on the exact same machine used to evaluate Block-STM—Latitude’s m4-metal-large,<strong> </strong>which has 384 GB of RAM and an AMD EPYC 9254 CPU with 24 physical and 48 logical cores. The tests are the exact same as those used to evaluate Block-STM as well. The results are shown below.</p><h3>TLMI</h3><p>The data for the TLMI runs are shown in figures 18-21 below. The TLMI has a maximum throughput of 137k TPS observed on 8 threads at a block size of 10k and account contention of 10k (essentially embarrassingly parallel). The TLMI also performs relatively well in very contentious scenarios, processing over 15k TPS for completely sequential workloads.</p><p>The performance trend  of the TLMI is relatively less steep (it reaches about half of its maximum throughput with an account contention of 10), i.e., the performance in contentious and non-contentious situations is similar. This implies that the TLMI will not experience significant performance degradation in contentious situations.</p><p>The data contains a few surprising facts. One of which is that with a block size of 1k (figures 19 and 20), performance peaks with 4 threads regardless of contention. With a block size of 10k (figures 21 and 22), performance consistently peaked at 8 threads and even slightly degraded as core count increased. </p><p>This behavior is understandable for threadcounts 24 and 32, as the machine used during testing only has 24 physical cores and there are some other processes running in the background, e.g., PoH. But the behavior is unexpected for threadcounts 12, and 16 and seems uncorelated to contention. There’s not enough data to assert a trend but it would seem the TLMI’s peak throughput is correlated to block size. This suggests that there’s still room for growth in regards to optimizing the performance of the TLMI. </p><p>But overall, the performance of the TLMI is a highly performant TPU that performs well in both contentious and non-contentious environments.</p><p>‍</p><figure class="w-richtext-align-center w-richtext-figure-type-image"><div><img src="https://cdn.prod.website-files.com/667922883d09f8c39ad9defe/6711187608ad02195603ef66_AD_4nXcmQGIC_RGqo-Mcm1Un2gbJvJVq4WvuXM1pWIJAatDbNVcBd7WMc1Nlz_8NCs9kKXEPAkmsKZfUBc-QoYs-fLl3fQyvEGIk-QcILsQuSZ5JQOOQT212J-mlgaKwfflFohU1fM_IoTpg2yhcA-XkE2yEv3U.png" loading="lazy" alt=""/></div></figure><p><br/><em>Figure 19: Sealevel-TLMI performance plotted against threadcount (Blocksize 1000)</em></p><figure class="w-richtext-align-center w-richtext-figure-type-image"><div><img src="https://cdn.prod.website-files.com/667922883d09f8c39ad9defe/671118767d6d3aa19896a0a3_AD_4nXfI4DFw2HUM5MOManjl6OmeRUOXNMtnNJMxe9rkrhCa2O_zdOzIaB4K0DmTkuIwpI2fP_yYTSAYzhVY4MCgbg8X8jHLYjZp1W40I0uAlpOrxU_DNy0jDr9cjrNhcsQqtLMSQR9_RTZZhc8q1WhDQlDbBilw.png" loading="lazy" alt=""/></div></figure><p><em>Figure 20: Sealevel-TLMI performance plotted against threadcount (Blocksize 1000)</em></p><figure class="w-richtext-align-center w-richtext-figure-type-image"><div><img src="https://cdn.prod.website-files.com/667922883d09f8c39ad9defe/67111876cb7b1c725905c11f_AD_4nXcg60tpclE98z9eF8T6mE8YDl6kVTqZp7j4OXcnhYS7qX0wnVabJSc-wSZ4QsU2hDK6VqTg4TYVd9KFvHT7t5-9YR2e5qqhQUnPWv7cmTOfGjY4eGebMNd4AJwLM3M1NgpQi5iCAuxlXQSQ44pEfzIShKwm.png" loading="lazy" alt=""/></div></figure><p><em>Figure 21: Sealevel-TLMI performance plotted against threadcount (Blocksize 10000)</em></p><figure class="w-richtext-align-center w-richtext-figure-type-image"><div><img src="https://cdn.prod.website-files.com/667922883d09f8c39ad9defe/671118762ee74d65f918cea0_AD_4nXc4QO3nFQelZjuKGmiaXZ1h5q4YGl_FeYfFTlRH9o4S8CG4dem_aCP-3_6R49AU7W0fr9oH3SYhKCMptStRiIEfvMdkUWDoQyFU6bJjLpx21-ReC97_0-z-2H0Gd3uIQ6RaYWMQBDh82aGbiAHGkgzXGkgp.png" loading="lazy" alt=""/></div></figure><p><em>Figure 22: Sealevel-TLMI performance plotted against threadcount (Blocksize 10000)</em></p><h3>Central Scheduler</h3><p>The decision was made to exclude the performance of the central scheduler because it was found to be inconsistent. Our tests saw it peak around 107k TPS with 10k account contention and as high as 70k TPS on a completely sequential workload. In other tests, we get 30k TPS on completely sequential workloads and ~90k TPS with an embarrassingly parallel workload.<br/><br/>These results are consistent “within” the tests and rerunning the tests will produce the same results. But the inconsistency across tests suggests that there are still bugs in the implementation that need attention. Because of that, we decided to leave the evaluation and presentation of the results to a future study.</p><p>A few conclusions that we can draw regardless are that relative to the TLMI, the performance will be better in highly contentious scenarios and (slightly) worse in low-contention scenarios. Aside the extra overhead of scheduling, the Central Scheduler currently uses only one thread to preprocess data, while the TLMI uses all available threads which will certainly reduce overall performance.</p><p>With Sealevel completely discussed, we can move on to the highlight of the report.</p><h1>Block-STM vs. Sealevel</h1><p>Both TPUs have been thoroughly discussed and evaluated; it’s time to compare them. We’ll start with the fee market structures that both TPUs enable and move on to performance.</p><h2>Fee-Markets</h2><p>Appropriately pricing blockspace is a difficult challenge to solve. To put it more eloquently:<br/><br/></p><p><em>“One of the most challenging issues in blockchain protocol design is how to limit and price the submission of transactions that get included into the chain.”</em></p><p><em>— </em><a href="https://github.com/ethereum/research/blob/master/papers/pricing/ethpricing.tex"><em>Vitalik Buterin</em></a><em> </em></p><p>A proper discussion on fee markets would fill up its own paper. But on the subject of comparing Block-STM and the Sealevel it is relevant to mention that due to the designs of both TPUs, the fee market structures are completely different. Specifically, Sealevel has <em>pseudolocal</em> fee markets, while Block-STM’s fee markets are <em>global</em>.<br/><br/>In local fee markets, contention for a portion of state does not affect other portions of state, while in global fee markets, the cost of blockspace depends on general demand for blockspace, irrespective of what portion of state a transaction is accessing. </p><p>Local fee markets are clearly more ideal from every point of view: </p><ul role="list"><li>for users, the UX is superior because users are not forced to compete with transactions accessing portions of state they are not accessing.</li><li>for validators and the network (ceteris paribus), local fee markets make for more efficient use of block space as there will be fewer failed transactions.</li></ul><p>In short, local fee markets are superior but they are very hard to implement. I’ll explain next the fee-market structure of each TPU.</p><h3>Block-STM Fee-Markets</h3><p>As mentioned above, Block-STM’s fee markets are global. Ironically, this is a consequence of the design choice that is responsible for Block-STM’s performance boost—the predefined ordering of transactions.<br/><br/>As discussed when analyzing Block-STM’s design, when Block-STM wants to execute a BLOCK of transactions, it pulls an already-ordered set of transactions from its mempool (or Quorum Store in the new design) and executes the BLOCK. Because the BLOCK had already been constructed prior to execution and inclusion in the block was based on gas fees, securing inclusion in the block is solely dependent on gas fees.</p><p>For example, in the event of a highly contested NFT mint where the highest priority transactions are competing for the same account, most, (if not all) the transactions packed into the BLOCK will compete for the same state. This will:</p><ul role="list"><li>significantly degrade the performance of Block-STM (since it performs poorly in high contention situations).</li><li>prevent the inclusion of non-conflicting transactions and unnecessarily drive up the price of blockspace, as seen on networks with single-threaded TPUs like Ethereum and other EVM-compatible chains. </li></ul><p>We’re more focused on the latter point in this section and what it implies—that all users on Block-STM networks will be forced to compete with each other for blockspace. Considering historical data on networks like Ethereum, blockspace could become unnecessarily expensive during times of high activity. And during sustained activity, fees will be higher for all users.</p><p>This is a problem, as it suggests that blockspace on BSTM networks must be cheaper and more abundant than on a Sealevel network for users to pay similar amounts in fees.</p><h3>Sealevel Fee-Markets</h3><p>All iterations of Sealevel have always had some form of fee market locality but the fee markets were barely functional for the reasons discussed above (local view on priority). Post-<em>Central Scheduler,</em> Sealevel’s fee markets are functional and &quot;pseudolocal.&quot; Transactions bidding for inclusion and priority only have to bid against other transactions contesting the accounts they want to access.<br/><br/>For example, if transactions tx1 through tx4 are all bidding for the same portion of state, tx5 doesn’t have to bid against all the previous transactions. In the current scheduler design, it will be scheduled second, while transactions tx2 through tx4 are all queued behind tx1. This is a very simple example but it holds true for any batch of transactions with any type of transaction dependency.</p><p>Just for clarity, it’s relevant to mention that there is still (and will always be) some global pricing of blockchain because of block size limits (currently 48 Million Compute Units (CUs)). Transactions that don’t conflict with other transactions in the block may never make it into the block simply because their absolute priority is not high enough. But once a transaction can pay the “minimum inclusion fee (𝚽),” fee-markets are local.</p><p>Solana further improves its fee-market locality by constraining the maximum number of CUs that can be taken up by a single account in a block (the current implementation is 12 million CUs).  This ensures that transactions competing for highly contested accounts cannot prevent the inclusion of other transactions, even if the former set of transactions, for some reason, executes much faster. The data collected during this study suggests that there might be benefits to lowering the limits relative to blockspace but that’s a discussion for another day.</p><p>To summarize, Sealevel implicitly enables local fee-markets and locality is reinforced by the account limits.</p><p>Next we’ll move on to actual throughput from both TPUs.</p><h2>Performance</h2><p>With all the necessary background discussed, the time has come to answer the question of which TPU performs better. Figures 24 and 25 show the performance of both TPUs for different at blocksizes 1k and 10k. The results show that Sealevel is significantly more performant across the board. For the sake of reading convenience, only the data for 2, 10, 50, and 10000 accounts were shown, as they suffice to represent most of the landscape.</p><p>Figure 24 shows performance at a blocksize of 1k and Sealevel completely outperforms Block-STM. With a completely sequential workload, there’s a roughly 7x difference in performance and with a highly parallelizable workload (10k accs), there’s a 2.4x difference in performance.</p><figure class="w-richtext-align-center w-richtext-figure-type-image"><div><img src="https://cdn.prod.website-files.com/667922883d09f8c39ad9defe/6711187648badb4b4fe710ea_AD_4nXfkkVwcEzAQyg8QUcMQhfS5G0F8HOErglDynkDFAYKB-z_8mOG3RamzDCQjZLM4dgf8bRIpFwz8K5FvWOk66V-rPuH3IKPtPa6MmUcFIgcN_yewjkOJ8Y0wo7c4O9it2Tu4T52lZ3Q7Fbg3WszNTzJekuoJ.png" loading="lazy" alt=""/></div></figure><p><em>Figure 24: Block-STM vs. Sealevel at 1k blocksize</em></p><p>With a blocksize of 10k, Sealevel has a 45%, 53, and 118% performance boost over Block-STM, with account contention 100, 1k, and 10k respectively. These results are better than the 1k tests and are likely due to the fact that with larger blocks, more transactions are stopped earlier. As discussed above, transactions that fail validation are tagged estimate; because of these failures, the transactions that come after read estimate values and halt quicker which helps to amortize the cost of the initial failures.</p><figure class="w-richtext-align-center w-richtext-figure-type-image"><div><img src="https://cdn.prod.website-files.com/667922883d09f8c39ad9defe/67111876cb5f1808ecceb248_AD_4nXfUOLYu7K9k0lX-UTt6G17L4oVGc2RIeWgMYrCTkGlSgR7olsimtmvaraELHfw60CXLDhivCes9Fd796EGYMzC1PhAuANy41dJ1YThXBBrS6Xo0kugLaQdBYAkYWkwU5_QSERy-HuObn55fFtvXvabh4LBe.png" loading="lazy" alt=""/></div></figure><p><em>Figure 25: Block-STM vs. Sealevel at 10k blocksize</em></p><p>All said, the results are surprising, as years of research on concurrency control have concluded that OCC is highly suited for low contention workloads and PCC for high contention workloads<sup>[2]</sup>.</p><p>In isolation, Block-STM conforms to this standard, with performance improving significantly as contention is reduced. However, regardless of contention, when compared to Sealevel, Block-STM falls behind significantly.</p><p>During testing, we also benchmarked Block-STM with a much earlier iteration of the MoveVM and the observed throughput is more than double the results presented (we got throughput as high as 193k TPS with blocksize: 10k, account-contention: 10k) and overall, Block-STM was much more competitive in contentious scenarios and outperformed Sealevel in non-contentious situations. </p><p>While the performance of Block-STM from those tests is legitimate, those numbers cannot be used for a fair comparison as the execution VM and parts of the underlying program used to obtain them were not production-ready. But this does suggest that Block-STM’s true potential <strong>might</strong> be handicapped by the complexity of the MoveVM.</p><p>We say might as benchmarking Block-STM with Diem Move produces similar results as the ones presented, here today, suggesting that the presented results might be the limit of Block-STM’s ability with a production-ready VM.<br/><br/>Another factor that can explain the performance gap is that Sealevel executes transactions in batches as opposed to Block-STM’s ad hoc execution. The increased context switching from ad hoc execution likely adds some overhead.</p><p>As to the question of what TPU will perform better in real-world situations, it is true that it’s impossible to describe real-world contention with a single number. But Block-STM is too far behind, regardless of contention. However, just to be thorough, we’ll briefly attempt to estimate real-world contention by looking at historical blockchain data and how contentious it is.</p><h2>Visualization of blockchain contention</h2><p>Contention can be visualized using the same prio-graphs that the <em>Central Scheduler</em> uses to identify transaction dependencies. The prio-graphs shown when describing the Central Scheduler were fairly simple. Real priority graphs, shown in figures 26-33 are much, much more complex. The following prio-graphs are prio-graphs for both Ethereum and Solana blocks, as these are the only two networks with enough data to accurately model contention.</p><p>‍</p><figure class="w-richtext-align-center w-richtext-figure-type-image"><div><img src="https://cdn.prod.website-files.com/667922883d09f8c39ad9defe/67111876c19d83ceb6bb6784_AD_4nXeWo1xjgRwXSHqt-Fi9fiR8ix0V8K1u3FNMu_gjlfu3sT0LzMPphYRn1MT8PSMRUBB2tbibRLMKe71_mF7NufKzbd6SYYGa-PL1kgzbUVLQ2zIIbQZn9l-KpLER3GAdJK1F3TE6hxRXvxwwRs7Eh343wQZO.png" loading="lazy" alt=""/></div></figure><p><em>Figure 26: Prio Graph 1</em>| <a href="https://apfitzge.github.io/posts/solana-scheduler/">Source</a></p><p>Figure 25 shows the prio-graph for Solana slot <a href="https://solscan.io/block/%20229666043">229666043</a>. The graph has 89 components (distinct subgraphs of transactions.) Most of these components have simple structures, with many having zero-dependent transactions or simple sequential dependencies. However, a large number of transactions are part of very complex trees.<br/></p><p>Zoom in to see dependencies, keeping in mind that the priority of a transaction is indicated by the color of the node. Also remember that the further out a transaction is from the center of a <em>component</em>, the fewer dependencies it has. Nodes in the center of a <em>component</em> depend on all the transactions outward from them; in all directions.</p><p>‍</p><figure class="w-richtext-align-center w-richtext-figure-type-image"><div><img src="https://cdn.prod.website-files.com/667922883d09f8c39ad9defe/6711187642c9ccc773c8d286_AD_4nXdu24_Kk9snA0h32uG6nD1x1sWawei1IE1nCc10JG552oW-8-ztMGELZd8JK5vV7ed5Pg0ZZHMP2owMtdPDkLhW_4UkNjwOwqyiOAAZXx5CpFFtlHzu4W1PywNykV4er0Vz34c_yBFD8QObUve4gPulWyU.png" loading="lazy" alt=""/></div></figure><p><em>Figure 27: Close-up of prio-graph 1</em>| <a href="https://apfitzge.github.io/posts/solana-scheduler/#central-scheduling-thread">Source</a></p><p>Figure 27 shows a closer shot of the largest tree and the structure is fairly complex.</p><p>The data above show that blockchain transactions are very contentious—a fairly large set of accounts have very low contention but the vast majority of transactions are in straight, long branches of very large trees. The straight, long branches suggest that the transactions contend over the same accounts and the size of the trees relative to the smaller clusters suggests that most transactions are contentious. But most interestingly, the number of branches suggests that many accounts are contentious, not just a small set.</p><p>More prio graphs tell the same story:</p><figure class="w-richtext-align-center w-richtext-figure-type-image"><div><img src="https://cdn.prod.website-files.com/667922883d09f8c39ad9defe/671118760ae7715edc59c908_AD_4nXf8aOYaywjGrCuOY8wVVqJR8J4QKsjJZ4fm0uL2ggG7D9zb5YywnC7i2CE8P5UV_kAI8pAi3fT5SDt9Dodzeen77EFuUfgrDj1RpNOAuI_jjhSr7rVlMdaZkl1lB8w52qVAO5mYTYfP4u7o3yOsvQTQbJTi.jpeg" loading="lazy" alt=""/></div></figure><p><em>Figure 28: Solana Prio-graph 2 </em>| <a href="https://x.com/waitfreemaxi">Source</a></p><figure class="w-richtext-align-center w-richtext-figure-type-image"><div><img src="https://cdn.prod.website-files.com/667922883d09f8c39ad9defe/671118763836e0b52e59b101_AD_4nXcz-RSOluevIXHZQ8_FxLBzPrKaYB4vcYPxAHO7R_Qtop2ua31y--zkV-K0LIi7ZuQX9e3VnBmeHrxJWmz2BRRiGuGl1t0V33EIt1VcmuSqfuRo-On5JaOuPvych4YEjiVKifUTGJEG2yjNYlp_f7hvnWG0.png" loading="lazy" alt=""/></div></figure><p><em>Figure 29 Solana Prio-graph 3 </em>| <a href="https://x.com/waitfreemaxi">Source</a></p><p>‍</p><figure class="w-richtext-align-center w-richtext-figure-type-image"><div><img src="https://cdn.prod.website-files.com/667922883d09f8c39ad9defe/67111876bef7de76c995ac55_AD_4nXfHP4G3EzwRM2pJoiR5EVJEIZQySQWaZmhi492YImm_ugMKuuFoJB_fOKBkgmdV0GCZRFYagdO1P7OovEJKaZ3YFhjPZLOpmPA4FJzo64lC3zIITDAnIlPcg8ckAM4WrzeTJIo4nMn4whqaEMU4Z9w5ZN0.png" loading="lazy" alt=""/></div></figure><p><em>Figure 30: Ethereum Prio-graph 1 (Block 20500428)</em>| <a href="https://par.tryghost.xyz/20500428">Source</a></p><p>‍</p><figure class="w-richtext-align-center w-richtext-figure-type-image"><div><img src="https://cdn.prod.website-files.com/667922883d09f8c39ad9defe/671118760b4cc5dd27742add_AD_4nXea0fLRDsY3nft-ap9mzUnY68n74IEhkiRRfjO8FNcF9BmmNw93-LWzetgypPVfNEh6g0tHxwlTvctuO1Ej-pOBZy0eIs6cK5ZEOVM0NQqen-FSL-s66ipTJTnpfcroMO6A0Z3Ppinuqd450bx7sYJzy17B.png" loading="lazy" alt=""/></div></figure><p><em>Figure 31: Close-up of of Prio-graph for Ethereum Block 20500428 </em>| <a href="https://par.tryghost.xyz/20500428">Source</a></p><p>‍</p><figure class="w-richtext-align-center w-richtext-figure-type-image"><div><img src="https://cdn.prod.website-files.com/667922883d09f8c39ad9defe/6711187681c4feb5ca9742ad_AD_4nXcShLZXZ_djRWFo9pQzIL8PM9YI4kP1BUE2MWWi5ixYCgNkJixQx2_1PPgPXvdVr2oix-S6PgoYYeGJJ31Jn5DrC8OV5CmJtr4l8eopPv0hUIDfq1DyrCXChvc76fqYKxasAbHRL-QSi_rUx9QxP6c5uO4.png" loading="lazy" alt=""/></div></figure><p><em>Figure 32: Ethereum Prio-graph 2 (Block 20500429) </em>| <a href="https://par.tryghost.xyz/20500428">Source</a></p><p>‍</p><figure class="w-richtext-align-center w-richtext-figure-type-image"><div><img src="https://cdn.prod.website-files.com/667922883d09f8c39ad9defe/67111876c1b4308c5d5cd3c8_AD_4nXddjHMNmrlnl5cKB3GoDt_-eDM7rPilpJDOgn002XAOCX2m3ghX0U4AmWUhS2EAi2ZSwUL8GRVGGQcKSZ1K1s5wEOdAhT9n4vHRshnboc0EwJ12ciqz185LUYVIxGvz1i4U-IJolSIWlqNC49Ee7bfYD_k3.png" loading="lazy" alt=""/></div></figure><p><em>Figure 33: Ethereum Prio-graph 3 (Block 20500430) </em>| <a href="https://par.tryghost.xyz/20500428">Source</a></p><p>In summary, state access on blockchains is <em>very contentious</em>.</p><p>The more nuanced conclusions that can be drawn from looking at the data are:</p><ol role="list"><li>most high-priority transactions are for highly contested portions of state</li><li>state access is contentious but also highly parallelizable—there are many hotspots (of varying “temperature”) as opposed to one large hostpot.</li><li>a reasonably large set of transactions do not contend with any others. This set is small relative to the set of transactions that do (as small as 10%), but not ifinitestimal.</li></ol><p>So what does this mean for Block-STM and Sealevel? Well, it strengthens the argument that Sealevel will perform better in real-world scenarios. The extent of “better” is a question that can only be answered by more involved simulations but the current data strongly indicates that Sealevel will perform significantly better in real world use.</p><p>All said, it’s important to note that because of Block-STM’s primitive dependency identification and other optimizations<sup>2, 3</sup>, Block-STM will perform much better than traditional OCC TPUs. But it’s performance will likely never match that of Sealevel.</p><h2>The case for OCC and Block-STM</h2><p>As we approach the end of this paper, it’s easy to walk away with the impression that OCC (and, by extension, Block-STM) is pointless—years of research and test data suggest that it’s practically guaranteed to be slower than PCC in an environment like blockchains, where state access is fairly contentious. In addition, Block-STM seems like a step backwards in the context of Transaction Fee Markets (TFMs) as it lacks one of the major benefits of concurrent execution—local fee markets. However, Block-STM has made many improvements to the traditional OCC design and will perform much better than previous OCC TPUs. In addition, there are three more benefits of Bock-STM’s design that are worth noting.</p><h3>Wider Range of Supported Applications</h3><p>The primary advantage of an OCC-TPU is that it allows for arbitrary transaction logic. Since PCC-TPUs require that transactions declare upfront the portions of memory they will access, it is impossible to write transactional logic where a transaction decides to read or write certain memory locations based on information discovered during execution. </p><p>A good example is on-chain orderbook design. Orderbooks on PCC-TPUs usually cannot offer atomic settlement (or permissionless market making) and limit orders since transactions must specify upfront what accounts will be accessed during the transaction. To work around this, most orderbooks on Solana required the aid of an additional entity—the cranker—to finalize limit orders. Phoenix on Solana has managed to overcome this by holding all the balances in one account but this approach faces its own struggles. OCC TPU orderbooks like Aptos’ <a href="https://x.com/EconiaLabs">Econia</a> completely avoid this complexity since transactions don’t need to know their read/write dependencies before hand.</p><p>On-chain orderbooks are a single use case; there are many others and likely some unknown unknowns that are only possible (or efficient) with arbitrary smart contract logic. PCC blockchains will never fully offer this functionality because their design does not allow for it. This is where OCC blockchains shine the most.</p><h3>Developer Experience</h3><p>The necessity of declaring dependencies upfront not only constrains the types of applications that can be developed, it also degrades developer experience. Developers writing applications and even transactions on PCC-TPUs face the added complexity of having to determine ahead the exact portions of state their code will access. This can be very rigorous and there’s no better proof than this excerpt from a proposal on the Sei forum where the authors propose adopting Block-STM because of the complexities of working with a PCC-execution engine.</p><p>‍</p><figure class="w-richtext-align-center w-richtext-figure-type-image"><div><img src="https://cdn.prod.website-files.com/667922883d09f8c39ad9defe/67111876959a7ce4fcc567f8_AD_4nXd4OjfDJvGgCU-3a_xIAQde4M1aKYL2ze_M4eVfFIW7xyJhwqalo47TfwzSDrLCZUcVngCGKSMIG3JBbr3mWV6Z_gcyugmy51o_1G_DnW3qtkJEMU2cJD-s7R2zurkSkoYEEGMoAkA34uc-NglPmow_egt_.png" loading="lazy" alt=""/></div></figure><p><em>Figure 34: Screenshot of SEI forums discussing adoption of OCC (Block-STM) </em>| <a href="https://forum.sei.io/t/optimistic-concurrency-control/28"><em>Source</em></a></p><h3>Portability</h3><p>The final argument for Block-STM is that it can integrate with any blockchain without breaking compatibility with existing transactions. There have been attempts to have transactions optionally specify upfront what portion of state they’ll be accessing on Ethereum in a bid to increase the efficiency of the EVM but they never saw the light of day. Because of Block-STM’s nature, it can be (permissionlessly) integrated into any blockchain without breaking consensus. Even Solana clients can implement Block-STM with modifications to ensure that the blocks meet all the constraints without a formal proposal. It is specifically for this reason that Monad and all other parallel EVMs use Block-STM to achieve functional parallelization of the EVM.</p><p>For these reasons—arbitrary transaction logic, improved developer experience, and portability—OCC-execution engines are at least worth exploring.</p><h1>Conclusion</h1><p>Over the course of this paper, we’ve considered two opposing paradigms to improving blockchain execution: Optimistic Concurrency Control (OCC) and Pessimistic Concurrency Control (PCC) by looking at the leading implementations of both paradigms. Both designs (Block-STM and Sealevel) are extremely innovative and undoubtedly a much more efficient use of hardware than sequential TPUs.</p><p>Block-STM uses OCC and insights from dDB design to improve concurrency without sacrificing developer experience. While Sealevel relies on established lock-based techniques and hardware-maximizing design to increase performance at the cost of some use cases and a more difficult developer experience.<br/></p><p>Overall, both Block-STM and Sealevel are great leaps from sequential TPUs and have set new standards for blockchain TPUs. In the current landscape, it’s hard to appreciate them as there are other bottlenecks but as the other components of blockchain pipelines continue to improve, the importance of the TPUs will only become more apparent.</p><h1>References</h1><ul role="list"><li><a href="https://en.wikipedia.org/wiki/Concurrency_control">Concurrency control</a></li><li><a href="https://www.geeksforgeeks.org/concurrency-control-in-dbms/">Concurrency Control in DBMS - GeeksforGeeks</a></li><li><a href="https://en.wikipedia.org/wiki/Multiversion_concurrency_control">Multiversion concurrency control</a></li><li><a href="https://en.wikipedia.org/wiki/Database_transaction">Database transaction</a></li><li><a href="https://en.wikipedia.org/wiki/Database_transaction_schedule">Database transaction schedule</a></li><li><a href="https://en.wikipedia.org/wiki/Lock_(computer_science)">Lock (computer science)</a></li><li><a href="https://en.wikipedia.org/wiki/Two-phase_locking#Strong_strict_two-phase_locking">Two-phase locking</a></li><li><a href="https://en.wikipedia.org/wiki/Conservative_two-phase_locking">Conservative two-phase locking</a></li><li><a href="https://dl.acm.org/doi/10.5555/2604448">Deterministic transaction execution in distributed database systems | Guide books</a></li><li><a href="https://en.wikipedia.org/wiki/Deadlock">Deadlock</a></li><li><a href="https://solana.com/docs/core/accounts">Solana Account Model | Solana</a></li><li><a href="https://www.youtube.com/watch?v=rNGmTlND9tM">Solana Validator Educational - Transaction Lifecycle</a></li><li><a href="https://solana.com/docs/core/programs">Programs | Solana</a></li><li><a href="https://solana.com/docs/core/transactions">Transactions and Instructions | Solana</a></li><li><a href="https://github.com/solana-labs/solana/blob/27eff8408b7223bb3c4ab70523f8a8dca3ca6645/sdk/program/src/instruction.rs#L539">https://github.com/solana-labs/solana/blob/27eff8408b7223bb3c4ab70523f8a8dca3ca6645/sdk/program/src/instruction.rs#L539</a></li><li><a href="https://medium.com/@asmiller1989/solana-transactions-in-depth-1f7f7fe06ac2">Solana Transactions in Depth</a></li><li><a href="https://arxiv.org/html/2405.08882v1">Lollipop: SVM Rollups on Solana Version: 0.1.0</a></li><li><a href="https://solana.com/docs/advanced/confirmation#proof-of-history-refresher">Transaction Confirmation &amp; Expiration | Solana</a></li><li><a href="https://youtu.be/rNGmTlND9tM?si=22Vzrh7HoGvmg6FN">Solana Validator Educational - Transaction Lifecycle</a></li><li><a href="https://www.umbraresearch.xyz/writings/lifecycle-of-a-solana-transaction">Lifecycle of a Solana Transaction | Umbra Research</a></li><li><a href="https://medium.com/solana-labs/sealevel-parallel-processing-thousands-of-smart-contracts-d814b378192">Sealevel — Parallel Processing Thousands of Smart Contracts</a></li><li><a href="https://www.youtube.com/watch?v=R7hq8ampBio">Spotlight: Solana&#x27;s Scheduler</a></li><li><a href="https://www.anza.xyz/blog/introducing-the-central-scheduler-an-optional-feature-of-agave-v1-18">Introducing the Central Scheduler: An Optional Feature of Agave v1.18 - Anza</a></li><li><a href="https://www.notion.so/What-s-new-with-Solana-s-transaction-scheduler-0f9bb5c0e4f04645bf3d2f65e0d56231?pvs=21">What’s new with Solana’s transaction scheduler?</a></li><li><a href="https://apfitzge.github.io/posts/solana-scheduler/#central-scheduling-thread">Solana Scheduler</a></li><li><a href="https://www.helius.dev/blog/all-you-need-to-know-about-solanas-v1-18-update">All You Need to Know About Solana&#x27;s v1.18 Update</a></li><li><a href="https://apfitzge.github.io/posts/solana-scheduler/#central-scheduling-thread">Solana Scheduler</a></li><li><a href="https://apfitzge.github.io/posts/road-to-bankless/">Road to Bankless</a></li><li><a href="https://github.com/solana-labs/solana/blob/cd6f931223181d5a1d47cba64e857785a175a760/core/src/banking_stage.rs#">solana/core/src/banking_stage.rs at cd6f931223181d5a1d47cba64e857785a175a760 · solana-labs/solana</a></li><li><a href="https://www.notion.so/Transaction-confirmation-d5b8f4e09b9c4a70a1f263f82307d7ce?pvs=21">Transaction confirmation</a></li><li><a href="https://docs.google.com/document/d/1fQp2G-W0fFN19nRZVRbAwxD7Qa8H8cn5VVUvPKOF1Pg/edit#heading=h.mn48hr9e6wzk">https://docs.google.com/document/d/1fQp2G-W0fFN19nRZVRbAwxD7Qa8H8cn5VVUvPKOF1Pg/edit#heading=h.mn48hr9e6wzk</a></li><li><a href="https://solana.com/docs/terminology#transactions-entry">Terminology | Solana</a></li><li><a href="https://aptos.dev/concepts/blockchain">Aptos Blockchain Deep Dive | Aptos Docs</a></li><li><a href="https://messari.io/report/understanding-aptos-a-comprehensive-overview">Understanding Aptos: A Comprehensive Overview</a></li><li><a href="https://medium.com/aptoslabs/quorum-store-how-consensus-horizontally-scales-on-the-aptos-blockchain-988866f6d5b0">Quorum Store: How Consensus Horizontally Scales on the Aptos Blockchain</a></li><li><a href="https://dl.acm.org/doi/abs/10.1145/3492321.3519594?casa_token=GQtprhA8Ko0AAAAA:P_FcreghKROwtXI6OQUL437Ix1ilommzaMDz3_8sDpfZXYg1m2NZIkRtcJSzGXurgVisqRSVvn6XHw">Narwhal and Tusk | Proceedings of the Seventeenth European Conference on Computer Systems</a></li><li><a href="http://web.mit.edu/rust-lang_v1.25/arch/amd64_ubuntu1404/share/doc/rust/html/std/collections/struct.BTreeMap.html">std::collections::BTreeMap - Rust</a></li><li><a href="https://en.wikipedia.org/wiki/Transactional_memory">Transactional memory</a></li><li><a href="http://cs.yale.edu/homes/thomson/publications/calvin-sigmod12.pdf">cs.yale.edu</a></li><li><a href="https://arxiv.org/pdf/1412.2324">arxiv.org</a></li><li><a href="https://blog.chain.link/block-stm/">Block-STM: Accelerating Smart-Contract Processing | Chainlink Blog</a></li><li><a href="https://arxiv.org/abs/2203.06871">Block-STM: Scaling Blockchain Execution by Turning Ordering Curse...</a></li><li><a href="https://github.com/danielxiangzl/Block-STM">GitHub - danielxiangzl/Block-STM: Diem’s mission is to build a trusted and innovative financial network that empowers people and businesses around the world.</a></li><li><a href="https://github.com/danielxiangzl/Block-STM">GitHub - danielxiangzl/Block-STM: Diem’s mission is to build a trusted and innovative financial network that empowers people and businesses around the world.</a></li><li><a href="https://forum.sei.io/t/optimistic-concurrency-control/28">Optimistic Concurrency Control</a></li><li><a href="https://app.blockworksresearch.com/unlocked/the-aptos-advantage-moving-at-scale">The Aptos Advantage: Moving at Scale | Blockworks Research</a></li><li><a href="https://econia.dev/overview/orders">Orders | Econia Docs</a></li><li><a href="https://ellipsis-labs.gitbook.io/phoenix-dex/tRIkEFlLUzWK9uKO3W2V/getting-started/technical-overview/seats">Seats | Phoenix DEX</a></li><li><a href="https://aptosfoundation.org/currents/aptos-ecosystem-leading-the-way-with-parallelism">Aptos Ecosystem Leading the Way with Parallelism</a></li><li><a href="https://github.com/ethereum/EIPs/issues/648">https://github.com/ethereum/EIPs/issues/648</a></li><li><a href="https://drops.dagstuhl.de/entities/document/10.4230/LIPIcs.AFT.2023.4">Designing Multidimensional Blockchain Fee Markets</a></li><li><a href="https://arxiv.org/abs/2402.08661">Multidimensional Blockchain Fees are (Essentially) Optimal</a></li><li><a href="https://en.wikipedia.org/wiki/Parallel_Virtual_Machine">Parallel Virtual Machine</a></li><li><a href="https://docs.avax.network/build/vm/">Avalanche Dev Docs: Create Without Limits</a></li><li><a href="https://docs.avax.network/build/vm/create/rust-vm">Avalanche Dev Docs: Create Without Limits</a></li><li><a href="https://docs.eclipse.xyz/eclipse-architecture/what-is-eclipse-mainnet/execution-solana-virtual-machine-svm">Execution - Solana Virtual Machine (SVM) | Eclipse Documentation</a></li><li><a href="https://www.youtube.com/watch?v=Yu_ciYtxYzM&amp;t=2350s">Introduction to Virtual Machines - Part 1 Zoom recording of online class on April 13th 2020</a></li><li><a href="https://www.linkedin.com/pulse/building-vm-instruction-set-rust-luis-soares-m-sc--fjnjf">Building a VM Instruction Set in Rust</a></li><li><a href="https://www.youtube.com/watch?v=ZBJ0u9MaKtM">JVM ( java virtual machine) architecture - tutorial</a></li><li><a href="https://arxiv.org/pdf/2102.10784">arxiv.org</a></li><li><a href="https://www.notion.so/The-Agave-Runtime-d1f8d3608e5d4529b120e09e80b48887?pvs=21">The Agave Runtime</a></li><li><a href="https://x.com/0xEdgar/status/1617347877000413184">edgar on Twitter / X</a></li><li><a href="https://www.kentik.com/kentipedia/what-is-ebpf-extended-berkeley-packet-filter/">What is eBPF? (Extended Berkeley Packet Filter)</a></li><li><a href="https://www.kentik.com/blog/ebpf-explained-why-its-important-for-observability/">eBPF Explained: Why it&#x27;s Important for Observability</a></li><li><a href="https://ebpf.io/what-is-ebpf/">What is eBPF? An Introduction and Deep Dive into the eBPF Technology</a></li><li><a href="https://youtu.be/oBW2KJq3FnA?si=8JUgs2h27lKBgqrn">In Rust We Trust - Berkeley Packet Filter and Rust</a></li><li><a href="https://en.wikipedia.org/wiki/Distributed_database">Distributed database</a></li><li><a href="https://en.wikipedia.org/wiki/Partition_(database)">Partition (database)</a></li><li><a href="https://www.databricks.com/glossary/acid-transactions">What are ACID Transactions?</a></li><li><a href="https://en.wikipedia.org/wiki/Embarrassingly_parallel">Embarrassingly parallel</a></li><li><a href="https://en.wikipedia.org/wiki/IPv6_packet">IPv6 packet</a></li><li><a href="https://www.geeksforgeeks.org/branching-instructions-8085-microprocessor/">Branching instructions in 8085 microprocessor - GeeksforGeeks</a></li><li><a href="https://en.wikipedia.org/wiki/Single_instruction,_multiple_data">Single instruction, multiple data</a></li><li><a href="https://ftp.cvut.cz/kernel/people/geoff/cell/ps3-linux-docs/CellProgrammingTutorial/BasicsOfSIMDProgramming.html">Basics of SIMD Programming</a></li><li><a href="https://en.wikipedia.org/wiki/Single_instruction,_multiple_data">Single instruction, multiple data</a></li><li><a href="https://byjus.com/gate/types-of-instructions-in-computer-architecture-notes/">Types of Instructions in Computer Architecture | GATE Notes</a></li><li><a href="https://en.wikipedia.org/wiki/Thread_(computing)">Thread (computing)</a></li><li><a href="https://www.liquidweb.com/blog/difference-cpu-cores-thread/">The Difference Between CPU Cores and Threads</a></li><li><a href="http://docs.oracle.com/cd/E19455-01/806-5257/6je9h032b/index.html">Defining Multithreading Terms (Multithreaded Programming Guide)</a></li><li><a href="https://en.wikipedia.org/wiki/Assembly_language">Assembly language</a></li><li><a href="https://apfitzge.github.io/posts/optimizing-scheduler-performance-accelerating-packet-to-transaction-conversion/">transaction_deserialization</a></li><li><a href="https://hazelcast.com/glossary/serialization/">Serialization</a></li><li><a href="https://en.wikipedia.org/wiki/Min-max_heap">Min-max heap</a></li><li><a href="https://en.wikipedia.org/wiki/Directed_acyclic_graph">Directed acyclic graph</a></li><li><a href="https://en.wikipedia.org/wiki/Channel_(programming)">Channel (programming)</a></li><li><a href="https://en.wikipedia.org/wiki/Frequency_scaling">Frequency scaling</a></li><li><a href="https://en.wikipedia.org/wiki/Work_stealing">Work stealing</a></li><li><a href="https://solana.com/docs/terminology">Terminology | Solana</a></li><li><a href="https://www.nervos.org/knowledge-base/state_and_state_change_(explainCKBot)">What do “State” and “State Change” Mean in Blockchain?</a></li><li><a href="https://pages.cs.wisc.edu/~remzi/OSTEP/threads-locks.pdf">https://pages.cs.wisc.edu/~remzi/OSTEP/threads-locks.pdf</a></li><li><a href="https://docs.monad.xyz/technical-discussion/consensus/deferred-execution">Deferred Execution | Monad</a></li></ul><h2><strong>Paper References</strong></h2><ul role="list"><li>Maurice Herlihy and J. Eliot B. Moss. <em>Transactional memory: architectural support for lock-free data structures.</em> Proceedings of the 20th annual international symposium on Computer architecture (ISCA &#x27;93). Volume 21, Issue 2, May 1993.</li><li><strong><em>Optimistic versus pessimistic concurrency control mechanisms in database management systems</em></strong><a href="https://www.semanticscholar.org/author/D.-Menasc%C3%A9/2264617067"><em> </em>D. Menascé</a>, <a href="https://www.semanticscholar.org/author/Tatuo-Nakanishi/31634756">Tatuo Nakanishi</a>  <a href="https://www.semanticscholar.org/venue?name=Information%20Systems">Information Systems</a> 1982. DOI:<a href="https://doi.org/10.1016/0306-4379%2882%2990003-5">10.1016/0306-4379(82)90003-5</a></li><li><strong><em>Revisiting optimistic and pessimistic concurrency control</em> </strong>Goetz Graefe 2016.</li></ul><h2><strong>Repos for tests</strong></h2><ul role="list"><li><a href="https://github.com/2077-Research/agave-BSTM-v-Sealevel-">Sealevel</a></li><li><a href="https://github.com/2077-Research/aptos-core-Block-STM-v-Sealevel-">Block-STM</a></li></ul><h1>Glossary</h1><h2>CPU Architecture</h2><p>This section will provide concrete definitions for computer hardware terms that showed up during the report:<br/></p><ul role="list"><li>A CPU core is essentially a CPU in and of itself. It has all the necessary components to qualify as a full CPU and is capable of executing tasks by itself. Most modern CPU chips have multiple cores that share memory and I/O hardware.</li></ul><ul role="list"><li>A <em>thread</em> is an abstraction that roughly refers to a series of instructions executed by a CPU core.some text<ul role="list"><li>Multithreading is executing a program (not a transaction) across multiple threads.</li><li>Hyperthreading allows CPU cores to execute two threads pseudo-simultaneously. The core shares its resources between two threads in a way that improves parallelism but it’s not the 2x performance that’s often implied.</li></ul></li></ul><h2>Parallel vs. Concurrent</h2><p>In English, the terms parallel and concurrent can be used interchangeably but in computing, they mean different things. I’ll leave you with a few computer science definitions of both terms and allow you to build a bridge from them to processing transactions in blockchains.</p><ul role="list"><li>A parallel program uses multiple CPU cores, each core performing a task independently. On the other hand, concurrency enables a program to deal with multiple tasks even on a single CPU core; the core switches between tasks (i.e. threads) without necessarily completing each one. A program can have both, neither of or a combination of parallelism and concurrency characteristics.<br/><br/></li><li>Concurrency focuses on managing multiple tasks efficiently with one resource, parallelism utilizes multiple resources to execute tasks simultaneously, making processes faster.<br/><br/></li><li>Concurrency is when two or more tasks can start, run, and complete in overlapping time periods. It doesn&#x27;t necessarily mean they&#x27;ll ever both be running at the same instant. For example, multitasking on a single-core machine. Parallelism is when tasks literally run at the same time, e.g., on a multicore processor.<br/><br/></li><li>A parallel functional program uses multiple processors to gain performance. For example, it may be faster to evaluate e<sub>1</sub> + e<sub>2</sub> by evaluating e<sub>1</sub> and e<sub>2</sub> in parallel, and then add the results. Parallelism has no semantic impact at all: the meaning of a program is unchanged whether it is executed sequentially or in parallel. Furthermore, the results are deterministic; there is no possibility that a parallel program will give one result in one run and a different result in a different run.</li></ul><p>In contrast, a concurrent program has concurrency as part of its specification. The program must run concurrent threads, each of which can independently perform input/output. The program may be run on many processors, or on one — that is an implementation choice. The behavior of the program is, necessarily and by design, non-deterministic. Hence, unlike parallelism, concurrency has a substantial semantic impact.</p><p>It should be clear now why transaction processing in blockchains is more analogous to concurrent processing than parallel processing.</p><h2>Other Terms</h2><ul role="list"><li>instruction: an instruction is the most granular operation that a processor can perform. They can vary in complexity based on the computer’s instruction set architecture but the idea is that an instruction is guaranteed to be atomic by the hardware design.<br/><br/></li><li>bytecode:bytecode is an assembly code-like intermediate representation. In this context, it refers to a VM’s instruction set.<br/><br/></li><li>assembly language: assebly language is a low level language with constructs that map 1:1 with the underlying CPU’s instruction set.<br/><br/></li><li>priority inversion: is when a lower priority process (read: transaction) prevents the execution of a higher priority process.<br/><br/></li><li>convoying: a lock convoy occurs when threads of equal priority compete for access to a shared resource. Each time a thread relinquishes access to the resource and pauses or stops the process, there is some overhead incurred.<br/><br/></li><li>deadlocks: a phenomenon where two or more processes can not advance because each one requires resources held by the other.<br/><br/></li><li>slots: a slot is Solana’s term for blocktime, currently around 400ms. Nodes are allotted four consecutive slots every time they are leader.<br/><br/></li><li>epoch: an epoch in Solana is a distinct block of 432,000 consecutive slots. Not any 4320,000 slots but rather distinct blocks like days of the week.<br/><br/></li><li>serialization: is the process of converting data (data structures and object) to a string of bits that can be stored, transmitted, and reconstructed according to the format.<br/><br/></li><li>deserialization: is the process of reconstructing serialized data from the string of bits to the original data structures or objects<br/><br/></li><li>buffer: a buffer is a temporary storage element. It’s usually used when data cannot or should not be processed at the same rate at which it is being fed to the next block of a process.<br/><br/></li><li>packets: a packet is a fixed size unit of data carried by a packet-switched network. Packets are relevant to Solana because each transaction is constrained to the maximum size of an IPv6 packet.<br/><br/></li><li>double-ended queue: also called dequeue, is an abstract data structure that supports the addition of data to one end and removal of from the other.<br/><br/></li><li>channel: high-performance I/O gadget.<br/><br/></li><li>b-tree: self balancing data structure.<br/><br/></li><li>hashmap: is an efficient associative array data structure.<br/><br/></li><li>race conditions: occur when uncontrollable processes can lead to incorrect or inconsistent results. In the context of this paper, race conditions occur in OCC systems.</li></ul><h1>Appendix</h1><h2>A1: Distributed Databases</h2><p>Distributed databases are a lot like blockchains, in fact, it’s not a stretch to say that they’re fundamentally the same thing. A distributed database is a collection of multiple, interconnected databases spread across different physical locations connected via a network. These databases appear as a single database to the user but function on multiple servers. </p><p>The topic of distributed databases is expansive so I’ll (briefly) cover only the areas relevant to this report: data distribution methods and database transactions.</p><h3>Data Distribution Methods</h3><ul role="list"><li><strong>Horizontal Partitioning</strong>: Each site stores a different (subset) of the rows of a table. For example, a customer table might be divided so that the first X entries are stored on one database and the others are stored elsewhere.</li><li><strong>Vertical Partitioning</strong>: Each site stores different columns of a table. For example, one site might store the customer names and addresses, while another site stores their purchase histories.</li><li><strong>Replication</strong>: Copies of the entire database (or subsets) are stored at multiple sites. This improves data availability and reliability but may introduce consistency challenges.</li></ul><h3>Transactions</h3><p>Transactions in DBMSs are defined as a single unit of <em>operations</em> that perform a logical action, usually accessing and/or modifying the database. For most databases, especially those keeping track of financial records, transactions are required to have ACID properties i.e., the transactions are:</p><ul role="list"><li>Atomic: all or nothing, if one operation fails, the entire transaction reverts</li><li>Consistent: transactions modify the database in predictable and repeatable ways</li><li>Isolated: when multiple transactions are executed concurrently, they execute without affecting each other, as if they were executed sequentially, and</li><li>Durable: changes made by completed transactions are permanent even in the event of system failure.</li></ul><p>If it’s not already obvious, blockchains are just replicated databases with adversarial operators. So it’s not surprising that distributed database research forms the foundation for most blockchain designs today.</p><figure class="w-richtext-align-center w-richtext-figure-type-image"><div><img src="https://cdn.prod.website-files.com/667922883d09f8c39ad9defe/6711187531935f629a8bdb0e_AD_4nXfHnNg02f2ucYMXHNTGjTb-uznONzm2HC8E_Vmr8YvHM_mySIvpFhoPe3pLIi_FZOlwz-IiIZcbVnj9CwbntSxEb4prooiIRj-i52Q3K58jAdDQEYzBUwuzYMW05b9TNqnSzSzWm2RqyGvItbrtto5EysyR.jpeg" loading="lazy" alt=""/></div></figure><h2>A2: Narwhal and Quorum Store TLDR</h2><p>The value proposition of Narwhal (and by extension Quorum Store) is that “leader-based consensus” i.e. a consensus system where the leader for a slot is responsible for transmitting most of the information during that slot (a-la-Solana) is bottlenecked by the performance of the leader as opposed to the entire validator set. Narwhal (and Quorum Store) resolve this bottleneck by decoupling data dissemination and consensus down to the hardware level. The implementation of this idea spreads the work equally across all validators, as opposed to having the leader alone bear the brunt.</p><figure class="w-richtext-align-center w-richtext-figure-type-image"><div><img src="https://cdn.prod.website-files.com/667922883d09f8c39ad9defe/671118761d677abf834d3039_AD_4nXeg743KuWkptCweYMJ2j7Gmpqxq3lM5Y9ofbZ5Xv2Vce4e7uz8AK61GuH0uyGz6LlwKwvAfZJjIUVJlKgHC3YsnT5KOOgT1XyApiuRVwMuw1ny6AEjKWYLGmtf69Rm10ZqhQ59yyfbznx4vI-CIqEPy4Utc.png" loading="lazy" alt=""/></div></figure><p><em>Figure A2.1: Bandwidth utilization in leader-based consensus and Quorum Store </em>| <a href="https://medium.com/aptoslabs/quorum-store-how-consensus-horizontally-scales-on-the-aptos-blockchain-988866f6d5b0"><em>Source</em></a></p><p>There’s perhaps no better proof of Narwhal’s value than Solana itself. The Solana documentation currently recommends that validators use dedicated 1 Gbit/s lines as the minimum bandwidth setup and ideally a 10 Gbit line. Average sized validators report around 1.5Gbit/s peak traffic (during leader slots) Aptos node runners report using 25 Mbps by comparison. Of course, both chains don’t process nearly the same amount of traffic and there’s the question of the stakeweight of each validator but the big idea is that Quorum Store is more efficient from a leader’s point of view than “leader-based consensus.” Let’s run through how it works.</p><p>In Quorum Store, validators continuously steam batches of ordered transactions (similar to the blocks discussed above) to one another. The batches contain raw transaction data and metadata (batch identifiers.) Other validators receive these batches, sign the batches, and transmit the signatures to other validators just like they would a normal executed block in “leader-based consensus.” When a batch reaches the quorum of stake-weighted signatures, it essentially receives a proof-of-availability as all the validators that sign a batch promise to keep and provide the batch on request until it “expires.”</p><figure class="w-richtext-align-center w-richtext-figure-type-image"><div><img src="https://cdn.prod.website-files.com/667922883d09f8c39ad9defe/6711187618e20d406db2e1a2_AD_4nXeIp-HIVNP8T0LicSQAU3FG7AvvBX1Vk4YLq3OYh0061zE0wPcqZw3SnKZtKih0OmGQiglZS_I0GrkJpmhvC4dI77pgLAwBaLx84kObemIRWwEcHjh3rZGWVjJuOlttQ3BoL-jhcxpmEDpulqywL4sqa2iB.png" loading="lazy" alt=""/></div></figure><p><em>Figure A2.2 Illustration </em>| Source</p><p>Because of Quorum Store, the leader doesn’t have to propose transaction batches anymore. Instead, the leader simply selects a batch for which it has a Proof-of-Availability, sends out the batch metadata, executes the block, and sends out the execution results. Other validators can then map the metadata to the batch and replay the batch for verification. If they don’t have the batch, they can request it from other nodes and be sure they’ll receive it since 2f+1 nodes promised to store and provide the data. This reduces the messaging overhead of the leader. And because Quorum Store is run on a separate machine, it’s horizontally scalable by adding more boxes.</p><p>‍</p><p>There is a lot of nuance that my TLDR has left out; you can find more details in the <a href="https://medium.com/aptoslabs/quorum-store-how-consensus-horizontally-scales-on-the-aptos-blockchain-988866f6d5b0">Aptos Blog Post</a> and <a href="https://dl.acm.org/doi/abs/10.1145/3492321.3519594?casa_token=GQtprhA8Ko0AAAAA%3AP_FcreghKROwtXI6OQUL437Ix1ilommzaMDz3_8sDpfZXYg1m2NZIkRtcJSzGXurgVisqRSVvn6XHw">Narwhal Paper</a>.</p><h2>A3: Block-STM Algorithm</h2><p>This section contains the Block-STM algorithm from the paper alongside explanatory comments to aid understanding.</p><p>Thread Logic<br/><em>//this block checks if execution is complete, if it is, it ends the procedure, if not:</em><br/><em>//it checks if there is a task, and based on the type of task, it performs an action</em><br/><em>//if there are no tasks, it calls the scheduler to assign it a task.</em><br/>1: procedure run()<br/>2:     task ← ⊥ <em>//⊥ is pseudocode for null</em><br/>3:     while ¬Scheduler.done() do <em>//¬ is pseudocode for not</em><br/>4:         if task ≠ ⊥ ∧ task.kind = EXECUTION_TASK then <br/>5:             task ← try_execute(task.version) ⊲ returns a validation task, or ⊥<br/>6:         if task ≠ ⊥ ∧ task.kind = VALIDATION_TASK then<br/>7:             task ← needs_reexecution(task.version) ⊲ returns a re-execution task, or ⊥<br/>8:         if task = ⊥ then<br/>9:             task ← Scheduler.next_task()<br/><br/><em>//this block attempts to execute a transaction version</em><br/><em>//line 13 checks that the transaction did not read any estimates</em><br/><em>//line 14 attempts to add a dependency and if it fails retries the transaction</em><br/><em>//line 18 calls the MVMemory module that will be covered later,</em><br/><em>//but the MVMemory.record function writes the read_set and write_set to the data structure</em><br/><em>//and returns a bool that indicates if the trnasaction version wrote a new location</em><br/>10: function try_execute(version) ⊲ returns a validation task, or ⊥<br/>11:     (txn_idx, incarnation_number) ← version <em>//unpacks version into its components</em><br/>12:     vm_result ← VM.execute(txn_idx) ⊲ VM execution results not written to shared memory<br/>13:     if vm_result.status = READ_ERROR then<br/>14:         if ¬Scheduler.add_dependency(txn_idx, vm_result.blocking_txn_idx) then<br/>15:             return try_execute(version) ⊲ dependency resolved in the meantime, re-execute<br/>16:         return ⊥<br/>17:     else<br/>18:         wrote_new_location ← MVMemory.record(version, vm_result.read_set, vm_result.write_set)<br/>19:         return Scheduler.finish_execution(txn_idx, incarnation_number, wrote_new_location)<br/><br/><em>//this block checks if a transaction needs reexecution and returns a task for re-execution, or ⊥</em><br/><em>//line 23 defines the conditions for a transaction version to be considered aborted</em><br/><em>//the read set of the transaction must be invalid and the scheduler&#x27;s attempt to abort must be true</em><br/>20: function needs_reexecution(version)<br/>21:     (txn_idx, incarnation_number) ← version<br/>22:     read_set_valid ← MVMemory.validate_read_set(txn_idx)<br/>23:     aborted ← ¬read_set_valid ∧ Scheduler.try_validation_abort(txn_idx, incarnation_number)<br/>24:     if aborted then<br/>25:         MVMemory.convert_writes_to_estimates(txn_idx)<br/>26:     return Scheduler.finish_validation(txn_idx, aborted)<br/><br/><em>//defines atomic variables</em><br/><br/>Atomic Variables:<br/>    data ← Map, initially empty ⊲ (location, txn_idx)<br/>    last_written_locations ← Array(BLOCK.size(), <em>{}</em>) ⊲ txn_idx to a set of memory locations written during its last finished execution.<br/>    last_read_set ← Array(BLOCK.size(), <em>{}</em>) ⊲ txn_idx to a set of (location, version) pairs per reads in last finished execution.<br/><em>//data is the MV data structure, it maps the (location, transaction_index) pair to </em><br/><em>//an (incarnation number, value) pair or to an ESTIMATE marker</em><br/><em>//the next two lines describe creating abstract data strctures that hold a mapping of</em><br/><em>//transaction id to the last written memory locations and</em><br/><em>//txn id to the memory locations that version of the transaction read</em><br/><br/><em>//A procedure is essentially a function that does not return any value</em><br/><em>//this block iterates over every location-value pair in the write set</em><br/><em>//and stores it in the multi-version data structure </em><br/>27: procedure apply_write_set(txn_index, incarnation_number, write_set)<br/>28:     for every (location, value) ∈ write_set do<br/>29:         data[(location, txn_idx)] ← (incarnation_number, value) ⊲ store in the multi-version data structure<br/><br/><em>//Read-Copy-Updates the variable that holds the last write set of a transaction</em><br/>30: function rcu_update_written_locations(txn_index, new_locations)<br/>31:     prev_locations ← last_written_locations[txn_idx] ⊲ loaded atomically (RCU read)<br/>32:     for every unwritten_location ∈ prev_locations \\ new_locations do<br/>33:             data.remove((unwritten_location, txn_idx)) ⊲ remove entries that were not overwritten<br/>34:     last_written_locations[txn_idx] ← new_locations ⊲ store newly written locations atomically (RCU update)<br/>35:     return new_locations \\ prev_locations ≠ <em>{}</em> ⊲ was there a write to a location not written the last time?<br/><em>//unpacks the last written locations into previous locations</em><br/><em>//determines the set that contains elements in new locations that are not in previous locations</em><br/><em>//and for every location that this incarnation does not write to,</em><br/><em>//remove the location from the write set</em><br/><em>//this entire fucking block literally just finds old written locations that were not written in this new incarnation and removes them</em><br/><em>//it also returns a bool to confirm that there was a write to a location that wasn&#x27;t written to this time.</em><br/><em>//the \\ symbol in line 35 is set difference. the line checks if the set difference is empty</em><br/><br/><em>//this block records a version to the multi version data structure</em><br/>36: function record(version, read_set, write_set)<br/>37:     (txn_idx, incarnation_number) ← version<br/>38:     apply_write_set(txn_idx, incarnation_number, write_set) <em>//procedure call</em><br/>39:     new_locations ← <em>{location | (location, ★) ∈ write_set}</em> ⊲ extract locations that were newly written<br/>40:     wrote_new_location ← rcu_update_written_locations(txn_idx, new_locations) <em>//check if new locations were written</em><br/>41:     last_read_set[txn_idx] ← read_set ⊲ store the read-set atomically (RCU update)<br/>42:     return wrote_new_location<br/><em>//calls the apply_write_set procedure which stores the write-set data in the multi-version data structure</em><br/><em>//extracts the locations that were not written by the previous incarnation</em><br/><em>//unpacks the rcu_update_written_location function which returns a bool but also updates the set of written transactions</em><br/><em>//stores the read_set</em><br/><em>//returns the value of wrote_new_location bool</em><br/><br/>43: procedure convert_writes_to_estimates(txn_idx)<br/>44:     prev_locations ← last_written_locations[txn_idx] ⊲ loaded atomically (RCU read)<br/>45:     for every location ∈ prev_location do<br/>46:         data[(location, txn_idx)] ← ESTIMATE ⊲ entry is guaranteed to exist<br/><br/><em>//logic for reading from the multi-version data structure</em><br/>47: function read(location, txn_idx)<br/>48:     𝑆 ← <em>{((location, idx), entry) ∈ data | idx &lt; txn_idx}</em> <em>// | means such that</em><br/>49:     if 𝑆 = <em>{}</em> then<br/>50:         return (status ← NOT_FOUND)<br/>51:     ((location, idx), entry) ← arg max𝑖𝑑𝑥 𝑆<br/>52:     if entry = ESTIMATE then<br/>53:         return (status ← READ_ERROR, blocking_txn_idx ← idx)<br/>54:     return (status ← OK, version ← (idx, entry.incarnation_number), value ← entry.value)<br/><em>//takes location and txn_idx as inputs</em><br/><em>//creates a data structure S of the form ((location, transaction id), entry)</em><br/><em>//and fills it with all the data from the multi-version data structure</em><br/><em>//while the transaction ids of the elements in data are less than the specified txn id </em><br/><em>//(remember 1&lt;2&lt;3&lt;...) so if txn_id is 3, it fills S with all the data for 1 and 2</em><br/><em>//if the set is empty, set status to not found i.e there are no writes to that location</em><br/><em>//by earlier transactions</em><br/><em>//select the entry from S with the highest transaction index (the most recent transaction since 2&gt;1)</em><br/><em>//find the write of the most recent transaction to that location.</em><br/><em>//if the entry is an estimate return status as read error</em><br/><em>//and set the value of the transaction blocking the transaction supplied in inout as idx</em><br/><em>//else return status as ok and set version to a tuple </em><br/><br/><em>//takes a snapshot of the multiversion data structure</em><br/>55: function snapshot()<br/>56:     ret ← <em>{}</em><br/>57:     for every location | ((location, ★), ★) ∈ data do <em>//★ is a placeholder</em><br/>58:         result ← read(location, BLOCK.size())<br/>59:         if result.status = OK then<br/>60:             ret ← ret ∪ <em>{location, result.value}</em> <em>//pseudo for set union</em><br/>61:     return ret<br/><em>//for every location such that contains a map of estimate or incarnation-value pair to </em><br/><em>//the location and transaction id pair, create an array equal in size to the block size</em><br/><em>//and move it to result</em><br/><em>//if result.status = OK then **add the location and result.value to the snapshot.**</em><br/><br/>62: function validate_read_set(txn_idx)<br/>63:     prior_reads ← last_read_set[txn_idx] ⊲ last recorded read_set, loaded atomically via RCU<br/>64:     for every (location, version) ∈ prior_reads do ⊲ version is ⊥ when prior read returned NOT_FOUND<br/>65:         cur_read ← read(location, txn_idx)<br/>66:         if cur_read.status = READ_ERROR then<br/>67:             return false ⊲ previously read entry from data, now ESTIMATE<br/>68:         if cur_read.status = NOT_FOUND ∧ version ≠ ⊥ then<br/>69:             return false ⊲ previously read entry from data, now NOT_FOUND<br/>70:         if cur_read.status = OK ∧ cur_read.version ≠ version then<br/>71:             return false ⊲ read some entry, but not the same as before<br/>72:     return true<br/><em>//line 64 and 65 can be read as for every location, version pair in the set of prior reads</em><br/><em>//set the current read to the most recent value set of values written by txn</em><br/><br/>Algorithm 3: The VM module<br/>73: function execute(txn_id)<br/>74:     read_set ← <em>{}</em> ⊲ (location, version) pairs<br/>75:     write_set ← <em>{}</em> ⊲ (location, value) pairs<br/>76:     run transaction BLOCK[txn_idx] ⊲ function call--run transaction, intercept reads and writes<br/>77: ....<br/>78:         when execution requires writing data to a location:<br/>79:             if (location, prev_value) ∈ write_set then<br/>80:                 write_set ← write_set \\ <em>{(location, prev_value)}</em> ⊲ store the latest value per location<br/>81:             write_set ← write_set ∪ <em>{(location, value)}</em> ⊲ VM does not write to MVMemory or Storage<br/><em>// when the execution of a transaction has never written to a location</em><br/><em>//line 81 adds a location value pair to the write set.</em><br/><br/>82: ....<br/>83:         when execution requires reading from a location:<br/>84:             if (location, value) ∈ write_set then<br/>85:                 VM reads value ⊲ value written by this txn<br/>86:             else<br/>87:                 result ← MVMemory.read(location, txn_idx) <br/>88:                 if result.status = NOT_FOUND then<br/>89:                     read_set ← read_set ∪ <em>{(location, ⊥)}</em> ⊲ record version ⊥ when reading from storage<br/>90:                     VM reads from Storage<br/>91:                 else if result.status = OK then<br/>92:                     read_set ← read_set ∪ <em>{(location, result.version)}</em><br/>93:                     VM reads result.value<br/>94:                 else<br/>95:                     return result ⊲ return (READ_ERROR, blocking_txn_id) from the VM.execute<br/><em>//for line 87, recall that the &quot;read&quot; fuction</em><br/><em>//checks for the most recent write and determines if it&#x27;s empty, estimate , or OK</em><br/>96: ....<br/>97:     return (read_set, write_set)<br/><br/>Algorithm 4: The Scheduler module, variables, utility APIs and next task logic<br/>Atomic variables:<br/>	execution_idx ← 0, validation_idx ← 0, decrease_cnt ← 0, num_active_tasks ← 0, done_marker ← false<br/>	⊲ Respectively: <br/>	An index that tracks the next transaction to try and execute. <br/>	A similar index for tracking validation. <br/>	Number of times validation_idx or execution_idx was decreased. <br/>	Number of ongoing validation and execution tasks.<br/>	Marker for completion.<br/><br/>	txn_dependency ← Array(BLOCK.size(), mutex(<em>{}</em>)) ⊲ txn_idx to a mutex-protected set of dependent transaction indices<br/>	txn_status ← Array(BLOCK.size(), mutex((0, READY_TO_EXECUTE))) ⊲ txn_idx to a mutex-protected pair (incarnation_number, status),<br/>	where status ∈ <em>{READY_TO_EXECUTE, EXECUTING, EXECUTED, ABORTING}</em>.<br/>	<br/>98: procedure decrease_execution_idx(target_idx)<br/>99:    execution_idx ← min(execution_idx, target_idx) ⊲ atomic<br/>100:   decrease_cnt.increment()<br/><br/>101: function done()<br/>102:   return done_marker<br/><br/>103: procedure decrease_validation_idx(target_idx)<br/>104:   validation_idx ← min(validation_idx, target_idx) ⊲ atomic<br/>105:   decrease_cnt.increment()<br/><br/>106: procedure check_done()<br/>107:   observed_cnt ← decrease_cnt<br/>108:   if min(execution_idx, validation_idx) ≥ BLOCK.size() ∧ num_active_tasks = 0 ∧ observed_cnt = decrease_cnt then<br/>109:     done_marker ← true<br/><em>//line 108 can be read as:</em><br/><em>//if the next task is for a transaction not in this block</em><br/><em>//and the number of active tasks is 0</em><br/><em>//and the observed count is equal to the number of times counters were decreased</em><br/><em>//then execution has finished</em><br/><br/>110: function try_incarnate(txn_idx)<br/>111:   if txn_idx &lt; BLOCK.size() then<br/>112:     with txn_status[txn_idx].lock()<br/>113:       if txn_status[txn_idx].status = READY_TO_EXECUTE then<br/>114:         txn_status[txn_idx].status ← EXECUTING<br/>115:         return (txn_idx, txn_status[txn_idx].incarnation_number)<br/>116:   num_active_tasks.decrement()<br/>117:   return ⊥<br/><em>//no actual execution of the transaction, just sets up the environemnt to call</em><br/><em>//execute from line 73</em><br/><br/><em>//determines what transaction to execute and calls try incarnate with the transaction id</em><br/>118: function next_version_to_execute()<br/>119:   if execution_idx ≥ BLOCK.size() then<br/>120:     check_done()<br/>121:     return ⊥<br/>122:   num_active_tasks.increment()<br/>123:   idx_to_execute ← execution_idx.fetch_and_increment()<br/>124:   return try_incarnate(idx_to_execute)<br/><br/><em>//same as above for validation tasks</em><br/>125: function next_version_to_validate()<br/>126:   if validation_idx ≥ BLOCK.size() then<br/>127:     check_done()<br/>128:     return ⊥<br/>129:   num_active_tasks.increment()<br/>130:   idx_to_validate ← validation_idx.fetch_and_increment()<br/>131:   if idx_to_validate &lt; BLOCK.size() then<br/>132:     (incarnation_number, status) ← txn_status[idx_to_validate].lock()<br/>133:     if status = EXECUTED then <em>//ensures the transaction has been executed</em><br/>134:       return (idx_to_validate, incarnation_number)<br/>135:   num_active_tasks.decrement()<br/>136:   return ⊥<br/><br/><em>//selects between execution and validation tasks</em><br/>137: function next_task()<br/>138:   if validation_idx &lt; execution_idx then<br/>139:     version_to_validate ← next_version_to_validate()<br/>140:     if version_to_validate ≠ ⊥ then<br/>141:       return (version ← version_to_validate, kind ← VALIDATION_TASK)<br/>142:   else<br/>143:     version_to_execute ← next_version_to_execute()<br/>144:     if version_to_execute ≠ ⊥ then<br/>145:       return (version ← version_to_execute, kind ← EXECUTION_TASK)<br/>146: return ⊥<br/><br/>Algorithm 5 The Scheduler module, dependencies and finish logic<br/><em>//determines if a transaction is being blocked by the transaction in the second argument</em><br/>147: function add_dependency(txn_idx, blocking_txn_idx)<br/>148:   with txn_dependency[blocking_txn_idx].lock()<br/>149:     if txn_status[blocking_txn_idx].lock().status = EXECUTED then ⊲ thread holds 2 locks<br/>150:     return false ⊲ dependency resolved before locking in Line 148<br/>151:   txn_status[txn_idx].lock().status() ← ABORTING ⊲ previous status must be EXECUTING<br/>152:   txn_dependency[blocking_txn_idx].insert(txn_idx)<br/>153:   num_active_tasks.decrement() ⊲ execution task aborted due to a dependency<br/>154:   return true<br/><br/>155: procedure set_ready_status(txn_idx)<br/>156:   with txn_status[txn_idx].lock()<br/>157:     (incarnation_number, status) ← txn_status[txn_idx] ⊲ status must be ABORTING<br/>158:     txn_status[txn_idx] ← (incarnation_number + 1, READY_TO_EXECUTE)<br/><br/>159: procedure resume_dependencies(dependent_txn_indices)<br/>160:   for each dep_txn_idx ∈ dependent_txn_indices do<br/>161:     set_ready_status(dep_txn_idx)<br/>162:     min_dependency_idx ← min(dependent_txn_indices) ⊲ minimum is ⊥ if no elements<br/>163:   if min_dependency_idx ≠ ⊥ then<br/>164:     decrease_execution_idx(min_dependency_idx) ⊲ ensure dependent indices get re-executed<br/><br/>165: procedure finish_execution(txn_idx, incarnation_number, wrote_new_path)<br/>166:   txn_status[txn_idx].lock().status ← EXECUTED ⊲ status must have been EXECUTING<br/>167:   deps ← txn_dependency[txn_idx].lock().swap(<em>{}</em>) ⊲ swap out the set of dependent transaction indices<br/>168:   resume_dependencies(deps)<br/>169:   if validation_idx &gt; txn_idx then ⊲ otherwise index already small enough<br/>170:     if wrote_new_path then<br/>171:     decrease_validation_idx(txn_idx) ⊲ schedule validation for txn_idx and higher txns<br/>172:   else<br/>173:     return (version ← (txn_idx, incarnation_number), kind ← VALIDATION_TASK)<br/>174:   num_active_tasks.decrement()<br/>175:   return ⊥ ⊲ no task returned to the caller<br/><br/>176: function try_validation_abort(txn_idx, incarnation_number)<br/>177:   with txn_status[txn_idx].lock()<br/>178:     if txn_status[txn_idx] = (incarnation_number, EXECUTED) then<br/>179:       txn_status[txn_idx].status ← ABORTING ⊲ thread changes status, starts aborting<br/>180:       return true<br/>181:   return false<br/><br/>182: procedure finish_validation(txn_idx, aborted)<br/>183:   if aborted then<br/>184:     set_ready_status(txn_idx)<br/>185:     decrease_validation_idx(txn_idx + 1) ⊲ schedule validation for higher transactions<br/>186:     if execution_idx &gt; txn_idx then ⊲ otherwise index already small enough<br/>187:       new_version ← try_incarnate(txn_idx)<br/>188:       if new_version ≠ ⊥ then<br/>189:         return (new_version, kind ← EXECUTION_TASK) ⊲ return re-execution task to the caller<br/>190:   num_active_tasks.decrement() ⊲ done with validation task<br/>191:   return ⊥ ⊲ no task returned to the caller</p><p>*<sup>1</sup>Executing transactions in batches reduces messaging and context switching but comes at the cost of requiring extra scheduling.<sup> </sup></p><p><sup>*2</sup>The topic of OCC vs. PCC is considered moot in academia—the general sentiment is that OCC is suited for low contention applications and PCC for high contention applications. As such there is very little work ongoing in this regard—one of the most recent papers to discuss the subject was written in 1982. The following graph is adapted from the paper and it helps to reinform the established sentiment.</p><p>‍</p><figure class="w-richtext-align-center w-richtext-figure-type-image"><div><img src="https://cdn.prod.website-files.com/667922883d09f8c39ad9defe/6711187625a472793ccc8cf7_AD_4nXcvcZ7tFv1tSNHxkh7Y4dAc2wY4ffoO2b5ss1QXlSD4Ki4uycsDqUJ76i58HzxFNSfX7h84527_4STncGVPdaXyybXD6XmqhCcTtSmFDfqRawtj3b7jGj89huWNmOknfg3Op6JqlFJDFifzbxoGE8mGS5I.png" loading="lazy" alt=""/></div></figure><p><em>Figure 24: OCC (COCC) vs PCC (LOCC) </em>|<em> Source: Optimistic versus pessimistic concurrency control mechanisms in database management systems</em><a href="https://www.semanticscholar.org/author/D.-Menasc%C3%A9/2264617067"><em> D. Menascé</em></a><em>, </em><a href="https://www.semanticscholar.org/author/Tatuo-Nakanishi/31634756"><em>Tatuo Nakanishi</em></a><em>  </em><a href="https://www.semanticscholar.org/venue?name=Information%20Systems"><em>Information Systems</em></a><em> 1982. DOI:</em><a href="https://doi.org/10.1016/0306-4379%2882%2990003-5"><em>10.1016/0306-4379(82)90003-5</em></a><em> </em></p><p>The 2016 study, <em>Revisiting optimistic and pessimistic concurrency control</em> by Goetz Graefe of Hewlett-Packard Labs, comes to the same conclusion as Menasce and Nakanishi; to quote the author,<br/><br/>“<em>...we have concluded that optimistic concurrency control permits more concurrency than pessimistic concurrency control only if it fails to detect some actual conflicts or if a particular implementation of locking detects false conflicts.</em>”</p><p>There are numerous studies that come to the same conclusion but we’ve left them out for brevity.</p><p>*<sup>3 </sup>A perfectly fair evaluation of Block-STM and Sealevel would require isolation, i.e., removing all other processes like Solana’s PoH and ledger commits, using the same VM for both TPUs and a host of laborious engineering tasks that are simply not worth the effort, especially when preliminary testing suggests that the TPUs follow the established trends.</p><p>*<sup>4 </sup>An optimization in the implementation of Block-STM allows aborted transactions to be restarted from the point of conflict. Instead of restarting execution from scratch, the MoveVM supports validating the readset of the transaction’s previous incarnation and if valid, continuing execution from the point of conflict.</p><p>*<sup>5 </sup>A second optimization is when the dependency is resolved before the execution task is created i.e when line 14 of the algorithm returns false. In the implementation, the VM continues execution from where it paused rather than restarting the execution.</p><p>‍</p></div><div class="blog-article_share"><div class="heading-48 u-mb-0">Share</div><div class="blog-socials"><a fs-socialshare-element="twitter" href="block-stm-vs-sealevel-a-comparison-of-parallel-execution-engines.html#" class="blog_social-link w-inline-block"><svg xmlns="http://www.w3.org/2000/svg" width="100%" viewBox="0 0 36 32" fill="none" class="icon-embed"><path d="M27.8756 0H33.28L21.4756 13.5822L35.4133 32H24.4622L15.9289 20.8356L6.11556 32H0.711111L13.3689 17.4933L0 0H11.2356L18.9867 10.24L27.8756 0ZM25.9556 28.7289H28.9422L9.6 3.05778H6.32889L25.9556 28.7289Z" fill="currentColor"></path></svg></a><a fs-socialshare-element="linkedin" href="block-stm-vs-sealevel-a-comparison-of-parallel-execution-engines.html#" class="blog_social-link w-inline-block"><svg xmlns="http://www.w3.org/2000/svg" width="100%" viewBox="0 0 37 36" fill="none" class="icon-embed"><g clip-path="url(#clip0_281_78591)"><path fill-rule="evenodd" clip-rule="evenodd" d="M4.63501 36H32.635C34.8442 36 36.635 34.2091 36.635 32V4C36.635 1.79086 34.8442 0 32.635 0H4.63501C2.42587 0 0.63501 1.79086 0.63501 4V32C0.63501 34.2091 2.42587 36 4.63501 36Z" fill="black"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M31.635 31H26.2928V21.9011C26.2928 19.4064 25.3449 18.0123 23.3704 18.0123C21.2223 18.0123 20.1 19.4631 20.1 21.9011V31H14.9517V13.6667H20.1V16.0015C20.1 16.0015 21.648 13.1371 25.3263 13.1371C29.0029 13.1371 31.635 15.3822 31.635 20.0256V31ZM8.80968 11.397C7.05604 11.397 5.63501 9.96483 5.63501 8.1985C5.63501 6.43218 7.05604 5 8.80968 5C10.5633 5 11.9835 6.43218 11.9835 8.1985C11.9835 9.96483 10.5633 11.397 8.80968 11.397ZM6.15129 31H11.5197V13.6667H6.15129V31Z" fill="white"></path></g><defs><clipPath id="clip0_281_78591"><rect width="36" height="36" fill="white" transform="translate(0.63501)"></rect></clipPath></defs></svg></a><a fs-socialshare-element="reddit" href="block-stm-vs-sealevel-a-comparison-of-parallel-execution-engines.html#" class="blog_social-link w-inline-block"><svg xmlns="http://www.w3.org/2000/svg" width="100%" viewBox="0 0 37 36" fill="none" class="icon-embed"><path d="M18.635 36C28.5761 36 36.635 27.9411 36.635 18C36.635 8.05887 28.5761 0 18.635 0C8.69388 0 0.63501 8.05887 0.63501 18C0.63501 27.9411 8.69388 36 18.635 36Z" fill="black"></path><path d="M30.635 18C30.6344 17.4854 30.4826 16.9822 30.1984 16.5532C29.9142 16.1241 29.5101 15.7881 29.0364 15.5869C28.5627 15.3856 28.0404 15.3281 27.5342 15.4214C27.0281 15.5146 26.5606 15.7546 26.1898 16.1115C24.117 14.7005 21.6769 13.9264 19.1698 13.8848L20.3653 8.25975L24.272 9.09075C24.2933 9.5466 24.48 9.97905 24.7973 10.307C25.1146 10.635 25.5406 10.8361 25.9955 10.8724C26.4504 10.9088 26.903 10.778 27.2683 10.5046C27.6337 10.2312 27.8868 9.83393 27.9803 9.38725C28.0737 8.94057 28.001 8.47515 27.7758 8.07823C27.5507 7.6813 27.1884 7.38012 26.7571 7.23114C26.3258 7.08216 25.8549 7.09559 25.4328 7.26894C25.0106 7.44228 24.6662 7.76363 24.464 8.17275L20.0983 7.24425C19.9767 7.21846 19.8499 7.24197 19.7457 7.30961C19.6415 7.37725 19.5684 7.4835 19.5425 7.605L18.2075 13.8825C15.6651 13.9052 13.1862 14.6791 11.0825 16.107C10.8068 15.8402 10.476 15.6371 10.1134 15.512C9.75078 15.3868 9.36512 15.3427 8.98359 15.3826C8.60206 15.4226 8.23392 15.5457 7.9051 15.7433C7.57627 15.9409 7.29474 16.2081 7.08033 16.5262C6.86592 16.8443 6.72384 17.2056 6.66409 17.5845C6.60434 17.9634 6.62837 18.3509 6.73449 18.7195C6.84061 19.0882 7.02624 19.4291 7.27832 19.7182C7.53039 20.0074 7.84279 20.2378 8.19351 20.3932C8.15364 20.6561 8.13408 20.9216 8.13501 21.1875C8.13501 25.2262 12.833 28.5 18.635 28.5C24.437 28.5 29.135 25.2262 29.135 21.1875C29.1346 20.9233 29.114 20.6596 29.0735 20.3985C29.538 20.1927 29.9327 19.8565 30.2099 19.4308C30.4871 19.005 30.6347 18.508 30.635 18ZM12.635 19.875C12.635 19.5042 12.745 19.1416 12.951 18.8333C13.157 18.525 13.4499 18.2846 13.7925 18.1427C14.1351 18.0008 14.5121 17.9637 14.8758 18.036C15.2395 18.1084 15.5736 18.287 15.8358 18.5492C16.0981 18.8114 16.2766 19.1455 16.349 19.5092C16.4213 19.8729 16.3842 20.2499 16.2423 20.5925C16.1004 20.9351 15.86 21.228 15.5517 21.434C15.2434 21.64 14.8809 21.75 14.51 21.75C14.0127 21.75 13.5358 21.5525 13.1842 21.2008C12.8326 20.8492 12.635 20.3723 12.635 19.875ZM23.09 24.8295C21.8105 26.1045 19.358 26.2073 18.6373 26.2073C17.9165 26.2073 15.4633 26.1075 14.1853 24.8295C14.1402 24.7843 14.1044 24.7307 14.08 24.6718C14.0556 24.6128 14.0431 24.5496 14.0431 24.4857C14.0431 24.4219 14.0557 24.3587 14.0802 24.2998C14.1046 24.2408 14.1405 24.1872 14.1856 24.1421C14.2308 24.097 14.2844 24.0612 14.3434 24.0368C14.4024 24.0125 14.4656 23.9999 14.5294 24C14.5932 24 14.6564 24.0126 14.7154 24.0371C14.7743 24.0615 14.8279 24.0973 14.873 24.1425C15.6793 24.9487 17.405 25.2352 18.6373 25.2352C19.8695 25.2352 21.5953 24.9487 22.4038 24.1417C22.4484 24.0944 22.5021 24.0566 22.5617 24.0304C22.6212 24.0043 22.6854 23.9903 22.7504 23.9894C22.8155 23.9885 22.88 24.0007 22.9403 24.0252C23.0005 24.0497 23.0553 24.086 23.1012 24.1321C23.1471 24.1781 23.1834 24.2329 23.2078 24.2932C23.2321 24.3535 23.2442 24.4181 23.2431 24.4832C23.2421 24.5482 23.228 24.6124 23.2017 24.6719C23.1754 24.7313 23.1374 24.785 23.09 24.8295ZM22.76 21.75C22.3892 21.75 22.0267 21.64 21.7183 21.434C21.41 21.228 21.1697 20.9351 21.0277 20.5925C20.8858 20.2499 20.8487 19.8729 20.921 19.5092C20.9934 19.1455 21.172 18.8114 21.4342 18.5492C21.6964 18.287 22.0305 18.1084 22.3942 18.036C22.7579 17.9637 23.1349 18.0008 23.4775 18.1427C23.8202 18.2846 24.113 18.525 24.319 18.8333C24.525 19.1416 24.635 19.5042 24.635 19.875C24.635 20.3723 24.4375 20.8492 24.0858 21.2008C23.7342 21.5525 23.2573 21.75 22.76 21.75Z" fill="white"></path></svg></a></div></div></div></section><footer class="footer"><div class="footer_top"><div class="footer-col"><a href="../blog.html" class="footer-link w-inline-block"><div>Blog</div></a><a href="block-stm-vs-sealevel-a-comparison-of-parallel-execution-engines.html#" class="footer-link u-d-none w-inline-block"><div>points</div></a><a href="mailto:team@eclipse.xyz" class="footer-link w-inline-block"><div>Contact</div></a><a href="../terms.html" class="footer-link w-inline-block"><div>Terms</div></a><a href="../privacy-policy.html" class="footer-link w-inline-block"><div>Privacy Policy</div></a><a href="../cookie-policy.html" class="footer-link w-inline-block"><div>Cookie Policy</div></a></div><div class="footer-col"><a href="../why-eclipse.html" class="footer-link w-inline-block"><div>why eclipse?</div></a><a href="https://docs.eclipse.xyz/" target="_blank" class="footer-link w-inline-block"><div>developer docs</div></a><a href="block-stm-vs-sealevel-a-comparison-of-parallel-execution-engines.html#" class="footer-link u-d-none w-inline-block"><div>hackquest</div></a></div><div id="w-node-b778defb-9e27-56db-13fb-582d3418c53c-3418c513" class="footer-socials"><div class="text-32">SOLANA <span class="text-20-copy">( ON )</span> ETHEREUM</div><div class="footer_social-links"><a href="https://x.com/EclipseFND" target="_blank" class="footer-social w-inline-block"><svg xmlns="http://www.w3.org/2000/svg" width="100%" viewBox="0 0 28 24" fill="none" class="icon-embed"><g clip-path="url(#clip0_200_291)"><path d="M21.6801 0H25.7334L16.8801 10.1867L27.3334 24H19.1201L12.7201 15.6267L5.3601 24H1.30677L10.8001 13.12L0.773438 0H9.2001L15.0134 7.68L21.6801 0ZM20.2401 21.5467H22.4801L7.97344 2.29333H5.5201L20.2401 21.5467Z" fill="currentColor"></path></g><defs><clipPath id="clip0_200_291"><rect width="26.56" height="24" fill="currentColor" transform="translate(0.773438)"></rect></clipPath></defs></svg></a><a href="https://discord.gg/eclipse-fnd" target="_blank" class="footer-social w-inline-block"><svg xmlns="http://www.w3.org/2000/svg" width="100%" viewBox="0 0 32 24" fill="none" class="icon-embed"><g clip-path="url(#clip0_200_294)"><path d="M27.1574 2.00996C25.0769 1.05745 22.8805 0.381713 20.6244 0C20.3157 0.551901 20.0363 1.11973 19.7875 1.70112C17.3843 1.33898 14.9404 1.33898 12.5372 1.70112C12.2883 1.11979 12.009 0.551968 11.7004 0C9.44279 0.384937 7.24497 1.06228 5.16237 2.01494C1.02788 8.132 -0.0929189 14.0971 0.46748 19.9776C2.88874 21.7665 5.59883 23.127 8.47993 24C9.12867 23.1275 9.70272 22.2018 10.196 21.2329C9.2591 20.883 8.35482 20.4512 7.49363 19.9427C7.72028 19.7783 7.94195 19.609 8.15615 19.4446C10.662 20.623 13.397 21.234 16.1661 21.234C18.9352 21.234 21.6702 20.623 24.1761 19.4446C24.3928 19.6214 24.6144 19.7908 24.8386 19.9427C23.9757 20.4521 23.0698 20.8846 22.1312 21.2354C22.6239 22.2039 23.198 23.1287 23.8473 24C26.7309 23.1305 29.443 21.7707 31.8647 19.9801C32.5223 13.1606 30.7414 7.25031 27.1574 2.00996ZM10.9058 16.3611C9.34419 16.3611 8.05403 14.944 8.05403 13.2005C8.05403 11.457 9.29936 10.0274 10.9009 10.0274C12.5023 10.0274 13.7825 11.457 13.7552 13.2005C13.7278 14.944 12.4974 16.3611 10.9058 16.3611ZM21.4264 16.3611C19.8622 16.3611 18.5771 14.944 18.5771 13.2005C18.5771 11.457 19.8224 10.0274 21.4264 10.0274C23.0304 10.0274 24.3006 11.457 24.2732 13.2005C24.2458 14.944 23.0179 16.3611 21.4264 16.3611Z" fill="currentColor"></path></g><defs><clipPath id="clip0_200_294"><rect width="31.6663" height="24" fill="currentColor" transform="translate(0.333008)"></rect></clipPath></defs></svg></a></div></div></div><div class="footer_logo"><svg xmlns="http://www.w3.org/2000/svg" width="100%" viewBox="0 0 1344 144" fill="none" class="icon-embed"><path d="M193.189 28.5047L200.076 0H54.9142C40.7075 0 26.3636 11.7106 22.8712 26.1591L0.770964 117.638C-2.71855 132.086 5.96666 143.797 20.1705 143.797H165.333L172.22 115.292H56.7404C52.0048 115.292 49.1098 111.388 50.2729 106.572L55.2057 86.1507H179.256L186.144 57.646H62.0961L67.0289 37.2244C68.1921 32.4082 72.9734 28.5047 77.7089 28.5047H193.186H193.189Z" fill="currentColor"></path><path d="M383.017 28.5047L389.904 0H244.742C230.538 0 216.195 11.7106 212.702 26.1591L190.599 117.638C187.11 132.086 195.795 143.797 209.999 143.797H355.161L362.048 115.292H246.571C241.836 115.292 238.941 111.388 240.104 106.572L256.86 37.2244C258.023 32.4082 262.804 28.5047 267.54 28.5047H383.017Z" fill="currentColor"></path><path d="M431.977 106.572L457.727 0H410.897L382.475 117.638C378.986 132.086 387.671 143.797 401.875 143.797H547.037L553.924 115.292H438.447C433.712 115.292 430.817 111.388 431.98 106.572H431.977Z" fill="currentColor"></path><path d="M764.962 28.5047L771.85 0H600.966L594.079 28.5047H647.53C652.266 28.5047 655.161 32.4082 653.998 37.2244L637.242 106.572C636.079 111.388 631.297 115.292 626.562 115.292H573.11L566.223 143.797H737.106L743.994 115.292H690.542C685.806 115.292 682.911 111.388 684.075 106.572L700.83 37.2244C701.994 32.4082 706.775 28.5047 711.511 28.5047H764.962Z" fill="currentColor"></path><path d="M839.07 0H817.961C803.757 0 789.411 11.7106 785.921 26.1591L757.499 143.797H804.329L818.255 86.1507H916.585C930.792 86.1507 945.136 74.4401 948.628 59.9916L956.802 26.1591C960.294 11.7106 951.606 0 937.402 0H839.073H839.07ZM894.03 57.646H825.14L832.182 28.5047H901.072C905.808 28.5047 908.703 32.4082 907.54 37.2244L904.713 48.9263C903.55 53.7425 898.769 57.646 894.033 57.646H894.03Z" fill="currentColor"></path><path d="M1092.49 143.797H947.327L954.215 115.292H1069.48C1074.22 115.292 1079 111.388 1080.16 106.572L1082.99 94.8704C1084.15 90.0542 1081.25 86.1507 1076.52 86.1507H986.975C972.768 86.1507 964.083 74.4401 967.576 59.9916L975.749 26.1591C979.239 11.7106 993.585 0 1007.79 0H1152.95L1146.06 28.5047H1030.58C1025.85 28.5047 1021.07 32.4082 1019.9 37.2244L1017.08 48.9263C1015.91 53.7425 1018.81 57.646 1023.54 57.646H1113.3C1127.51 57.646 1136.19 69.3565 1132.7 83.8051L1124.53 117.638C1121.04 132.086 1106.69 143.797 1092.48 143.797H1092.49Z" fill="currentColor"></path><path d="M1337.11 28.5047L1344 0H1198.84C1184.63 0 1170.29 11.7106 1166.79 26.1591L1144.69 117.638C1141.2 132.086 1149.89 143.797 1164.09 143.797H1309.25L1316.14 115.292H1200.66C1195.93 115.292 1193.03 111.388 1194.2 106.572L1199.13 86.1507H1323.18L1330.07 57.646H1206.02L1210.95 37.2244C1212.11 32.4082 1216.89 28.5047 1221.63 28.5047H1337.11H1337.11Z" fill="currentColor"></path></svg></div></footer></main></div><script src="https://d3e54v103j8qbb.cloudfront.net/js/jquery-3.5.1.min.dc5e7f18c8.js?site=667150f66409572775122b43" type="text/javascript" integrity="sha256-9/aliU8dGd2tb6OSsuzixeV4y/faTqgFtohetphbbj0=" crossorigin="anonymous"></script><script src="https://cdn.prod.website-files.com/667150f66409572775122b43/js/webflow.f5324e08c.js" type="text/javascript"></script><!-- NAV BRAND SWITCHING -->
<script>
document.addEventListener('DOMContentLoaded', () => {
	const navBrand = document.querySelector('.d_nav-brand');

	window.addEventListener('scroll', function () {
		const currentScrollPos = Math.floor(window.scrollY);

		if (currentScrollPos > 1200) {
			navBrand.classList.add('is-short');
		} else {
			navBrand.classList.remove('is-short');
		}
	});
});
</script>

<!-- INTRO ANIM -->
<script>
document.addEventListener('DOMContentLoaded', () => {
	if (document.querySelector('.anim')) {
		runIntro();
	}

	function runIntro() {
		const elements = document.querySelectorAll('.anim');

		gsap.from(elements, {
			y: '0.25rem',
			opacity: 0,
			stagger: {
				each: 0.05,
			},
		});
	}
});
</script>

<!-- SLIDERS -->
<script>
  document.addEventListener('DOMContentLoaded', () => {
    const sliders = document.querySelectorAll('.swiper');


    sliders.forEach((slider) => {
      //SETUP SLIDER
      if(slider.classList.contains("cc-home") && window.innerWidth > 767){
        const homeSwiper = new Swiper(
          slider,
          {
            speed: 800,
            effect: 'slide',
            direction: 'horizontal',
            // loop: true,
            // loopedSlides: 12,
            slidesPerView: "auto",
            // loopAdditionalSlides: 8,
            keyboard: true,
            spaceBetween: 4,
          }
        );
      }

      if(slider.classList.contains("cc-blog")){
        const blogSwiper = new Swiper(
          slider,
          {
            speed: 800,
            effect: 'slide',
            direction: 'horizontal',
            // loop: true,
            // loopedSlides: 12,
            slidesPerView: "auto",
            // loopAdditionalSlides: 8,
            keyboard: true,
            spaceBetween: 4,
          }
        );
      }
    });
  });
</script>

</body></html>